# 第22章：稀疏计算与动态稀疏

稀疏计算是现代深度学习加速的关键技术之一。随着模型规模的不断增长，利用权重和激活值中的稀疏性已成为突破性能瓶颈的重要手段。本章将深入探讨CUDA中的稀疏计算技术，从传统的稀疏矩阵格式到最新的结构化稀疏和动态稀疏网络，帮助你在自动驾驶和具身智能场景中实现数倍的推理加速。

## 22.1 稀疏矩阵格式

稀疏矩阵的高效存储和计算是稀疏优化的基础。不同的稀疏格式适用于不同的稀疏模式和计算场景，选择合适的格式对性能至关重要。

### 22.1.1 CSR（Compressed Sparse Row）格式

CSR是最常用的稀疏矩阵格式，特别适合行访问模式的计算。它使用三个数组来表示稀疏矩阵，通过压缩行信息来节省存储空间，是许多科学计算和机器学习应用的基础数据结构。

```
稀疏矩阵 A (4×4, 6个非零元素):
[4  0  0  2]
[0  3  0  0]
[0  0  5  0]
[1  0  0  6]

CSR表示:
values:     [4, 2, 3, 5, 1, 6]  // 非零元素值（按行序存储）
col_idx:    [0, 3, 1, 2, 0, 3]  // 列索引（对应每个非零值）
row_ptr:    [0, 2, 3, 4, 6]     // 行指针（第i行的起始位置）

解读：
- row_ptr[i]到row_ptr[i+1]定义第i行的元素范围
- 第0行：values[0:2] = [4, 2]，列索引[0, 3]
- 第1行：values[2:3] = [3]，列索引[1]
- 存储开销：O(nnz + rows)，其中nnz为非零元素数
```

**CSR格式的内存布局优势**：
- 行指针数组使得行遍历效率极高，O(1)定位任意行的起始位置
- 连续存储同一行的非零元素，充分利用缓存局部性和预取机制
- 适合SpMV（稀疏矩阵向量乘）等行主导操作，内存访问模式可预测
- 行压缩存储减少了冗余信息，相比COO格式节省33%的索引存储
- 支持高效的行切片和子矩阵提取操作

**CUDA中的CSR并行策略**：

1. **标量模式（One thread per row）**：
   ```
   线程分配：tid = blockIdx.x * blockDim.x + threadIdx.x
   处理逻辑：线程tid处理第tid行
   优势：实现简单，无需同步
   劣势：行长度差异大时负载严重不均
   适用场景：稀疏度均匀的矩阵（如规则网格离散化）
   ```

2. **向量模式（Warp per row）**：
   ```
   线程分配：每32个线程（一个warp）协作处理一行
   处理逻辑：warp内线程并行处理非零元素，shuffle归约
   优势：更好的负载均衡，warp内自动同步
   劣势：短行会浪费线程资源
   适用场景：中等稠密度矩阵（每行32-256个非零元素）
   ```

3. **自适应模式（动态线程分配）**：
   ```
   预处理：统计行长度分布，分类为短/中/长行
   短行（<32）：一个线程处理
   中行（32-512）：一个warp处理
   长行（>512）：一个block处理
   优势：最优负载均衡
   劣势：需要额外的预处理和调度开销
   ```

4. **分段CSR（Segmented CSR）**：
   - 将矩阵按行分段，每段内行长度相近
   - 不同段使用不同的并行策略
   - 减少warp divergence，提高SIMD效率

**性能优化技巧**：

1. **内存访问优化**：
   - 使用纹理内存缓存列索引，利用空间局部性
   - 向量化load非零值，使用float2/float4利用128位内存事务
   - 对齐数据结构到128字节边界，优化内存合并
   - 使用__ldg()内在函数强制L1缓存只读数据

2. **负载均衡优化**：
   - 排序优化：按行长度排序，相似长度的行分组处理
   - 工作队列：使用原子操作动态分配行到空闲warp
   - 行合并：多个短行合并到一个warp处理
   - 负载预测：基于历史数据预测负载分布

3. **数据类型优化**：
   - 混合精度：值用FP16/BF16，索引用INT32/INT16
   - 压缩索引：对于小矩阵使用INT16甚至INT8索引
   - Delta编码：存储列索引差值而非绝对值
   - 位打包：对于布尔稀疏矩阵使用位向量

4. **算法级优化**：
   - 分块CSR：将大矩阵分块，提高缓存重用
   - 双精度累加：使用FP64累加器避免精度损失
   - 提前退出：检测零向量元素跳过计算
   - 向量预加载：将常用向量元素缓存到共享内存

### 22.1.2 COO（Coordinate）格式

COO格式是最简单直观的稀疏格式，使用三个数组分别存储行索引、列索引和值。这种格式也称为IJV格式或三元组格式，是构建其他稀疏格式的基础，在矩阵构造阶段和动态更新场景中广泛使用。

```
同样的稀疏矩阵 A:
[4  0  0  2]
[0  3  0  0]
[0  0  5  0]
[1  0  0  6]

COO表示:
row_idx:    [0, 0, 1, 2, 3, 3]  // 行索引
col_idx:    [0, 3, 1, 2, 0, 3]  // 列索引  
values:     [4, 2, 3, 5, 1, 6]  // 非零元素值

特点：
- 每个非零元素独立存储其完整坐标
- 不假设任何排序，元素可以任意顺序
- 存储开销：O(3×nnz)，是CSR的1.5倍
- 支持重复坐标（需要累加处理）
```

**COO格式的特点与应用场景**：
- 格式简单，易于构建和修改，无需维护复杂的数据结构
- 不要求排序，灵活性高，支持增量构建和动态插入
- 适合极度稀疏的矩阵（稀疏度>99%），存储效率相对较高
- 原子操作友好，适合并行assembly和矩阵构造阶段
- 天然支持矩阵转置（交换行列索引即可）
- 便于实现矩阵运算的并行化（每个元素独立处理）

**CUDA优化策略**：

1. **原子操作优化**：
   ```
   策略1：使用atomicAdd进行结果累加
   - 简单直接，但可能有竞争
   - 适用于输出稀疏的情况
   
   策略2：分段原子操作
   - 将输出向量分段，每段独立原子操作
   - 减少竞争，提高吞吐量
   
   策略3：使用共享内存缓冲
   - 先在共享内存累加，再写回全局内存
   - 显著减少全局内存原子操作
   ```

2. **排序优化策略**：
   - Morton编码（Z-order）排序：提升2D空间局部性
   - Hilbert曲线排序：更好的局部性保持
   - 行主序排序：便于转换为CSR格式
   - 分块排序：块内有序，块间可以无序

3. **分块处理技术**：
   ```
   将矩阵逻辑分块为tiles:
   - Tile大小：通常32×32或64×64
   - 每个block处理一个或多个tile
   - Tile内使用共享内存累加
   - 减少原子操作竞争范围
   ```

4. **哈希表加速**：
   - 使用哈希表管理坐标到值的映射
   - 支持O(1)的查找和更新
   - 特别适合动态稀疏模式
   - GPU哈希表实现需要处理冲突

5. **批量COO处理**：
   - 多个小矩阵打包成一个大COO
   - 添加batch维度索引
   - 提高GPU利用率
   - 适合图神经网络的批量图处理

### 22.1.3 ELL（ELLPACK）格式

ELL格式将稀疏矩阵填充成规则的二维数组，特别适合GPU的SIMD执行模型。这种格式通过牺牲一定的存储空间来换取完美的内存访问模式，是GPU稀疏计算的理想选择之一。

```
原始稀疏矩阵 A (4×4):
[4  0  0  2]   <- 2个非零元素
[0  3  0  0]   <- 1个非零元素
[0  0  5  0]   <- 1个非零元素  
[1  0  0  6]   <- 2个非零元素

ELL表示（K=2，每行固定存储2个元素）:
values矩阵(4×2):           col_idx矩阵(4×2):
[4  2]                      [0  3]
[3  *]  (*为padding)        [1  -1] (-1表示无效)
[5  *]                      [2  -1]
[1  6]                      [0  3]

存储布局（列主序，GPU友好）:
values: [4, 3, 5, 1, 2, *, *, 6]  // 第1列, 第2列
col_idx: [0, 1, 2, 0, 3, -1, -1, 3]
```

**ELL格式的优势**：
- 完美的内存合并访问模式：所有线程访问连续内存地址
- 无需同步，线程间完全独立，无数据依赖
- 固定的内存访问模式，编译器易于优化和向量化
- 适合非零元素分布均匀的矩阵（如有限元离散化）
- 消除了负载不均衡问题，所有线程执行相同工作量
- 支持高效的SIMD操作和向量指令

**K值选择与分析**：
```
K值选择策略：
1. 统计每行非零元素数量分布
2. 计算不同K值的覆盖率和浪费率
3. 权衡存储开销vs计算效率

示例分析：
行长度分布：[1:20%, 2:30%, 3:25%, 4:15%, 5:10%]
K=3时：覆盖75%，padding率=(3×100-实际非零数)/3×100
K=4时：覆盖90%，padding率更高
K=5时：覆盖100%，但可能浪费大量空间
```

**Padding策略与优化**：

1. **自适应K值选择**：
   - 统计分析：选择覆盖90-95%行的K值
   - 成本模型：min(存储开销 + 计算开销)
   - 动态调整：根据运行时稀疏模式调整

2. **分片ELL（Sliced ELL）**：
   ```
   将矩阵按行分成多个片段：
   片段1（行0-999）：K1=3
   片段2（行1000-1999）：K2=5
   片段3（行2000-2999）：K3=2
   每个片段独立处理，减少padding浪费
   ```

3. **混合格式（ELL+COO）**：
   ```
   ELL部分：存储每行前K个非零元素
   COO部分：存储超出K的额外元素
   优势：结合ELL的规则性和COO的灵活性
   适用：大部分行稀疏，少数行稠密
   ```

4. **向量化访问**：
   - 使用float2/float4一次加载多个元素
   - 列主序存储利于向量化
   - 使用纹理内存加速随机列访问
   - 预取技术减少内存延迟

5. **压缩技术**：
   - 位图标记有效元素，避免存储无效索引
   - Run-length编码压缩连续padding
   - 差分编码减少索引存储

### 22.1.4 格式转换与选择策略

稀疏格式之间的高效转换是实际应用的关键需求，不同计算阶段可能需要不同的格式。理解转换算法和选择策略对于构建高性能稀疏应用至关重要。

**格式转换的并行算法**：

1. **CSR到COO转换**：
   ```
   并行算法：
   1. 计算总非零元素数：nnz = row_ptr[rows]
   2. 并行展开row_ptr为行索引：
      - 每个线程处理一行
      - 使用前缀和确定写入位置
   3. 直接复制col_idx和values数组
   
   复杂度：O(rows + nnz)并行时间
   ```

2. **COO到CSR转换**：
   ```
   两阶段算法：
   阶段1：排序和计数
   - 按(row, col)排序COO三元组
   - 并行计算每行的非零元素数
   
   阶段2：构建CSR
   - 前缀和生成row_ptr
   - 复制排序后的列索引和值
   
   优化：使用基数排序获得O(nnz)复杂度
   ```

3. **Dense到Sparse转换**：
   ```
   两遍扫描算法：
   第一遍：计数非零元素
   - 并行扫描所有元素
   - 原子计数或分段归约
   
   第二遍：填充稀疏数组
   - 分配精确大小的存储
   - 并行写入非零元素
   
   优化：使用warp级协作减少原子操作
   ```

4. **ELL到CSR转换**：
   ```
   压缩算法：
   1. 计算每行实际非零数（跳过padding）
   2. 前缀和生成row_ptr
   3. 紧凑存储非padding元素
   
   特点：保持行序，无需排序
   ```

**格式选择决策树**：
```
矩阵特征分析：
├─ 稀疏度 < 50%？
│  └─ 使用Dense格式（利用Tensor Core）
├─ 每行非零数标准差 < 平均值×0.5？
│  └─ 使用ELL格式（规则访问模式）
├─ 需要频繁插入/删除？
│  └─ 使用COO格式（动态友好）
├─ 以行遍历为主？
│  └─ 使用CSR格式（行局部性好）
├─ 以列遍历为主？
│  └─ 使用CSC格式（列局部性好）
└─ 分块结构明显？
   └─ 使用BSR格式（块稀疏行）
```

**性能基准对比**：
```
场景：矩阵规模100K×100K，稀疏度95%
硬件：NVIDIA A100 GPU

SpMV性能（GFLOPS）：
- ELL：     45.2（非零分布均匀）
- CSR：     38.7（自适应算法）
- COO：     25.3（原子操作）
- HYB：     42.1（ELL+COO混合）

内存占用（MB）：
- CSR：     24（最紧凑）
- COO：     36（1.5×CSR）
- ELL：     85（含50% padding）
- Dense：   40000（不可行）

构建时间（ms）：
- COO：     12（直接构建）
- CSR：     18（需要排序）
- ELL：     25（需要分析+padding）

更新开销（单个元素）：
- COO：     O(1)（追加）
- CSR：     O(nnz)（最坏情况）
- ELL：     O(1)（如果不超过K）
```

**自适应格式选择框架**：
```
运行时决策系统：
1. 矩阵分析（采样或完整扫描）
2. 性能模型预测
3. 格式选择与转换
4. 性能监控与反馈
5. 动态调整策略
```

## 22.2 cuSPARSE高级用法

cuSPARSE是NVIDIA提供的稀疏线性代数库，提供了高度优化的稀疏矩阵运算。本节深入探讨其高级特性和优化技巧。

### 22.2.1 cuSPARSE架构与API演进

**Generic API（11.0+）的优势**：
- 统一的接口设计，支持多种数据类型
- 自动格式选择和优化
- 异步执行和CUDA Graph支持
- 更好的性能可移植性

**句柄与描述符管理**：
```
cusparseHandle_t：管理库的上下文
cusparseSpMatDescr_t：稀疏矩阵描述符
cusparseDnVecDescr_t：稠密向量描述符
cusparseSpGEMMDescr_t：SpGEMM操作描述符
```

**内存管理策略**：
- 使用内存池减少分配开销
- 工作空间复用，避免重复分配
- 显式控制临时缓冲区大小
- 使用统一内存简化管理

### 22.2.2 SpMV优化技术

稀疏矩阵向量乘（SpMV）是许多算法的核心操作，其优化至关重要。

**算法选择**：
- CUSPARSE_SPMV_ALG_DEFAULT：自动选择
- CUSPARSE_SPMV_CSR_ALG1：向量化算法
- CUSPARSE_SPMV_CSR_ALG2：自适应算法
- CUSPARSE_SPMV_COO_ALG1：原子操作算法

**性能优化技巧**：

1. **预处理优化**：
   - 使用cusparseSpMV_preprocess预计算
   - 缓存预处理结果，多次使用
   - 行重排序改善负载均衡

2. **批量SpMV**：
   - 使用cusparseSpMM处理多个向量
   - 共享矩阵读取，提高带宽利用率
   - 向量打包减少内核启动开销

3. **混合精度SpMV**：
   - 矩阵用FP16，累加用FP32
   - 使用Tensor Core加速（A100+）
   - 动态范围调整防止溢出

**自定义SpMV内核**：
当cuSPARSE不能满足特定需求时，可以实现自定义内核：
- 利用矩阵特殊结构（对称、分块等）
- 融合前后处理操作
- 特定的数值精度要求
- 非标准的稀疏格式

### 22.2.3 SpMM与批量操作

稀疏矩阵矩阵乘（SpMM）在深度学习中应用广泛，特别是在图神经网络中。

**SpMM的并行策略**：
1. **行并行**：每个线程块处理稀疏矩阵的若干行
2. **列并行**：对稠密矩阵列进行分片
3. **混合并行**：结合行列并行，使用2D线程块

**优化技术**：
- 共享内存缓存稠密矩阵块
- 寄存器阻塞提高重用
- 使用纹理内存加速随机访问
- Warp级协作计算

**批量稀疏操作**：
- 批量LU分解：小矩阵批量求解
- 批量三对角求解：适用于PDE求解
- 批量稀疏三角求解：前向/后向替代

### 22.2.4 稀疏矩阵分解

**Cholesky分解**：
- 使用符号分析预计算填充模式
- 数值分解的并行化策略
- 不完全分解用于预条件子

**LU分解优化**：
- 超节点识别与合并
- 动态选主元策略
- 异步执行的任务图

**预条件子技术**：
- ILU(0)和ILU(k)的GPU实现
- 近似逆预条件子
- 多重网格预条件子

## 22.3 2:4结构化稀疏

NVIDIA Ampere架构引入了2:4结构化稀疏支持，在每4个元素中恰好有2个非零，实现了理论上2倍的计算加速。

### 22.3.1 稀疏张量核心原理

**硬件支持**：
- A100/A30/A6000的稀疏张量核心
- 自动跳过零元素的计算
- 保持与稠密张量核心相同的编程接口
- 支持FP16/BF16/TF32/INT8数据类型

**2:4稀疏模式**：
```
稠密矩阵:           2:4稀疏矩阵:
[1.2  0.5  0.8  0.3]    [1.2  0    0.8  0  ]
[0.1  0.9  0.2  0.7] -> [0    0.9  0    0.7]
[0.6  0.4  0.1  0.5]    [0.6  0.4  0    0  ]
```

**元数据编码**：
- 每4个元素用2bit编码非零位置
- 紧凑的元数据存储，开销仅12.5%
- 硬件自动解码和处理

### 22.3.2 剪枝策略

**幅度剪枝**：
- 保留每4个元素中幅度最大的2个
- 简单有效，但可能损失重要小权重
- 适用于推理场景

**梯度敏感剪枝**：
- 考虑梯度信息，保留梯度大的权重
- 更好地保持模型精度
- 计算开销较大

**结构化剪枝算法**：
```
1. 将权重矩阵reshape为(..., 4)
2. 计算重要性分数（幅度、梯度、Hessian）
3. 每组选择top-2
4. 创建mask并应用
5. 对剩余权重进行缩放补偿
```

**渐进式剪枝**：
- 从密集开始，逐步增加稀疏度
- 每个epoch增加一定比例
- 最终达到50%稀疏度（2:4模式）

### 22.3.3 重训练与微调

**稀疏感知训练**：
- 训练时应用2:4 mask
- 梯度只在非零位置更新
- 使用直通估计器（STE）处理mask梯度

**知识蒸馏**：
- 使用密集教师模型指导稀疏学生
- 特征级和logit级蒸馏结合
- 温度调节平衡硬标签和软标签

**微调策略**：
- 学习率warm-up防止突变
- 更长的训练周期恢复精度
- 层级渐进：从不敏感层开始

### 22.3.4 性能分析与优化

**理论加速比**：
- 计算：2x（跳过50%的MAC操作）
- 内存：1.78x（考虑元数据开销）
- 实际：1.5-1.9x（取决于问题规模）

**性能瓶颈分析**：
- 小矩阵受限于内核启动开销
- 内存带宽可能成为瓶颈
- 需要足够大的矩阵维度（>128）

**优化建议**：
- 矩阵维度对齐到16的倍数
- 批量大小至少为8
- 使用混合精度训练
- 融合相邻层减少内存访问

## 22.4 动态稀疏网络

动态稀疏网络在训练和推理过程中自适应地调整稀疏模式，能够在保持高稀疏度的同时维持模型精度。这种技术在自动驾驶的实时感知和具身智能的在线学习中具有重要应用。

### 22.4.1 动态稀疏的基本概念

**静态vs动态稀疏**：
- 静态稀疏：稀疏模式在训练后固定
- 动态稀疏：稀疏模式随训练/推理动态变化
- 半动态：周期性更新稀疏模式

**动态稀疏的优势**：
- 探索更大的稀疏子空间
- 自适应不同的输入分布
- 在线学习和持续适应
- 更好的精度-稀疏度权衡

**实现挑战**：
- 稀疏模式更新的计算开销
- 内存布局的动态调整
- 梯度流的正确传播
- 硬件加速的限制

### 22.4.2 稀疏模式的动态调整

**Top-K稀疏化**：
```
动态Top-K算法:
1. 前向传播时，保留每层top-k%的激活值
2. 创建动态mask记录非零位置
3. 反向传播只通过mask位置
4. 使用近似梯度处理阈值函数
```

**自适应阈值策略**：
- 百分位数阈值：保持固定稀疏率
- 绝对阈值：根据数值大小决定
- 相对阈值：基于局部统计量
- 学习型阈值：可训练的阈值参数

**稀疏模式预测**：
- 使用小型网络预测稀疏mask
- 基于输入特征的条件稀疏
- 注意力机制指导的稀疏化
- 强化学习的稀疏决策

### 22.4.3 梯度流的稀疏传播

**直通估计器（STE）**：
```
前向：y = x * mask
反向：grad_x = grad_y（忽略mask的梯度）
```

**稀疏梯度累积**：
- 使用稀疏格式存储梯度
- 原子操作累加梯度更新
- 动态索引表管理
- 延迟密集化策略

**动量和优化器状态**：
- 稀疏动量更新
- AdaGrad/Adam的稀疏变体
- 状态压缩和量化
- 周期性状态重置

### 22.4.4 RigL算法实现

RigL（Rigged Lottery）是一种高效的动态稀疏训练算法：

**核心思想**：
- 周期性移除不重要连接
- 根据梯度信息增长新连接
- 保持固定的稀疏度
- 无需密集训练初始化

**算法流程**：
```
每ΔT步执行:
1. 计算权重重要性：|w| * |∇w|
2. 移除bottom (1-α)%的连接
3. 计算潜在连接的梯度
4. 增长top (1-α)%的新连接
5. 更新稀疏拓扑
```

**CUDA实现要点**：
- 使用cub进行高效排序
- 原子操作更新连接表
- 双缓冲避免数据竞争
- 流水线化的拓扑更新

### 22.4.5 自适应稀疏推理

**输入相关稀疏**：
- 根据输入特征动态选择子网络
- 早期退出机制
- 条件计算路径
- 混合专家（MoE）架构

**运行时稀疏度调节**：
- 根据延迟要求调整稀疏度
- 功耗感知的稀疏控制
- 精度-速度动态权衡
- 多级稀疏度切换

**硬件加速考虑**：
- 利用GPU的动态并行
- 稀疏tensor core的条件使用
- 混合稀疏-密集执行
- 异步稀疏模式更新

## 22.5 案例：稀疏Transformer加速

Transformer模型的注意力机制计算复杂度为O(n²)，稀疏化是实现长序列处理的关键技术。本案例展示如何在自动驾驶的多模态融合和具身智能的序列决策中应用稀疏Transformer。

### 22.5.1 注意力机制的稀疏化

**稀疏注意力模式**：

1. **固定模式**：
   - 局部窗口注意力（窗口大小w）
   - 跨步注意力（步长s）
   - 全局token注意力
   - 组合模式：局部+全局

2. **学习型模式**：
   - 基于内容的稀疏化
   - 可微分的top-k选择
   - 路由网络决定连接
   - 注意力剪枝

**BigBird稀疏模式**：
```
注意力矩阵结构:
[L L L G . . . .]  L: 局部窗口
[L L L G . . . .]  G: 全局注意力
[L L L G . . R .]  R: 随机注意力
[G G G G G G G G]  
[. . . G L L L .]
[. . . G L L L .]
[. . R G L L L .]
[. . . G . . . .]
```

**稀疏注意力的CUDA实现**：
- 使用CSR格式存储注意力矩阵
- 分块计算减少内存占用
- 共享内存缓存Q、K、V块
- Warp级softmax归一化

### 22.5.2 Block-Sparse Patterns

**分块稀疏的优势**：
- 更好的内存访问模式
- 利用张量核心加速
- 减少索引开销
- 易于负载均衡

**块大小选择**：
- 硬件相关：16x16（Tensor Core）
- 问题相关：32x32或64x64
- 自适应：根据稀疏度调整

**分块策略**：
```
1. 将注意力矩阵分为B×B的块
2. 计算块级重要性分数
3. 选择top-k个块保留
4. 块内使用密集计算
5. 块间使用稀疏索引
```

**优化技巧**：
- 预计算块索引表
- 使用纹理内存加速索引
- 异步预取下一个块
- 双缓冲隐藏延迟

### 22.5.3 动态注意力剪枝

**在线剪枝算法**：
```
for each layer:
    1. 计算完整注意力分数（可以低精度）
    2. 估计重要性：score * gradient
    3. 动态确定阈值（保持目标稀疏度）
    4. 创建稀疏mask
    5. 重新计算稀疏注意力（高精度）
```

**渐进式剪枝**：
- 从浅层到深层逐步增加稀疏度
- 早期层保持较密集
- 后期层可以更稀疏
- 自适应层级稀疏度

**剪枝决策网络**：
- 轻量级CNN预测重要区域
- 强化学习优化剪枝策略
- 元学习快速适应
- 多任务学习共享策略

### 22.5.4 端到端性能优化

**系统级优化**：

1. **内存优化**：
   - Flash Attention的稀疏版本
   - 重计算vs存储权衡
   - 激活值压缩
   - 梯度累积优化

2. **计算优化**：
   - 算子融合减少内核启动
   - 混合精度计算
   - 异步执行流水线
   - 多流并发

3. **调度优化**：
   - 动态批处理
   - 序列长度分组
   - 负载均衡策略
   - 优先级调度

**性能评估**：
```
基准配置：
- 模型：BERT-Large (24层)
- 序列长度：4096
- 批大小：8
- GPU：A100 40GB

性能提升：
- 稠密baseline：100ms/batch
- 50%稀疏（随机）：75ms/batch（1.33x）
- 50%稀疏（结构化）：55ms/batch（1.82x）
- 75%稀疏（块稀疏）：35ms/batch（2.86x）
- 90%稀疏（动态）：25ms/batch（4.00x）
```

**自动驾驶场景应用**：
- 多相机图像的稀疏关联
- 点云序列的时序建模
- 轨迹预测的长程依赖
- 多智能体交互建模

**具身智能场景应用**：
- 视觉-语言的跨模态注意力
- 长期记忆的选择性访问
- 技能序列的组合规划
- 环境交互的因果推理

## 22.6 本章小结

本章深入探讨了CUDA中的稀疏计算技术，从传统的稀疏矩阵格式到最新的动态稀疏网络。关键要点包括：

**核心概念**：
- 稀疏矩阵格式的选择直接影响性能，CSR适合行访问，ELL适合GPU并行，COO适合极稀疏场景
- cuSPARSE提供了高度优化的稀疏运算，但理解底层原理有助于定制优化
- 2:4结构化稀疏在Ampere架构上可实现接近2倍的理论加速
- 动态稀疏网络通过自适应调整稀疏模式，在精度和性能间取得更好平衡

**关键公式**：
- 稀疏度定义：`sparsity = 1 - nnz/(m×n)`
- 2:4稀疏约束：每连续4个元素中恰好2个非零
- RigL重要性度量：`importance = |w| × |∇w|`
- 注意力复杂度：稠密O(n²) → 稀疏O(n×k)，其中k << n

**性能指标**：
- 内存节省：50-90%（取决于稀疏度）
- 计算加速：1.5-4x（取决于稀疏模式和硬件）
- 精度损失：<1%（合理的剪枝和微调）

**最佳实践**：
- 根据稀疏模式和访问模式选择合适的存储格式
- 利用硬件特性（稀疏张量核心、纹理内存等）
- 平衡稀疏度和精度，使用渐进式剪枝
- 考虑端到端优化，包括内存、计算和调度

## 22.7 练习题

### 基础题

**练习22.1：稀疏矩阵格式转换**
实现一个CUDA内核，将COO格式的稀疏矩阵转换为CSR格式。要求支持任意稀疏模式，并处理重复索引的情况。

*Hint：使用原子操作计算行指针，考虑排序的必要性*

<details>
<summary>参考答案</summary>

主要步骤：
1. 对COO格式按行列索引排序（使用thrust或cub）
2. 并行扫描计算每行的非零元素数量
3. 使用前缀和计算row_ptr数组
4. 并行复制值和列索引到CSR格式
5. 处理重复索引：累加相同位置的值

关键优化：使用共享内存缓存局部计数，减少原子操作冲突。
</details>

**练习22.2：稀疏矩阵向量乘法优化**
针对ELL格式实现一个高性能的SpMV内核，要求：
- 支持padding值的自动跳过
- 使用向量化内存访问
- 实现warp级负载均衡

*Hint：使用__ldg内在函数和float4向量化*

<details>
<summary>参考答案</summary>

优化策略：
1. 使用float4一次加载4个元素，减少内存事务
2. 每个warp处理多行，动态分配减少线程空闲
3. 使用__ldg()读取只读数据，利用L1缓存
4. padding值设为-1（无效列索引），条件跳过
5. 使用共享内存缓存向量x的常用元素

性能提升：相比naive实现可达2-3倍加速。
</details>

**练习22.3：2:4稀疏模式生成**
编写一个函数，将稠密矩阵剪枝为2:4稀疏模式，要求最小化精度损失。实现至少两种剪枝策略并比较效果。

*Hint：考虑magnitude pruning和gradient-based pruning*

<details>
<summary>参考答案</summary>

策略1（幅度剪枝）：
- 将矩阵reshape为(..., 4)
- 计算每组的绝对值
- 保留top-2，其余置零
- 对保留值进行缩放补偿：scale = 4/2

策略2（梯度敏感剪枝）：
- 计算importance = |w| × |∇w|
- 每4个元素中保留importance最大的2个
- 使用moving average平滑梯度
- 实施渐进式剪枝避免突变

比较：梯度敏感通常精度更高，但计算开销大。
</details>

### 挑战题

**练习22.4：动态稀疏网络实现**
实现一个支持RigL算法的全连接层，包括：
- 动态拓扑更新
- 稀疏前向和反向传播
- 梯度的稀疏累积

*Hint：使用双缓冲管理拓扑变化*

<details>
<summary>参考答案</summary>

实现要点：
1. 数据结构：
   - 两套索引表（当前和下一个）
   - 稀疏权重存储（CSR或COO）
   - 梯度缓冲区（密集或稀疏）

2. 拓扑更新（每ΔT步）：
   - 并行计算重要性分数
   - Top-k选择（使用cub::DeviceRadixSort）
   - 原子操作更新索引表
   - 切换缓冲区指针

3. 优化技巧：
   - 延迟排序到必要时
   - 批量更新减少同步
   - 使用CUDA Graph减少启动开销

挑战：正确处理梯度流和数值稳定性。
</details>

**练习22.5：稀疏Attention实现**
实现一个支持自定义稀疏模式的Attention层，要求：
- 支持局部窗口+全局token模式
- 实现Flash Attention的稀疏版本
- 达到相比稠密attention至少2倍加速

*Hint：分块计算+共享内存优化*

<details>
<summary>参考答案</summary>

核心算法：
1. 稀疏模式定义：
   - 局部窗口：每个token关注前后w个
   - 全局token：所有token关注前g个
   - 使用bitmap或索引表表示

2. Flash Attention稀疏化：
   - 分块大小：Br×Bc（如32×32）
   - 只计算稀疏模式覆盖的块
   - 块内使用标准Flash Attention
   - 跨块使用稀疏索引

3. 内存优化：
   - Q、K、V分块加载到共享内存
   - 在线softmax避免存储中间结果
   - 重计算vs存储的权衡

性能关键：块大小选择和稀疏模式的规则性。
</details>

**练习22.6：自动驾驶场景的稀疏3D检测**
设计并实现一个稀疏化的PointPillars 3D目标检测网络，要求：
- 点云pillar的稀疏表示
- 稀疏卷积backbone
- 动态proposal稀疏化

*Hint：利用点云的天然稀疏性*

<details>
<summary>参考答案</summary>

设计方案：
1. Pillar稀疏化：
   - 只处理非空pillar（通常<10%）
   - 使用哈希表管理pillar索引
   - 动态批处理不同密度区域

2. 稀疏卷积：
   - 使用Minkowski Engine或SpConv
   - 规则化稀疏卷积保持结构
   - 子流形稀疏卷积保持稀疏度

3. Proposal优化：
   - Top-k筛选减少proposals
   - 空间哈希加速NMS
   - 级联检测逐步细化

性能提升：相比密集版本3-5倍加速，精度损失<2% mAP。
</details>

**练习22.7：具身智能的稀疏记忆网络**
为机器人设计一个稀疏长期记忆系统，支持：
- 选择性记忆存储（重要性判断）
- 稀疏记忆检索（相关性匹配）
- 动态记忆整理（遗忘机制）

*Hint：结合注意力机制和稀疏索引*

<details>
<summary>参考答案</summary>

系统架构：
1. 记忆编码：
   - 使用Transformer编码经验
   - 计算重要性分数（新颖性、奖励、不确定性）
   - 稀疏存储：只保留top-k%重要记忆

2. 检索机制：
   - 查询编码与记忆库匹配
   - 使用LSH或学习的哈希加速
   - 稀疏注意力聚合相关记忆

3. 动态管理：
   - 基于访问频率的LRU策略
   - 记忆压缩：相似记忆合并
   - 分层存储：近期密集，远期稀疏

实现挑战：平衡记忆容量、检索速度和信息保持。
</details>

## 22.8 常见陷阱与错误

### 稀疏格式选择错误
**问题**：盲目使用CSR格式，忽视访问模式
**症状**：性能低于预期，甚至不如稠密计算
**解决**：profile分析访问模式，选择合适格式

### 负载不均衡
**问题**：稀疏分布不均导致线程空闲
**症状**：GPU利用率低，kernel时间长
**解决**：动态负载均衡，自适应线程分配

### 原子操作竞争
**问题**：COO格式SpMV的原子加法冲突
**症状**：性能随稀疏度降低而急剧下降
**解决**：排序优化、分段处理、使用其他格式

### 内存访问不合并
**问题**：稀疏索引导致随机内存访问
**症状**：内存带宽利用率极低
**解决**：数据重排、缓存优化、向量化访问

### 数值稳定性问题
**问题**：稀疏化导致梯度消失或爆炸
**症状**：训练不收敛，精度严重下降
**解决**：渐进式稀疏化、正则化、梯度裁剪

### 动态稀疏开销
**问题**：频繁的拓扑更新开销超过收益
**症状**：训练速度反而变慢
**解决**：增大更新间隔、批量更新、异步更新

### 硬件兼容性
**问题**：使用了特定架构的稀疏特性
**症状**：旧GPU上性能差或功能失效
**解决**：运行时检测、提供fallback实现

### 精度损失过大
**问题**：过度稀疏化损害模型性能
**症状**：推理精度不可接受
**解决**：layer-wise稀疏度、知识蒸馏、微调

## 22.9 最佳实践检查清单

### 设计阶段
- [ ] 分析稀疏模式特征（稀疏度、分布、规则性）
- [ ] 评估不同稀疏格式的适用性
- [ ] 确定精度-性能权衡目标
- [ ] 考虑硬件特性和限制
- [ ] 设计fallback方案

### 实现阶段
- [ ] 使用合适的稀疏库（cuSPARSE、CUTLASS等）
- [ ] 实现高效的格式转换
- [ ] 优化内存访问模式
- [ ] 处理负载均衡问题
- [ ] 实现数值稳定性保护

### 优化阶段
- [ ] Profile识别性能瓶颈
- [ ] 尝试不同的并行策略
- [ ] 融合相邻的稀疏操作
- [ ] 使用混合精度计算
- [ ] 优化稀疏模式更新频率

### 验证阶段
- [ ] 测试不同稀疏度下的性能
- [ ] 验证数值精度
- [ ] 检查内存使用
- [ ] 测试边界条件
- [ ] 基准测试对比

### 部署阶段
- [ ] 选择合适的稀疏度级别
- [ ] 配置动态稀疏参数
- [ ] 监控运行时性能
- [ ] 准备性能调优接口
- [ ] 文档化性能特征