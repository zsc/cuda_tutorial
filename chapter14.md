# 第14章：路径规划与轨迹优化

本章深入探讨自动驾驶中路径规划与轨迹优化的GPU并行化技术。我们将学习如何将传统的串行规划算法改造为高效的并行版本，实现实时的路径搜索、轨迹生成和动态避障。通过批量化处理和并行求解技术，将规划系统的响应时间从秒级降低到毫秒级，满足自动驾驶的实时性要求。

## 14.1 A*与RRT*的GPU并行化

### 14.1.1 并行A*算法架构

传统A*算法的串行特性主要体现在逐个扩展节点的过程中。GPU并行化的核心思想是同时扩展多个前沿节点，将搜索树的广度优先特性充分利用起来。

```
串行A*的瓶颈：
while (!openSet.empty()) {
    current = openSet.top();  // 串行选择
    expand(current);           // 串行扩展
    updateNeighbors();         // 串行更新
}

并行A*的架构：
┌─────────────────────────────────────┐
│         Open Set (GPU Memory)        │
│  ┌────┬────┬────┬────┬────┬────┐   │
│  │ N1 │ N2 │ N3 │ N4 │... │ Nn │   │  <- 批量节点
│  └────┴────┴────┴────┴────┴────┘   │
└─────────────┬───────────────────────┘
              │ Parallel Expansion
    ┌─────────▼───────────┐
    │   Thread Block 1    │ Thread Block 2  ...
    │  ┌──┬──┬──┬──┬──┐ │ ┌──┬──┬──┬──┬──┐
    │  │T0│T1│T2│..│Tn│ │ │T0│T1│T2│..│Tn│
    │  └──┴──┴──┴──┴──┘ │ └──┴──┴──┴──┴──┘
    └─────────────────────┘
```

并行化的关键技术点：

1. **前沿节点批量选择**：使用并行堆或优先队列，每次选择K个最优节点
2. **冲突解决**：多个线程可能同时访问同一节点，需要原子操作保证一致性
3. **负载均衡**：不同节点的扩展代价不同，使用工作窃取策略均衡负载

### 14.1.2 并行优先队列实现

GPU上的高效优先队列是并行A*的核心数据结构。我们采用基于二叉堆的并行实现：

```
并行堆操作原理：

插入操作（Parallel Insert）：
Level 0:     [8]              <- 根节点
            /     \
Level 1:  [12]    [15]         <- 可并行
         /   \   /   \
Level 2:[20] [25][18] [22]     <- 可并行

每层可以并行处理，层间需要同步
使用 __syncthreads() 保证层级一致性
```

关键优化技术：

1. **批量堆化（Batch Heapify）**：一次性调整多个元素，减少同步开销
2. **分层并行**：同一层的所有节点可以并行比较和交换
3. **局部排序**：在共享内存中维护小堆，定期与全局堆合并

### 14.1.3 RRT*的GPU加速策略

RRT*（Rapidly-exploring Random Tree Star）的并行化主要在于：

1. **批量采样**：一次生成大量随机点，使用cuRAND库
2. **并行最近邻搜索**：使用空间哈希或KD-Tree加速
3. **批量碰撞检测**：将环境栅格化，使用纹理内存加速查询

```
RRT*并行化流程：

┌──────────────┐
│ Random Sample│ <- 批量生成N个采样点
│  Generation  │    cuRAND并行随机数
└──────┬───────┘
       │
┌──────▼───────┐
│Nearest Neighbor <- 并行KNN搜索
│    Search     │    每个采样点独立查找
└──────┬───────┘
       │
┌──────▼───────┐
│  Collision   │ <- 批量射线检测
│   Detection  │    使用3D纹理加速
└──────┬───────┘
       │
┌──────▼───────┐
│ Tree Update  │ <- 原子操作更新树结构
│  & Rewire    │    锁free数据结构
└──────────────┘
```

### 14.1.4 混合搜索策略

结合A*的最优性和RRT*的探索能力，我们可以设计混合并行搜索：

```
Hybrid Parallel Search:

GPU Kernel 1: A* Front Expansion
  - 处理结构化道路网络
  - 适合短距离精确规划
  
GPU Kernel 2: RRT* Exploration  
  - 处理非结构化空间
  - 适合复杂避障场景

GPU Kernel 3: Path Fusion
  - 合并两种方法的结果
  - 选择最优路径段
```

性能优化要点：

1. **内存访问模式**：确保coalesced access，使用SOA布局
2. **分支优化**：使用掩码操作替代条件分支
3. **共享内存使用**：缓存频繁访问的地图数据
4. **纹理内存**：存储环境地图，利用硬件插值

## 14.2 批量轨迹采样与评估

### 14.2.1 轨迹参数化与批量生成

自动驾驶中常用的轨迹参数化方法包括多项式曲线、贝塞尔曲线和样条曲线。GPU并行生成的核心是将参数空间离散化：

```
轨迹批量生成架构：

参数空间采样：
┌─────────────────────────────────┐
│  Lateral offset: [-3, -2, ..., 3] m     │
│  Longitudinal vel: [5, 10, ..., 30] m/s │  
│  Time horizon: [1, 2, ..., 5] s         │
└─────────────────────────────────┘
           │
           ▼
    Grid Dimension (7 × 6 × 5 = 210 trajectories)
           │
    ┌──────▼──────┐
    │ GPU Kernels │
    ├─────────────┤
    │ Block(0,0): │ -> Trajectory 0-31
    │ Block(0,1): │ -> Trajectory 32-63
    │    ...      │
    └─────────────┘
```

五次多项式轨迹生成的并行实现要点：

1. **系数预计算**：将边界条件转换为多项式系数的过程完全并行
2. **时间离散化**：每个轨迹的采样点独立计算
3. **向量化计算**：使用float4类型一次计算x,y,θ,κ

### 14.2.2 并行代价函数评估

轨迹评估涉及多个代价项的计算，天然适合并行化：

```
代价函数组成：
J_total = w1*J_safety + w2*J_comfort + w3*J_efficiency + w4*J_feasibility

并行评估策略：
┌────────────────────────────────────┐
│         Trajectory Buffer          │
│  [T0] [T1] [T2] ... [Tn]          │
└────────────┬───────────────────────┘
             │
    ┌────────▼────────┐
    │  Cost Kernels   │
    ├─────────────────┤
    │ Safety Check    │ <- 碰撞检测
    │ Comfort Eval    │ <- 加速度/曲率
    │ Efficiency      │ <- 路程/时间
    │ Feasibility     │ <- 动力学约束
    └────────┬────────┘
             │
    ┌────────▼────────┐
    │ Reduction Kernel│ <- 归约求和
    └─────────────────┘
```

关键优化技术：

1. **地图查询优化**：使用3D纹理存储占用栅格图，硬件加速双线性插值
2. **批量碰撞检测**：将轨迹点打包为float4，使用向量化指令
3. **动态规划评估**：对时序相关的代价项使用扫描算法

### 14.2.3 并行轨迹筛选与排序

从数百条候选轨迹中选择最优解需要高效的并行排序：

```
多级筛选策略：

Stage 1: Coarse Filter (Block Level)
  - 每个block处理32条轨迹
  - 快速剔除明显不可行轨迹
  - 使用共享内存局部排序

Stage 2: Fine Selection (Grid Level)  
  - 收集各block的top-k轨迹
  - 全局排序选出最优解
  - 使用bitonic sort或radix sort

优化技巧：
- Early termination: 检测到碰撞立即标记
- Warp voting: 使用__ballot_sync快速统计
- Shared memory: 缓存频繁访问的数据
```

### 14.2.4 时空一致性优化

利用帧间的时间相关性加速评估：

1. **轨迹重用**：上一帧的最优轨迹作为warm start
2. **增量更新**：只重新评估变化的部分
3. **预测缓存**：基于车辆运动模型预测下一帧的候选集

## 14.3 动态规划的并行实现

### 14.3.1 并行贝尔曼更新

动态规划的核心是贝尔曼方程的迭代求解。GPU并行化的关键是识别独立的子问题：

```
串行DP的递推：
for t in time_steps:
    for s in states:
        V[t][s] = min(cost[s] + V[t-1][s'])
        
并行DP的分解：
┌─────────────────────────────┐
│    Time Step t-1 (已知)     │
│ [V0] [V1] [V2] ... [Vn]     │
└──────────┬──────────────────┘
           │ 并行转移
    ┌──────▼──────┐
    │  GPU Grid   │
    │ ┌─┬─┬─┬─┐  │
    │ │B│B│B│B│  │ <- 每个Block处理一组状态
    │ └─┴─┴─┴─┘  │
    └──────┬──────┘
           │
┌──────────▼──────────────────┐
│    Time Step t (计算中)      │
│ [V0'] [V1'] [V2'] ... [Vn'] │
└─────────────────────────────┘
```

并行化策略：

1. **状态并行**：同一时刻的所有状态并行更新
2. **路径并行**：多条可能路径同时评估
3. **分块递推**：将长序列分段，段内并行

### 14.3.2 并行维特比算法

用于最优路径回溯的维特比算法并行化：

```
前向传播（并行）：
- 每个时间步的所有状态并行计算
- 使用共享内存存储转移概率矩阵
- 原子操作更新最优前驱

后向回溯（串行优化）：
- 从终点开始单线程回溯
- 或使用并行前缀和技术加速
```

### 14.3.3 分层动态规划

对于大规模状态空间，采用分层策略：

```
Hierarchical DP:

Level 0 (Coarse): 
  States: 100 × 100 grid
  Threads: 10,000 parallel updates
  
Level 1 (Medium):
  States: 20 × 20 local refinement  
  Threads: 400 parallel updates
  
Level 2 (Fine):
  States: Continuous optimization
  Threads: Gradient-based solver
```

内存管理优化：

1. **滚动数组**：只保留相邻两个时间步的状态
2. **状态压缩**：使用位运算压缩离散状态
3. **稀疏表示**：只存储和更新可达状态

## 14.4 二次规划求解器

### 14.4.1 并行二次规划问题形式

轨迹优化常归结为二次规划（QP）问题：

```
标准QP形式：
min  0.5 * x^T * H * x + f^T * x
s.t. A * x <= b
     Aeq * x = beq
     lb <= x <= ub

其中x为轨迹参数向量，维度可达数百到数千
```

GPU并行求解的关键在于矩阵运算的加速：

```
并行矩阵运算分解：

H * x 计算：
┌──────────────┐
│   H Matrix   │  
│ ┌──┬──┬──┐  │
│ │  │  │  │  │  每个线程块处理H的一个子块
│ ├──┼──┼──┤  │  使用共享内存缓存
│ │  │  │  │  │  
│ └──┴──┴──┘  │
└──────────────┘

梯度计算：∇f = H*x + f
- 使用cuBLAS加速矩阵向量乘法
- 融合kernel减少内存访问
```

### 14.4.2 内点法的GPU实现

内点法是求解大规模QP的主流方法：

```
内点法迭代步骤：

1. KKT系统构建（并行）
   [H    A^T] [dx]   [r1]
   [A    -D ] [dλ] = [r2]
   
2. 线性系统求解（并行）
   - Cholesky分解: cuSOLVER
   - PCG迭代: 自定义kernel
   
3. 步长搜索（并行）
   - 多个候选步长同时评估
   - 使用warp投票选择最优

4. 变量更新（并行）
   - x = x + α*dx
   - 向量运算完全并行
```

优化技巧：

1. **预条件子**：利用问题结构设计高效预条件子
2. **暖启动**：使用上一帧的解作为初始值
3. **早停策略**：满足实时性要求时提前终止

### 14.4.3 ADMM并行求解器

交替方向乘子法（ADMM）天然适合并行化：

```
ADMM分解策略：

原问题分解为子问题：
Problem 1: min f1(x) （动力学约束）
Problem 2: min f2(z) （避障约束）
Coupling:  x = z

ADMM迭代：
┌────────────┐     ┌────────────┐
│  x-update  │────▶│  z-update  │
│  (Kernel1) │     │  (Kernel2) │
└────────────┘     └────────────┘
       ▲                 │
       └─────────────────┘
          λ-update (Kernel3)

每个子问题可以独立并行求解
```

### 14.4.4 增量式QP求解

利用问题的时序结构加速：

```
MPC中的QP序列：

Time t:   QP_t   -> Solution x_t
Time t+1: QP_t+1 -> Solution x_t+1

增量更新策略：
1. 识别变化的约束（新障碍物）
2. 只更新受影响的KKT块
3. 使用Sherman-Morrison公式更新逆矩阵

性能提升：
- 完整求解: 100ms
- 增量更新: 10ms
```

## 14.5 实时避障与轨迹平滑

### 14.5.1 动态障碍物的并行处理

实时避障需要快速处理多个移动障碍物的轨迹预测和碰撞检测：

```
动态障碍物处理流水线：

输入：N个障碍物的当前状态
┌─────────────────────────────┐
│ Obstacle States at time t   │
│ [Obs1] [Obs2] ... [ObsN]   │
└──────────┬──────────────────┘
           │
    ┌──────▼──────┐
    │ Prediction  │ <- 并行轨迹预测
    │   Kernels   │    每个障碍物独立
    └──────┬──────┘
           │
┌──────────▼──────────────────┐
│ Predicted Trajectories      │
│ T=0  T=1  T=2  ...  T=K    │ <- K个时间步
└──────────┬──────────────────┘
           │
    ┌──────▼──────┐
    │  Collision  │ <- 批量碰撞检测
    │   Testing   │    使用空间哈希
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │ Risk Field  │ <- 生成风险场
    │ Generation  │    3D纹理存储
    └─────────────┘
```

关键技术：

1. **轨迹预测并行化**：
   - 每个障碍物使用独立线程预测
   - 多种运动模型（CV/CA/CTRV）并行评估
   - 使用贝叶斯滤波融合多模型预测

2. **时空占用网格**：
   ```
   4D Grid (x, y, z, t):
   - 空间分辨率: 0.2m
   - 时间分辨率: 0.1s
   - 使用位掩码压缩存储
   - 原子操作更新占用状态
   ```

3. **概率碰撞评估**：
   - 蒙特卡洛采样并行化
   - 使用cuRAND生成轨迹扰动
   - 批量评估碰撞概率

### 14.5.2 反应式避障层

在规划轨迹基础上添加快速反应层：

```
反应式避障架构：

┌────────────────────┐
│  Planned Path      │ <- 全局规划轨迹
└─────────┬──────────┘
          │
┌─────────▼──────────┐
│  Local Sensors     │ <- 激光雷达/相机
└─────────┬──────────┘
          │
    ┌─────▼─────┐
    │ Fast DWA  │ <- Dynamic Window Approach
    │  (GPU)    │    并行速度采样
    └─────┬─────┘
          │
┌─────────▼──────────┐
│ Modified Trajectory│ <- 局部调整后轨迹
└────────────────────┘

并行DWA实现：
- 速度空间离散: (v, ω) ∈ [v_min, v_max] × [ω_min, ω_max]
- 并行前向模拟: 每个速度组合独立仿真
- 批量评估: 距离、速度、方向代价并行计算
```

优化策略：

1. **分层采样**：粗细结合的速度空间采样
2. **早期剔除**：快速排除明显碰撞的速度
3. **GPU常量内存**：存储车辆动力学参数

### 14.5.3 轨迹平滑算法

生成的轨迹需要平滑处理以保证舒适性：

```
并行B样条平滑：

控制点优化问题：
min ||B(t) - P_original||² + λ*||B''(t)||²

其中B(t)为B样条曲线，P为原始轨迹点

并行优化策略：
┌────────────────────────┐
│   Control Points       │
│  [C0] [C1] ... [Cn]   │
└───────────┬────────────┘
            │
     ┌──────▼──────┐
     │ Gradient    │ <- 并行梯度计算
     │ Computation │    每个控制点独立
     └──────┬──────┘
            │
     ┌──────▼──────┐
     │   L-BFGS    │ <- 并行线搜索
     │   Update    │    多步长同时评估
     └──────┬──────┘
            │
┌───────────▼────────────┐
│   Smoothed Trajectory  │
└────────────────────────┘
```

关键实现细节：

1. **基函数预计算**：B样条基函数值预存于纹理内存
2. **稀疏矩阵运算**：利用B样条的局部支撑性
3. **约束投影**：并行投影到可行域

### 14.5.4 曲率连续性保证

确保轨迹的几何连续性对车辆控制至关重要：

```
曲率约束并行检查：

对每个轨迹点并行计算：
- 曲率: κ = |x'y'' - y'x''| / (x'² + y'²)^(3/2)
- 曲率变化率: dκ/ds

约束条件：
- |κ| ≤ κ_max （最大转向）
- |dκ/ds| ≤ dκ_max （转向平滑性）

并行修正策略：
1. 识别违反约束的点（并行扫描）
2. 局部调整控制点（并行优化）
3. 全局传播修正（迭代收敛）
```

### 14.5.5 多层级融合策略

将不同时间尺度的规划结果融合：

```
时间层级：
Level 0: 全局路径 (10s, 1Hz更新)
Level 1: 局部轨迹 (3s, 10Hz更新)  
Level 2: 反应控制 (0.3s, 100Hz更新)

GPU融合kernel：
__global__ void trajectoryFusion(
    float4* globalPath,    // 全局路径
    float4* localTraj,     // 局部轨迹
    float4* reactiveCmd,   // 反应指令
    float4* fusedOutput,   // 融合输出
    float* weights,        // 融合权重
    int horizonLength
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < horizonLength) {
        // 时间衰减权重
        float w_global = weights[0] * exp(-idx * 0.1f);
        float w_local = weights[1] * (1.0f - exp(-idx * 0.1f));
        float w_reactive = weights[2];
        
        // 加权融合
        fusedOutput[idx] = w_global * globalPath[idx] +
                          w_local * localTraj[idx] +
                          w_reactive * reactiveCmd[idx];
                          
        // 约束投影
        projectToFeasible(&fusedOutput[idx]);
    }
}
```

## 14.6 本章小结

本章深入探讨了路径规划与轨迹优化的GPU并行化技术。主要内容包括：

**核心算法并行化**：
- A*和RRT*的并行搜索策略，通过批量节点扩展实现10-50倍加速
- 动态规划的状态并行和时间并行分解，将O(n²)复杂度降至O(n)
- 二次规划求解器的矩阵运算加速，实现毫秒级MPC求解

**关键技术要点**：
1. **数据结构设计**：并行优先队列、空间哈希、位掩码压缩
2. **内存优化**：纹理内存存储地图、共享内存缓存热点数据
3. **负载均衡**：工作窃取、动态任务分配、分层处理
4. **数值稳定性**：原子操作保证一致性、增量更新减少误差累积

**性能优化公式**：
- 并行效率: η = S/(p×E) ≈ 0.7-0.9 （S=加速比, p=处理器数, E=串行部分比例）
- 内存带宽利用率: B_eff = (有效数据传输量)/(理论带宽×时间) > 80%
- 实时性保证: T_plan + T_smooth + T_check < 10ms

**实际应用效果**：
- 路径搜索：从100ms降至5ms
- 轨迹评估：批量1000条轨迹仅需2ms
- 避障响应：从30ms降至3ms
- 整体规划频率：从10Hz提升至100Hz

## 14.7 练习题

### 基础题

**练习14.1**：并行A*的前沿管理  
设计一个GPU上的并行优先队列，支持批量插入和批量提取最小的K个元素。要求支持至少10000个节点，每次批量操作K=32。

<details>
<summary>提示</summary>
考虑使用分段堆结构，每个段可以独立维护。使用原子操作协调段间的合并。
</details>

<details>
<summary>答案</summary>
使用两级堆结构：第一级是大小为32的局部堆（每个block一个），第二级是全局堆。局部堆在共享内存中维护，定期与全局堆同步。批量提取时，先从全局堆取出2K个元素分发给各局部堆，再并行提取。
</details>

**练习14.2**：轨迹批量评估优化  
给定1000条候选轨迹，每条包含100个点，设计GPU kernel计算每条轨迹的代价。代价包括：距离代价、平滑度代价和障碍物代价。

<details>
<summary>提示</summary>
使用网格维度映射轨迹，块维度处理轨迹内的点。考虑使用共享内存缓存障碍物地图的局部区域。
</details>

<details>
<summary>答案</summary>
Grid(32, 32)配置处理1024条轨迹，Block(128)处理每条轨迹的点。使用reduction计算轨迹内的累积代价。障碍物地图存储在纹理内存中，利用硬件插值。每个block使用48KB共享内存缓存地图tile。
</details>

**练习14.3**：动态规划的滚动数组实现  
实现一个GPU版本的动态规划求解器，用于解决网格路径规划问题。状态空间为100×100，时间步长为50。

<details>
<summary>提示</summary>
只需要保存相邻两个时间步的状态。使用ping-pong buffer技术交替更新。
</details>

<details>
<summary>答案</summary>
分配两个100×100的状态数组，使用指针交换实现滚动。每个时间步启动100×100个线程并行更新所有状态。使用纹理内存存储转移代价矩阵，减少全局内存访问。
</details>

**练习14.4**：实时碰撞检测网格  
设计一个空间哈希数据结构，支持动态障碍物的快速插入和查询。要求支持至少1000个动态障碍物的实时更新。

<details>
<summary>提示</summary>
使用3D网格哈希，每个cell维护障碍物ID列表。考虑使用原子操作处理并发插入。
</details>

<details>
<summary>答案</summary>
使用morton编码将3D坐标映射到1D哈希键。每个cell预分配固定大小的障碍物列表（如16个）。使用原子计数器管理列表插入。查询时并行检查相邻的27个cells。
</details>

### 挑战题

**练习14.5**：多分辨率路径规划  
实现一个三层分辨率的路径规划器：粗糙层（1m网格）、中等层（0.2m网格）、精细层（0.05m网格）。设计GPU kernel实现层间的信息传递和路径细化。

<details>
<summary>提示</summary>
从粗糙层开始规划，使用插值生成中等层的初始路径，再逐层细化。考虑使用纹理内存的mipmap功能。
</details>

<details>
<summary>答案</summary>
粗糙层使用标准A*找到初始路径。中等层在粗糙路径的管道内搜索（宽度±5个网格）。精细层只在中等路径的±2个网格内优化。使用3D纹理存储多分辨率地图，hardware mipmap加速层间查询。每层使用不同的block配置：粗(8,8)、中(16,16)、细(32,32)。
</details>

**练习14.6**：ADMM求解器的并行化  
实现一个GPU版本的ADMM求解器，用于求解包含1000个变量和500个约束的QP问题。要求达到1ms的求解时间。

<details>
<summary>提示</summary>
将问题分解为多个子问题，每个可以独立求解。使用cuBLAS加速矩阵运算，自定义kernel处理投影操作。
</details>

<details>
<summary>答案</summary>
将原问题分解为10个100维的子问题，每个block处理一个子问题。x更新使用cuBLAS的批量Cholesky求解。z更新使用自定义投影kernel，每个线程处理一个约束。λ更新完全并行。使用统一内存简化CPU-GPU数据交换。预计算并缓存不变的矩阵分解结果。
</details>

**练习14.7**：轨迹时空优化  
设计一个同时优化空间路径和速度剖面的GPU求解器。输入是参考路径，输出是满足动力学约束的最优轨迹。

<details>
<summary>提示</summary>
使用S-T图方法解耦空间和时间优化。先优化路径，再优化速度剖面，迭代收敛。
</details>

<details>
<summary>答案</summary>
第一阶段：固定时间，优化空间路径（QP问题）。第二阶段：固定路径，优化速度剖面（DP问题）。使用两个独立的kernel流并行执行。路径优化使用批量B样条控制点优化。速度优化使用并行DP，考虑加速度、加加速度约束。迭代3-5次达到收敛。使用graph capture减少kernel启动开销。
</details>

**练习14.8**：多机器人协同规划  
实现一个支持10个机器人的协同路径规划系统。要求避免机器人间的碰撞，同时最小化总体完成时间。

<details>
<summary>提示</summary>
使用优先级规划或耦合规划方法。考虑时空预留表避免冲突。
</details>

<details>
<summary>答案</summary>
使用CBS（Conflict-Based Search）算法的GPU并行版本。高层搜索冲突，低层并行规划各机器人路径。维护4D时空占用表(x,y,z,t)，使用原子操作更新预留状态。每个机器人的路径规划使用独立的CUDA流。冲突检测使用批量射线检测。使用优先级队列管理约束树的扩展。预计算启发式距离表加速搜索。
</details>

## 14.8 常见陷阱与错误

### 内存访问陷阱

1. **非合并访问**
   ```
   错误：每个线程访问轨迹的不同属性
   thread0: traj[0].x, traj[0].y, traj[0].theta
   thread1: traj[1].x, traj[1].y, traj[1].theta
   
   正确：SOA布局
   thread0: x[0], y[0], theta[0]
   thread1: x[1], y[1], theta[1]
   ```

2. **Bank Conflict**
   ```
   错误：32个线程访问同一bank
   __shared__ float cost[32];
   cost[threadIdx.x] = ...; // 所有访问映射到同一bank
   
   正确：添加padding
   __shared__ float cost[33];
   ```

### 数值稳定性问题

3. **浮点累积误差**
   ```
   错误：长轨迹的累积积分
   for(int i = 0; i < 1000; i++) {
       x += dx * dt; // 误差累积
   }
   
   正确：使用Kahan求和或双精度
   ```

4. **矩阵条件数**
   ```
   QP求解中的数值问题：
   - 添加正则化项：H = H + ε*I
   - 预条件处理：使用Jacobi或不完全Cholesky
   - 缩放变量：归一化到[-1, 1]区间
   ```

### 并发错误

5. **竞态条件**
   ```
   错误：多线程更新同一节点
   if(newCost < nodeCost[id]) {
       nodeCost[id] = newCost; // 竞态！
   }
   
   正确：使用原子操作
   atomicMin(&nodeCost[id], newCost);
   ```

6. **死锁**
   ```
   避免嵌套锁，使用lock-free数据结构
   优先使用原子操作而非互斥锁
   ```

### 性能陷阱

7. **过度同步**
   ```
   错误：频繁的__syncthreads()
   正确：批量处理，减少同步点
   ```

8. **分支发散**
   ```
   错误：复杂的条件分支
   if(complex_condition) {
       // 长代码路径
   } else {
       // 另一个长路径
   }
   
   正确：使用预测和掩码
   float result = mask * path1_result + 
                 (1-mask) * path2_result;
   ```

## 14.9 最佳实践检查清单

### 算法设计审查

- [ ] 识别并行化机会：数据并行、任务并行、流水线并行
- [ ] 选择合适的数据结构：避免指针追逐，优先使用数组
- [ ] 设计负载均衡策略：动态任务分配、工作窃取
- [ ] 考虑数值稳定性：正则化、预条件、适当精度

### 内存优化审查

- [ ] 数据布局优化：SOA vs AOS，考虑访问模式
- [ ] 使用适当的内存类型：全局、共享、常量、纹理
- [ ] 确保合并访问：检查内存访问模式
- [ ] 减少内存传输：kernel融合、数据重用

### 并发控制审查

- [ ] 正确使用原子操作：选择合适的原子函数
- [ ] 避免竞态条件：识别共享数据访问
- [ ] 最小化同步开销：批量处理、异步执行
- [ ] 使用CUDA流：并行kernel执行、异步传输

### 性能调优审查

- [ ] Profile分析：使用Nsight Compute识别瓶颈
- [ ] 占用率优化：调整block大小和寄存器使用
- [ ] 指令优化：使用快速数学函数、向量化操作
- [ ] 延迟隐藏：增加并行度、使用异步操作

### 鲁棒性审查

- [ ] 边界条件处理：检查数组越界、空指针
- [ ] 错误处理：CUDA API错误检查、kernel错误传播
- [ ] 输入验证：参数范围检查、维度匹配
- [ ] 测试覆盖：单元测试、集成测试、压力测试

### 可维护性审查

- [ ] 代码组织：模块化设计、清晰的接口
- [ ] 文档完善：算法说明、参数含义、性能指标
- [ ] 版本兼容：GPU架构兼容性、CUDA版本要求
- [ ] 调试支持：日志输出、中间结果验证