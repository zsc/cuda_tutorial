# 第14章：路径规划与轨迹优化

本章深入探讨自动驾驶中路径规划与轨迹优化的GPU并行化技术。我们将学习如何将传统的串行规划算法改造为高效的并行版本，实现实时的路径搜索、轨迹生成和动态避障。通过批量化处理和并行求解技术，将规划系统的响应时间从秒级降低到毫秒级，满足自动驾驶的实时性要求。

## 14.1 A*与RRT*的GPU并行化

### 14.1.1 并行A*算法架构

传统A*算法的串行特性主要体现在逐个扩展节点的过程中。GPU并行化的核心思想是同时扩展多个前沿节点，将搜索树的广度优先特性充分利用起来。

```
串行A*的瓶颈：
while (!openSet.empty()) {
    current = openSet.top();  // 串行选择
    expand(current);           // 串行扩展
    updateNeighbors();         // 串行更新
}

并行A*的架构：
┌─────────────────────────────────────┐
│         Open Set (GPU Memory)        │
│  ┌────┬────┬────┬────┬────┬────┐   │
│  │ N1 │ N2 │ N3 │ N4 │... │ Nn │   │  <- 批量节点
│  └────┴────┴────┴────┴────┴────┘   │
└─────────────┬───────────────────────┘
              │ Parallel Expansion
    ┌─────────▼───────────┐
    │   Thread Block 1    │ Thread Block 2  ...
    │  ┌──┬──┬──┬──┬──┐ │ ┌──┬──┬──┬──┬──┐
    │  │T0│T1│T2│..│Tn│ │ │T0│T1│T2│..│Tn│
    │  └──┴──┴──┴──┴──┘ │ └──┴──┴──┴──┴──┘
    └─────────────────────┘
```

并行化的关键技术点：

1. **前沿节点批量选择**：使用并行堆或优先队列，每次选择K个最优节点
2. **冲突解决**：多个线程可能同时访问同一节点，需要原子操作保证一致性
3. **负载均衡**：不同节点的扩展代价不同，使用工作窃取策略均衡负载

### 14.1.2 并行优先队列实现

GPU上的高效优先队列是并行A*的核心数据结构。我们采用基于二叉堆的并行实现：

```
并行堆操作原理：

插入操作（Parallel Insert）：
Level 0:     [8]              <- 根节点
            /     \
Level 1:  [12]    [15]         <- 可并行
         /   \   /   \
Level 2:[20] [25][18] [22]     <- 可并行

每层可以并行处理，层间需要同步
使用 __syncthreads() 保证层级一致性
```

关键优化技术：

1. **批量堆化（Batch Heapify）**：一次性调整多个元素，减少同步开销
2. **分层并行**：同一层的所有节点可以并行比较和交换
3. **局部排序**：在共享内存中维护小堆，定期与全局堆合并

### 14.1.3 RRT*的GPU加速策略

RRT*（Rapidly-exploring Random Tree Star）的并行化主要在于：

1. **批量采样**：一次生成大量随机点，使用cuRAND库
2. **并行最近邻搜索**：使用空间哈希或KD-Tree加速
3. **批量碰撞检测**：将环境栅格化，使用纹理内存加速查询

```
RRT*并行化流程：

┌──────────────┐
│ Random Sample│ <- 批量生成N个采样点
│  Generation  │    cuRAND并行随机数
└──────┬───────┘
       │
┌──────▼───────┐
│Nearest Neighbor <- 并行KNN搜索
│    Search     │    每个采样点独立查找
└──────┬───────┘
       │
┌──────▼───────┐
│  Collision   │ <- 批量射线检测
│   Detection  │    使用3D纹理加速
└──────┬───────┘
       │
┌──────▼───────┐
│ Tree Update  │ <- 原子操作更新树结构
│  & Rewire    │    锁free数据结构
└──────────────┘
```

### 14.1.4 混合搜索策略

结合A*的最优性和RRT*的探索能力，我们可以设计混合并行搜索：

```
Hybrid Parallel Search:

GPU Kernel 1: A* Front Expansion
  - 处理结构化道路网络
  - 适合短距离精确规划
  
GPU Kernel 2: RRT* Exploration  
  - 处理非结构化空间
  - 适合复杂避障场景

GPU Kernel 3: Path Fusion
  - 合并两种方法的结果
  - 选择最优路径段
```

性能优化要点：

1. **内存访问模式**：确保coalesced access，使用SOA布局
2. **分支优化**：使用掩码操作替代条件分支
3. **共享内存使用**：缓存频繁访问的地图数据
4. **纹理内存**：存储环境地图，利用硬件插值

## 14.2 批量轨迹采样与评估

### 14.2.1 轨迹参数化与批量生成

自动驾驶中常用的轨迹参数化方法包括多项式曲线、贝塞尔曲线和样条曲线。GPU并行生成的核心是将参数空间离散化：

```
轨迹批量生成架构：

参数空间采样：
┌─────────────────────────────────┐
│  Lateral offset: [-3, -2, ..., 3] m     │
│  Longitudinal vel: [5, 10, ..., 30] m/s │  
│  Time horizon: [1, 2, ..., 5] s         │
└─────────────────────────────────┘
           │
           ▼
    Grid Dimension (7 × 6 × 5 = 210 trajectories)
           │
    ┌──────▼──────┐
    │ GPU Kernels │
    ├─────────────┤
    │ Block(0,0): │ -> Trajectory 0-31
    │ Block(0,1): │ -> Trajectory 32-63
    │    ...      │
    └─────────────┘
```

五次多项式轨迹生成的并行实现要点：

1. **系数预计算**：将边界条件转换为多项式系数的过程完全并行
2. **时间离散化**：每个轨迹的采样点独立计算
3. **向量化计算**：使用float4类型一次计算x,y,θ,κ

### 14.2.2 并行代价函数评估

轨迹评估涉及多个代价项的计算，天然适合并行化：

```
代价函数组成：
J_total = w1*J_safety + w2*J_comfort + w3*J_efficiency + w4*J_feasibility

并行评估策略：
┌────────────────────────────────────┐
│         Trajectory Buffer          │
│  [T0] [T1] [T2] ... [Tn]          │
└────────────┬───────────────────────┘
             │
    ┌────────▼────────┐
    │  Cost Kernels   │
    ├─────────────────┤
    │ Safety Check    │ <- 碰撞检测
    │ Comfort Eval    │ <- 加速度/曲率
    │ Efficiency      │ <- 路程/时间
    │ Feasibility     │ <- 动力学约束
    └────────┬────────┘
             │
    ┌────────▼────────┐
    │ Reduction Kernel│ <- 归约求和
    └─────────────────┘
```

关键优化技术：

1. **地图查询优化**：使用3D纹理存储占用栅格图，硬件加速双线性插值
2. **批量碰撞检测**：将轨迹点打包为float4，使用向量化指令
3. **动态规划评估**：对时序相关的代价项使用扫描算法

### 14.2.3 并行轨迹筛选与排序

从数百条候选轨迹中选择最优解需要高效的并行排序：

```
多级筛选策略：

Stage 1: Coarse Filter (Block Level)
  - 每个block处理32条轨迹
  - 快速剔除明显不可行轨迹
  - 使用共享内存局部排序

Stage 2: Fine Selection (Grid Level)  
  - 收集各block的top-k轨迹
  - 全局排序选出最优解
  - 使用bitonic sort或radix sort

优化技巧：
- Early termination: 检测到碰撞立即标记
- Warp voting: 使用__ballot_sync快速统计
- Shared memory: 缓存频繁访问的数据
```

### 14.2.4 时空一致性优化

利用帧间的时间相关性加速评估：

1. **轨迹重用**：上一帧的最优轨迹作为warm start
2. **增量更新**：只重新评估变化的部分
3. **预测缓存**：基于车辆运动模型预测下一帧的候选集

## 14.3 动态规划的并行实现

### 14.3.1 并行贝尔曼更新

动态规划的核心是贝尔曼方程的迭代求解。GPU并行化的关键是识别独立的子问题：

```
串行DP的递推：
for t in time_steps:
    for s in states:
        V[t][s] = min(cost[s] + V[t-1][s'])
        
并行DP的分解：
┌─────────────────────────────┐
│    Time Step t-1 (已知)     │
│ [V0] [V1] [V2] ... [Vn]     │
└──────────┬──────────────────┘
           │ 并行转移
    ┌──────▼──────┐
    │  GPU Grid   │
    │ ┌─┬─┬─┬─┐  │
    │ │B│B│B│B│  │ <- 每个Block处理一组状态
    │ └─┴─┴─┴─┘  │
    └──────┬──────┘
           │
┌──────────▼──────────────────┐
│    Time Step t (计算中)      │
│ [V0'] [V1'] [V2'] ... [Vn'] │
└─────────────────────────────┘
```

并行化策略：

1. **状态并行**：同一时刻的所有状态并行更新
2. **路径并行**：多条可能路径同时评估
3. **分块递推**：将长序列分段，段内并行

### 14.3.2 并行维特比算法

用于最优路径回溯的维特比算法并行化：

```
前向传播（并行）：
- 每个时间步的所有状态并行计算
- 使用共享内存存储转移概率矩阵
- 原子操作更新最优前驱

后向回溯（串行优化）：
- 从终点开始单线程回溯
- 或使用并行前缀和技术加速
```

### 14.3.3 分层动态规划

对于大规模状态空间，采用分层策略：

```
Hierarchical DP:

Level 0 (Coarse): 
  States: 100 × 100 grid
  Threads: 10,000 parallel updates
  
Level 1 (Medium):
  States: 20 × 20 local refinement  
  Threads: 400 parallel updates
  
Level 2 (Fine):
  States: Continuous optimization
  Threads: Gradient-based solver
```

内存管理优化：

1. **滚动数组**：只保留相邻两个时间步的状态
2. **状态压缩**：使用位运算压缩离散状态
3. **稀疏表示**：只存储和更新可达状态

## 14.4 二次规划求解器

### 14.4.1 并行二次规划问题形式

轨迹优化常归结为二次规划（QP）问题：

```
标准QP形式：
min  0.5 * x^T * H * x + f^T * x
s.t. A * x <= b
     Aeq * x = beq
     lb <= x <= ub

其中x为轨迹参数向量，维度可达数百到数千
```

GPU并行求解的关键在于矩阵运算的加速：

```
并行矩阵运算分解：

H * x 计算：
┌──────────────┐
│   H Matrix   │  
│ ┌──┬──┬──┐  │
│ │  │  │  │  │  每个线程块处理H的一个子块
│ ├──┼──┼──┤  │  使用共享内存缓存
│ │  │  │  │  │  
│ └──┴──┴──┘  │
└──────────────┘

梯度计算：∇f = H*x + f
- 使用cuBLAS加速矩阵向量乘法
- 融合kernel减少内存访问
```

### 14.4.2 内点法的GPU实现

内点法是求解大规模QP的主流方法：

```
内点法迭代步骤：

1. KKT系统构建（并行）
   [H    A^T] [dx]   [r1]
   [A    -D ] [dλ] = [r2]
   
2. 线性系统求解（并行）
   - Cholesky分解: cuSOLVER
   - PCG迭代: 自定义kernel
   
3. 步长搜索（并行）
   - 多个候选步长同时评估
   - 使用warp投票选择最优

4. 变量更新（并行）
   - x = x + α*dx
   - 向量运算完全并行
```

优化技巧：

1. **预条件子**：利用问题结构设计高效预条件子
2. **暖启动**：使用上一帧的解作为初始值
3. **早停策略**：满足实时性要求时提前终止

### 14.4.3 ADMM并行求解器

交替方向乘子法（ADMM）天然适合并行化：

```
ADMM分解策略：

原问题分解为子问题：
Problem 1: min f1(x) （动力学约束）
Problem 2: min f2(z) （避障约束）
Coupling:  x = z

ADMM迭代：
┌────────────┐     ┌────────────┐
│  x-update  │────▶│  z-update  │
│  (Kernel1) │     │  (Kernel2) │
└────────────┘     └────────────┘
       ▲                 │
       └─────────────────┘
          λ-update (Kernel3)

每个子问题可以独立并行求解
```

### 14.4.4 增量式QP求解

利用问题的时序结构加速：

```
MPC中的QP序列：

Time t:   QP_t   -> Solution x_t
Time t+1: QP_t+1 -> Solution x_t+1

增量更新策略：
1. 识别变化的约束（新障碍物）
2. 只更新受影响的KKT块
3. 使用Sherman-Morrison公式更新逆矩阵

性能提升：
- 完整求解: 100ms
- 增量更新: 10ms
```

## 14.5 实时避障与轨迹平滑

### 14.5.1 动态障碍物的并行处理

实时避障需要快速处理多个移动障碍物的轨迹预测和碰撞检测：

```
动态障碍物处理流水线：

输入：N个障碍物的当前状态
┌─────────────────────────────┐
│ Obstacle States at time t   │
│ [Obs1] [Obs2] ... [ObsN]   │
└──────────┬──────────────────┘
           │
    ┌──────▼──────┐
    │ Prediction  │ <- 并行轨迹预测
    │   Kernels   │    每个障碍物独立
    └──────┬──────┘
           │
┌──────────▼──────────────────┐
│ Predicted Trajectories      │
│ T=0  T=1  T=2  ...  T=K    │ <- K个时间步
└──────────┬──────────────────┘
           │
    ┌──────▼──────┐
    │  Collision  │ <- 批量碰撞检测
    │   Testing   │    使用空间哈希
    └──────┬──────┘
           │
    ┌──────▼──────┐
    │ Risk Field  │ <- 生成风险场
    │ Generation  │    3D纹理存储
    └─────────────┘
```

关键技术：

1. **轨迹预测并行化**：
   - 每个障碍物使用独立线程预测
   - 多种运动模型（CV/CA/CTRV）并行评估
   - 使用贝叶斯滤波融合多模型预测

2. **时空占用网格**：
   ```
   4D Grid (x, y, z, t):
   - 空间分辨率: 0.2m
   - 时间分辨率: 0.1s
   - 使用位掩码压缩存储
   - 原子操作更新占用状态
   ```

3. **概率碰撞评估**：
   - 蒙特卡洛采样并行化
   - 使用cuRAND生成轨迹扰动
   - 批量评估碰撞概率

### 14.5.2 反应式避障层

在规划轨迹基础上添加快速反应层：

```
反应式避障架构：

┌────────────────────┐
│  Planned Path      │ <- 全局规划轨迹
└─────────┬──────────┘
          │
┌─────────▼──────────┐
│  Local Sensors     │ <- 激光雷达/相机
└─────────┬──────────┘
          │
    ┌─────▼─────┐
    │ Fast DWA  │ <- Dynamic Window Approach
    │  (GPU)    │    并行速度采样
    └─────┬─────┘
          │
┌─────────▼──────────┐
│ Modified Trajectory│ <- 局部调整后轨迹
└────────────────────┘

并行DWA实现：
- 速度空间离散: (v, ω) ∈ [v_min, v_max] × [ω_min, ω_max]
- 并行前向模拟: 每个速度组合独立仿真
- 批量评估: 距离、速度、方向代价并行计算
```

优化策略：

1. **分层采样**：粗细结合的速度空间采样
2. **早期剔除**：快速排除明显碰撞的速度
3. **GPU常量内存**：存储车辆动力学参数

### 14.5.3 轨迹平滑算法

生成的轨迹需要平滑处理以保证舒适性：

```
并行B样条平滑：

控制点优化问题：
min ||B(t) - P_original||² + λ*||B''(t)||²

其中B(t)为B样条曲线，P为原始轨迹点

并行优化策略：
┌────────────────────────┐
│   Control Points       │
│  [C0] [C1] ... [Cn]   │
└───────────┬────────────┘
            │
     ┌──────▼──────┐
     │ Gradient    │ <- 并行梯度计算
     │ Computation │    每个控制点独立
     └──────┬──────┘
            │
     ┌──────▼──────┐
     │   L-BFGS    │ <- 并行线搜索
     │   Update    │    多步长同时评估
     └──────┬──────┘
            │
┌───────────▼────────────┐
│   Smoothed Trajectory  │
└────────────────────────┘
```

关键实现细节：

1. **基函数预计算**：B样条基函数值预存于纹理内存
2. **稀疏矩阵运算**：利用B样条的局部支撑性
3. **约束投影**：并行投影到可行域

### 14.5.4 曲率连续性保证

确保轨迹的几何连续性对车辆控制至关重要：

```
曲率约束并行检查：

对每个轨迹点并行计算：
- 曲率: κ = |x'y'' - y'x''| / (x'² + y'²)^(3/2)
- 曲率变化率: dκ/ds

约束条件：
- |κ| ≤ κ_max （最大转向）
- |dκ/ds| ≤ dκ_max （转向平滑性）

并行修正策略：
1. 识别违反约束的点（并行扫描）
2. 局部调整控制点（并行优化）
3. 全局传播修正（迭代收敛）
```

### 14.5.5 多层级融合策略

将不同时间尺度的规划结果融合：

```
时间层级：
Level 0: 全局路径 (10s, 1Hz更新)
Level 1: 局部轨迹 (3s, 10Hz更新)  
Level 2: 反应控制 (0.3s, 100Hz更新)

GPU融合kernel：
__global__ void trajectoryFusion(
    float4* globalPath,    // 全局路径
    float4* localTraj,     // 局部轨迹
    float4* reactiveCmd,   // 反应指令
    float4* fusedOutput,   // 融合输出
    float* weights,        // 融合权重
    int horizonLength
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < horizonLength) {
        // 时间衰减权重
        float w_global = weights[0] * exp(-idx * 0.1f);
        float w_local = weights[1] * (1.0f - exp(-idx * 0.1f));
        float w_reactive = weights[2];
        
        // 加权融合
        fusedOutput[idx] = w_global * globalPath[idx] +
                          w_local * localTraj[idx] +
                          w_reactive * reactiveCmd[idx];
                          
        // 约束投影
        projectToFeasible(&fusedOutput[idx]);
    }
}
```

## 14.6 本章小结

本章深入探讨了路径规划与轨迹优化的GPU并行化技术。主要内容包括：

**核心算法并行化**：
- A*和RRT*的并行搜索策略，通过批量节点扩展实现10-50倍加速
- 动态规划的状态并行和时间并行分解，将O(n²)复杂度降至O(n)
- 二次规划求解器的矩阵运算加速，实现毫秒级MPC求解

**关键技术要点**：
1. **数据结构设计**：并行优先队列、空间哈希、位掩码压缩
2. **内存优化**：纹理内存存储地图、共享内存缓存热点数据
3. **负载均衡**：工作窃取、动态任务分配、分层处理
4. **数值稳定性**：原子操作保证一致性、增量更新减少误差累积

**性能优化公式**：
- 并行效率: η = S/(p×E) ≈ 0.7-0.9 （S=加速比, p=处理器数, E=串行部分比例）
- 内存带宽利用率: B_eff = (有效数据传输量)/(理论带宽×时间) > 80%
- 实时性保证: T_plan + T_smooth + T_check < 10ms

**实际应用效果**：
- 路径搜索：从100ms降至5ms
- 轨迹评估：批量1000条轨迹仅需2ms
- 避障响应：从30ms降至3ms
- 整体规划频率：从10Hz提升至100Hz