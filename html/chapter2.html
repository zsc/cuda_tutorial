<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第2章：CUDA编程模型与执行模型</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">CUDA 高性能编程实战教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第1章：CUDA硬件架构深度剖析</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第2章：CUDA编程模型与执行模型</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第3章：全局内存优化策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第4章：共享内存与Bank Conflict</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第5章：寄存器优化与常量内存</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第6章：Warp级编程与协作组</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第7章：原子操作与同步原语</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第8章：PTX内联与底层优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第9章：张量核心与混合精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第10章：CUTLASS深度解析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第11章：激光雷达点云处理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第12章：多传感器融合的并行化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第13章：实时语义分割与实例分割</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第14章：路径规划与轨迹优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第15章：视觉SLAM的GPU加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第16章：机械臂运动规划</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第17章：强化学习推理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第18章：大规模点云重建与网格化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第19章：多GPU编程与扩展</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第20章：CUDA Graph与内核融合</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第21章：嵌入式GPU开发（Jetson）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第22章：稀疏计算与动态稀疏</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第23章：量化与低精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第24章：新一代GPU特性展望</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第25章：性能分析与调优方法论</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第26章：CUDA调试技术与错误处理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter27.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第27章：开发环境与工具链配置</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="2cuda">第2章：CUDA编程模型与执行模型</h1>
<p>本章深入探讨CUDA的编程模型和执行模型，这是理解GPU并行计算的核心基础。我们将从线程组织结构开始，逐步深入到内核启动、流管理、内存模型以及调试技术。通过本章学习，你将掌握如何高效地组织和管理GPU上的大规模并行计算任务，为后续的性能优化打下坚实基础。</p>
<h2 id="21">2.1 线程层次结构与网格配置</h2>
<p>CUDA采用三级线程层次结构来组织大规模并行计算：网格（Grid）、线程块（Block）和线程（Thread）。这种层次化设计既符合GPU硬件架构，又为程序员提供了灵活的并行表达能力。</p>
<h3 id="211">2.1.1 三级层次结构详解</h3>
<p><strong>线程（Thread）</strong> 是CUDA中的最小执行单元。每个线程执行相同的内核代码，但可以通过内置变量访问自己的唯一标识符，从而处理不同的数据。线程拥有自己的寄存器和局部内存，执行时相互独立。</p>
<p><strong>线程块（Block）</strong> 是一组可以协作的线程集合。同一线程块内的线程可以通过共享内存进行数据交换，并通过同步原语进行协调。线程块的大小受硬件限制，目前最大为1024个线程。线程块可以是一维、二维或三维的，这种多维组织方式便于处理多维数据结构。</p>
<p><strong>网格（Grid）</strong> 是线程块的集合，代表一次内核启动的所有并行工作。网格也可以是一维、二维或三维的。网格中的线程块相互独立执行，它们之间没有同步机制（除非使用协作组或原子操作）。</p>
<div class="codehilite"><pre><span></span><code>Grid (3D)
    │
    ├─── Block(0,0,0) ─── Thread(0,0,0), Thread(1,0,0), ...
    │         │
    │         └─── Thread(0,1,0), Thread(1,1,0), ...
    │
    ├─── Block(1,0,0) ─── Thread(0,0,0), Thread(1,0,0), ...
    │         │
    │         └─── Thread(0,1,0), Thread(1,1,0), ...
    └─── ...
</code></pre></div>

<h3 id="212">2.1.2 线程索引计算</h3>
<p>在内核函数中，每个线程需要计算其全局唯一索引来确定要处理的数据。CUDA提供了内置变量来访问线程和块的索引：</p>
<ul>
<li><code>threadIdx.x/y/z</code>：线程在块内的局部索引</li>
<li><code>blockIdx.x/y/z</code>：块在网格内的索引</li>
<li><code>blockDim.x/y/z</code>：块的维度</li>
<li><code>gridDim.x/y/z</code>：网格的维度</li>
</ul>
<p>对于一维索引计算：</p>
<div class="codehilite"><pre><span></span><code>全局线程ID = blockIdx.x * blockDim.x + threadIdx.x
</code></pre></div>

<p>对于二维索引计算：</p>
<div class="codehilite"><pre><span></span><code>全局X索引 = blockIdx.x <span class="gs">* blockDim.x + threadIdx.x</span>
<span class="gs">全局Y索引 = blockIdx.y *</span> blockDim.y + threadIdx.y
线性索引 = 全局Y索引 * 网格宽度 + 全局X索引
</code></pre></div>

<h3 id="213-warpsimt">2.1.3 Warp与SIMT执行模型</h3>
<p>GPU的实际执行单位是<strong>warp</strong>，每个warp包含32个线程。这32个线程以SIMT（Single Instruction, Multiple Thread）方式执行，即同时执行相同的指令但操作不同的数据。理解warp对于性能优化至关重要：</p>
<p><strong>Warp调度</strong>：SM上的warp调度器负责选择就绪的warp执行。当某个warp因内存访问或同步而停滞时，调度器会切换到其他warp，从而隐藏延迟。这种零开销的上下文切换是GPU高吞吐量的关键。</p>
<p><strong>Warp分歧</strong>：当warp内的线程执行不同的代码路径（如if-else分支）时，会发生warp分歧。硬件通过串行执行各个分支来处理分歧，这会降低性能。优化策略包括：</p>
<ul>
<li>重组数据使相邻线程执行相同分支</li>
<li>使用无分支的算法（如位操作替代条件判断）</li>
<li>利用warp投票函数协调分支决策</li>
</ul>
<h3 id="214">2.1.4 最优网格配置策略</h3>
<p>选择合适的网格和块配置对性能至关重要。需要考虑的因素包括：</p>
<p><strong>占用率（Occupancy）</strong>：指SM上活跃warp数与最大warp数的比率。高占用率有助于隐藏延迟，但不是唯一决定因素。占用率受以下资源限制：</p>
<ul>
<li>每个SM的最大线程数</li>
<li>每个SM的最大块数</li>
<li>寄存器使用量</li>
<li>共享内存使用量</li>
</ul>
<p><strong>块大小选择原则</strong>：</p>
<ol>
<li>块大小应为32的倍数（warp大小）</li>
<li>通常选择128、256或512个线程</li>
<li>考虑共享内存和寄存器的使用情况</li>
<li>使用occupancy calculator工具辅助决策</li>
</ol>
<p><strong>动态网格尺寸计算</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">int</span><span class="w"> </span><span class="n">blockSize</span><span class="p">;</span><span class="w">   </span><span class="c1">// 内核的块大小</span>
<span class="kt">int</span><span class="w"> </span><span class="n">minGridSize</span><span class="p">;</span><span class="w"> </span><span class="c1">// 满足最大占用率的最小网格大小</span>
<span class="n">cudaOccupancyMaxPotentialBlockSize</span><span class="p">(</span><span class="o">&amp;</span><span class="n">minGridSize</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">blockSize</span><span class="p">,</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="kt">int</span><span class="w"> </span><span class="n">gridSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockSize</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">blockSize</span><span class="p">;</span><span class="w">  </span><span class="c1">// 向上取整</span>
<span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">gridSize</span><span class="p">,</span><span class="w"> </span><span class="n">blockSize</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">);</span>
</code></pre></div>

<h3 id="215">2.1.5 多维网格的应用场景</h3>
<p>多维网格特别适合处理多维数据结构：</p>
<p><strong>二维网格处理图像</strong>：对于M×N的图像，可以使用二维块和二维网格，每个线程处理一个像素。这种映射直观且缓存友好。</p>
<p><strong>三维网格处理体数据</strong>：在处理医学成像、流体模拟等三维数据时，三维网格提供了自然的映射方式。</p>
<p><strong>维度选择策略</strong>：</p>
<ul>
<li>数据维度与网格维度匹配可简化索引计算</li>
<li>考虑内存访问模式，相邻线程应访问相邻内存</li>
<li>某些算法可能需要特殊的线程组织（如矩阵转置）</li>
</ul>
<h2 id="22">2.2 内核启动与动态并行</h2>
<p>内核函数是在GPU上执行的并行代码单元。CUDA提供了灵活的内核启动机制，包括传统的主机端启动和动态并行（设备端启动）。理解这些机制对于构建复杂的GPU应用至关重要。</p>
<h3 id="221">2.2.1 内核函数的声明与定义</h3>
<p>CUDA使用特殊的函数类型限定符来区分不同的函数类型：</p>
<p><strong><code>__global__</code>函数</strong>：内核函数，可从主机调用，在设备上执行。必须返回void，支持模板和重载。</p>
<p><strong><code>__device__</code>函数</strong>：设备函数，只能从设备调用，在设备上执行。可以有返回值，支持递归（需要特殊编译选项）。</p>
<p><strong><code>__host__</code>函数</strong>：主机函数，默认类型。可以与<code>__device__</code>组合使用，生成主机和设备两个版本。</p>
<p>内核函数的参数传递规则：</p>
<ul>
<li>参数通过常量内存传递（限制4KB）</li>
<li>大型结构体应通过指针传递</li>
<li>不支持可变参数列表</li>
<li>不支持静态变量（除非使用<code>__shared__</code>）</li>
</ul>
<h3 id="222">2.2.2 启动配置参数详解</h3>
<p>内核启动使用特殊的执行配置语法：</p>
<div class="codehilite"><pre><span></span><code><span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="nb">gridDim</span><span class="p">,</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">,</span><span class="w"> </span><span class="n">sharedMem</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">);</span>
</code></pre></div>

<p><strong>gridDim</strong>：网格维度，类型为dim3。指定网格中块的数量。</p>
<ul>
<li>最大维度：X(2^31-1), Y(65535), Z(65535)</li>
<li>可以使用整数自动转换为(N,1,1)</li>
</ul>
<p><strong>blockDim</strong>：块维度，类型为dim3。指定每个块中线程的数量。</p>
<ul>
<li>最大线程数：1024（X×Y×Z ≤ 1024）</li>
<li>建议为warp大小（32）的倍数</li>
</ul>
<p><strong>sharedMem</strong>：动态共享内存大小（字节）。可选参数，默认为0。</p>
<ul>
<li>与静态共享内存共享48KB/96KB的空间</li>
<li>动态分配允许运行时确定大小</li>
</ul>
<p><strong>stream</strong>：执行流。可选参数，默认为0（默认流）。</p>
<ul>
<li>用于异步执行和并发管理</li>
<li>不同流中的操作可以并发执行</li>
</ul>
<h3 id="223">2.2.3 动态并行编程模型</h3>
<p>动态并行允许GPU内核直接启动其他内核，无需CPU介入。这对递归算法和自适应算法特别有用。</p>
<p><strong>启用条件</strong>：</p>
<ul>
<li>计算能力3.5及以上</li>
<li>编译时添加<code>-rdc=true -lcudadevrt</code></li>
<li>链接设备运行时库</li>
</ul>
<p><strong>设备端内核启动</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">parent_kernel</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">child_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">32</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>
<span class="w">        </span><span class="n">cudaDeviceSynchronize</span><span class="p">();</span><span class="w">  </span><span class="c1">// 设备端同步</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>内存模型</strong>：</p>
<ul>
<li>父内核的全局内存对子内核可见</li>
<li>子内核的局部和共享内存独立</li>
<li>父子内核间通过全局内存通信</li>
</ul>
<p><strong>同步机制</strong>：</p>
<ul>
<li><code>cudaDeviceSynchronize()</code>：等待所有子内核完成</li>
<li>父内核结束时隐式同步所有子内核</li>
<li>注意避免死锁（父等子，子等父）</li>
</ul>
<h3 id="224">2.2.4 嵌套深度与资源管理</h3>
<p>动态并行的嵌套深度和资源使用需要仔细管理：</p>
<p><strong>嵌套深度限制</strong>：</p>
<ul>
<li>默认最大深度为24层</li>
<li>可通过<code>cudaLimitDevRuntimeSyncDepth</code>调整</li>
<li>深度过大会导致资源耗尽</li>
</ul>
<p><strong>资源池管理</strong>：</p>
<ul>
<li>设备端启动使用独立的资源池</li>
<li>通过<code>cudaLimitDevRuntimePendingLaunchCount</code>控制</li>
<li>默认限制2048个待处理的启动</li>
</ul>
<p><strong>性能考量</strong>：</p>
<ul>
<li>设备端启动有额外开销（约10μs）</li>
<li>适合粗粒度并行（每个子内核做大量工作）</li>
<li>细粒度并行应使用协作组</li>
</ul>
<h3 id="225-gpu">2.2.5 递归算法的GPU实现</h3>
<p>动态并行使得递归算法在GPU上成为可能。典型应用包括：</p>
<p><strong>快速排序</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">quicksort</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">right</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">left</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">right</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">pivot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partition</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">right</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">s1</span><span class="p">,</span><span class="w"> </span><span class="n">s2</span><span class="p">;</span>
<span class="w">        </span><span class="n">cudaStreamCreateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s1</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamNonBlocking</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaStreamCreateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s2</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamNonBlocking</span><span class="p">);</span>

<span class="w">        </span><span class="n">quicksort</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">s1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">left</span><span class="p">,</span><span class="w"> </span><span class="n">pivot</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">        </span><span class="n">quicksort</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">s2</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">pivot</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">right</span><span class="p">);</span>

<span class="w">        </span><span class="n">cudaStreamDestroy</span><span class="p">(</span><span class="n">s1</span><span class="p">);</span>
<span class="w">        </span><span class="n">cudaStreamDestroy</span><span class="p">(</span><span class="n">s2</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>自适应网格细化</strong>：</p>
<ul>
<li>根据误差估计动态细化网格</li>
<li>只在需要的区域增加计算密度</li>
<li>适用于自适应有限元、光线追踪等</li>
</ul>
<p><strong>树遍历算法</strong>：</p>
<ul>
<li>并行遍历不规则树结构</li>
<li>动态负载均衡</li>
<li>避免CPU-GPU频繁同步</li>
</ul>
<h3 id="226">2.2.6 内核启动的性能优化</h3>
<p><strong>启动开销优化</strong>：</p>
<ul>
<li>批量处理小任务，减少启动次数</li>
<li>使用持久化内核处理流式数据</li>
<li>利用CUDA Graph减少启动开销</li>
</ul>
<p><strong>网格规模优化</strong>：</p>
<ul>
<li>确保足够的并行度（至少数千个线程）</li>
<li>避免尾部效应（部分块未充分利用）</li>
<li>使用网格跨步循环处理大规模数据</li>
</ul>
<p><strong>编译优化选项</strong>：</p>
<ul>
<li><code>-use_fast_math</code>：使用快速数学函数</li>
<li><code>-maxrregcount</code>：限制寄存器使用</li>
<li><code>--ptxas-options=-v</code>：显示资源使用信息</li>
</ul>
<h2 id="23">2.3 流与事件机制</h2>
<p>CUDA流（Stream）是GPU上的操作队列，允许并发执行多个任务。事件（Event）则用于同步和性能测量。掌握流和事件机制是实现高效GPU程序的关键。</p>
<h3 id="231-cuda">2.3.1 CUDA流的概念与创建</h3>
<p><strong>流的本质</strong>：流是一个有序的操作序列，同一流中的操作按顺序执行，不同流中的操作可以并发执行。这种机制允许：</p>
<ul>
<li>计算与数据传输重叠</li>
<li>多个内核并发执行</li>
<li>细粒度的执行控制</li>
</ul>
<p><strong>流的类型</strong>：</p>
<ul>
<li><strong>默认流（NULL流）</strong>：隐式同步，与其他所有流同步</li>
<li><strong>非默认流</strong>：显式创建，可以并发执行</li>
<li><strong>优先级流</strong>：支持不同优先级的任务调度</li>
</ul>
<p><strong>流的创建与销毁</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">;</span>
<span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">);</span><span class="w">                      </span><span class="c1">// 创建默认优先级流</span>
<span class="n">cudaStreamCreateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamNonBlocking</span><span class="p">);</span><span class="w">  </span><span class="c1">// 非阻塞流</span>
<span class="n">cudaStreamCreateWithPriority</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamNonBlocking</span><span class="p">,</span><span class="w"> </span><span class="n">priority</span><span class="p">);</span><span class="w">  </span><span class="c1">// 优先级流</span>
<span class="n">cudaStreamDestroy</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span><span class="w">                      </span><span class="c1">// 销毁流</span>
</code></pre></div>

<h3 id="232">2.3.2 异步操作与并发执行</h3>
<p>CUDA中大部分操作都有异步版本，允许CPU在GPU执行时继续工作：</p>
<p><strong>异步内存操作</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaMemsetAsync</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="n">cudaMemPrefetchAsync</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">device</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span><span class="w">  </span><span class="c1">// 统一内存预取</span>
</code></pre></div>

<p><strong>异步内核执行</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">);</span>
</code></pre></div>

<p><strong>并发模式分析</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="err">时间线示例（</span><span class="n">H2D</span><span class="o">=</span><span class="err">主机到设备传输，</span><span class="n">K</span><span class="o">=</span><span class="err">内核，</span><span class="n">D2H</span><span class="o">=</span><span class="err">设备到主机传输）：</span>

<span class="err">默认流：</span><span class="w">  </span><span class="n">H2D</span><span class="w"> </span><span class="o">-----&gt;</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">-----&gt;</span><span class="w"> </span><span class="n">D2H</span><span class="w"> </span><span class="o">-----&gt;</span>
<span class="w">         </span><span class="o">|&lt;-------</span><span class="w"> </span><span class="err">总时间</span><span class="w"> </span><span class="o">-------&gt;|</span>

<span class="err">双流并发：</span><span class="w"> </span><span class="n">Stream1</span><span class="o">:</span><span class="w"> </span><span class="n">H2D1</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">K1</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">D2H1</span><span class="w"> </span><span class="o">--&gt;</span>
<span class="w">         </span><span class="n">Stream2</span><span class="o">:</span><span class="w">      </span><span class="n">H2D2</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">K2</span><span class="w"> </span><span class="o">--&gt;</span><span class="w"> </span><span class="n">D2H2</span><span class="w"> </span><span class="o">--&gt;</span>
<span class="w">         </span><span class="o">|&lt;-----</span><span class="w"> </span><span class="err">减少的总时间</span><span class="w"> </span><span class="o">-----&gt;|</span>
</code></pre></div>

<h3 id="233">2.3.3 流同步机制</h3>
<p>控制流之间的依赖关系和同步点：</p>
<p><strong>流级同步</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span><span class="w">      </span><span class="c1">// 等待特定流完成</span>
<span class="n">cudaDeviceSynchronize</span><span class="p">();</span><span class="w">            </span><span class="c1">// 等待所有流完成</span>
<span class="n">cudaStreamQuery</span><span class="p">(</span><span class="n">stream</span><span class="p">);</span><span class="w">            </span><span class="c1">// 非阻塞查询流状态</span>
</code></pre></div>

<p><strong>流间依赖</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w">  </span><span class="c1">// 流等待事件</span>
<span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">event</span><span class="p">;</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">event</span><span class="p">);</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">event</span><span class="p">,</span><span class="w"> </span><span class="n">stream1</span><span class="p">);</span><span class="w">        </span><span class="c1">// 在stream1中记录事件</span>
<span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">stream2</span><span class="p">,</span><span class="w"> </span><span class="n">event</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="c1">// stream2等待event</span>
</code></pre></div>

<p><strong>回调函数</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="kt">void</span><span class="w"> </span><span class="n">CUDART_CB</span><span class="w"> </span><span class="nf">callback</span><span class="p">(</span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">status</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 在流中所有操作完成后执行</span>
<span class="p">}</span>
<span class="n">cudaStreamAddCallback</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">callback</span><span class="p">,</span><span class="w"> </span><span class="n">userData</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
</code></pre></div>

<h3 id="234">2.3.4 事件的创建与使用</h3>
<p>事件是流中的标记点，用于同步和计时：</p>
<p><strong>事件创建与记录</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaEvent_t</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">stop</span><span class="p">;</span>
<span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">start</span><span class="p">);</span>
<span class="n">cudaEventCreateWithFlags</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stop</span><span class="p">,</span><span class="w"> </span><span class="n">cudaEventDisableTiming</span><span class="p">);</span><span class="w">  </span><span class="c1">// 禁用计时</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
<span class="c1">// ... 执行操作 ...</span>
<span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stop</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</code></pre></div>

<p><strong>事件同步</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">event</span><span class="p">);</span><span class="w">        </span><span class="c1">// 等待事件完成</span>
<span class="n">cudaEventQuery</span><span class="p">(</span><span class="n">event</span><span class="p">);</span><span class="w">              </span><span class="c1">// 非阻塞查询</span>
<span class="kt">float</span><span class="w"> </span><span class="n">milliseconds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">milliseconds</span><span class="p">,</span><span class="w"> </span><span class="n">start</span><span class="p">,</span><span class="w"> </span><span class="n">stop</span><span class="p">);</span><span class="w">  </span><span class="c1">// 计算时间差</span>
</code></pre></div>

<p><strong>事件的硬件实现</strong>：</p>
<ul>
<li>事件在GPU时间线上插入标记</li>
<li>轻量级（几乎无开销）</li>
<li>精度达到纳秒级</li>
</ul>
<h3 id="235">2.3.5 多流优化策略</h3>
<p><strong>流的数量选择</strong>：</p>
<ul>
<li>Hyper-Q支持32个硬件队列</li>
<li>实践中4-8个流通常足够</li>
<li>过多流增加管理开销</li>
</ul>
<p><strong>深度优先vs广度优先</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 深度优先：每个流完成所有操作</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nStreams</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="p">}</span>

<span class="c1">// 广度优先：按操作类型批处理（更好的并发）</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nStreams</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nStreams</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nStreams</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">h_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">d_a</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</code></pre></div>

<p><strong>流水线并行模式</strong>：</p>
<ul>
<li>将大任务分割成小块</li>
<li>使用循环缓冲区</li>
<li>重叠计算和传输</li>
</ul>
<h3 id="236-cuda-graph">2.3.6 CUDA Graph优化</h3>
<p>CUDA Graph将一系列操作捕获为图，可以高效重复执行：</p>
<p><strong>Graph创建与执行</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">cudaGraph_t</span><span class="w"> </span><span class="n">graph</span><span class="p">;</span>
<span class="n">cudaGraphExec_t</span><span class="w"> </span><span class="n">instance</span><span class="p">;</span>
<span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">;</span>

<span class="c1">// 捕获操作序列</span>
<span class="n">cudaStreamBeginCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="n">cudaStreamCaptureModeGlobal</span><span class="p">);</span>
<span class="c1">// ... 记录操作 ...</span>
<span class="n">cudaStreamEndCapture</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">graph</span><span class="p">);</span>

<span class="c1">// 实例化并执行</span>
<span class="n">cudaGraphInstantiate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">instance</span><span class="p">,</span><span class="w"> </span><span class="n">graph</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="nb">NULL</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
<span class="n">cudaGraphLaunch</span><span class="p">(</span><span class="n">instance</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="p">);</span>
</code></pre></div>

<p><strong>Graph优势</strong>：</p>
<ul>
<li>减少CPU启动开销</li>
<li>优化GPU调度</li>
<li>适合重复执行的工作负载</li>
</ul>
<p><strong>Graph更新</strong>：</p>
<ul>
<li>支持参数更新而不重建图</li>
<li>动态修改节点</li>
<li>条件执行分支</li>
</ul>
            </article>
            
            <nav class="page-nav"><a href="chapter1.html" class="nav-link prev">← 第1章：CUDA硬件架构深度剖析</a><a href="chapter3.html" class="nav-link next">第3章：全局内存优化策略 →</a></nav>
        </main>
    </div>
</body>
</html>