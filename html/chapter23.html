<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第23章：量化与低精度计算</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">CUDA 高性能编程实战教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第1章：CUDA硬件架构深度剖析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第2章：CUDA编程模型与执行模型</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第3章：全局内存优化策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第4章：共享内存与Bank Conflict</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第5章：寄存器优化与常量内存</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第6章：Warp级编程与协作组</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第7章：原子操作与同步原语</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第8章：PTX内联与底层优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第9章：张量核心与混合精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第10章：CUTLASS深度解析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第11章：激光雷达点云处理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第12章：多传感器融合的并行化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第13章：实时语义分割与实例分割</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第14章：路径规划与轨迹优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第15章：视觉SLAM的GPU加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第16章：机械臂运动规划</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第17章：强化学习推理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第18章：大规模点云重建与网格化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第19章：多GPU编程与扩展</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第20章：CUDA Graph与内核融合</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第21章：嵌入式GPU开发（Jetson）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第22章：稀疏计算与动态稀疏</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第23章：量化与低精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第24章：新一代GPU特性展望</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第25章：性能分析与调优方法论</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第26章：CUDA调试技术与错误处理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter27.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第27章：开发环境与工具链配置</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="23">第23章：量化与低精度计算</h1>
<p>量化技术是深度学习模型部署的关键优化手段，通过降低数值精度来换取更高的计算吞吐量和更低的内存占用。本章深入探讨CUDA平台上的量化技术实现，从INT8/INT4基础到自定义量化算子，涵盖训练和推理全流程。我们将重点关注自动驾驶和具身智能场景中的实际应用，帮助你实现4x-8x的推理加速，同时保持可接受的精度损失。</p>
<h2 id="231-int8int4">23.1 INT8/INT4量化技术</h2>
<p>量化是将浮点数值映射到有限整数集合的过程。在深度学习中，我们通常将FP32/FP16权重和激活值量化为INT8甚至INT4，实现存储压缩和计算加速。现代GPU从Turing架构开始提供专门的INT8 Tensor Core，Ampere架构进一步支持INT4运算，使得量化成为生产部署的标配技术。</p>
<h3 id="2311">23.1.1 量化基础理论</h3>
<p>量化过程可以表示为两个变换：量化（Quantize）和反量化（Dequantize）。</p>
<p><strong>均匀量化公式：</strong></p>
<div class="codehilite"><pre><span></span><code>Q(x) = round(x / scale + zero_point)
DQ(q) = (q - zero_point) * scale
</code></pre></div>

<p>其中scale是缩放因子，zero_point是零点偏移。对于INT8量化，q ∈ [-128, 127]（有符号）或 [0, 255]（无符号）。</p>
<p><strong>量化参数计算：</strong></p>
<div class="codehilite"><pre><span></span><code>scale = (x_max - x_min) / (q_max - q_min)
zero_point = round(q_min - x_min / scale)
</code></pre></div>

<p>关键在于如何确定x_min和x_max。常见策略包括：</p>
<ul>
<li><strong>MinMax量化</strong>：使用实际最小值和最大值</li>
<li><strong>百分位量化</strong>：使用99.9%分位数，裁剪异常值</li>
<li><strong>KL散度量化</strong>：最小化量化前后分布的KL散度</li>
<li><strong>MSE量化</strong>：最小化均方误差</li>
</ul>
<p><strong>INT4量化的特殊考虑：</strong></p>
<p>INT4仅有16个量化等级，需要更精细的处理：</p>
<ul>
<li>通常采用对称量化（zero_point = 0）</li>
<li>结合分组量化（group-wise）提高精度</li>
<li>使用查找表（LUT）加速反量化</li>
</ul>
<h3 id="2312">23.1.2 对称与非对称量化</h3>
<p><strong>对称量化</strong>假设数据分布关于零对称：</p>
<div class="codehilite"><pre><span></span><code>scale = max(|x_max|, |x_min|) / q_max
zero_point = 0
Q(x) = round(x / scale)
</code></pre></div>

<p>优点：</p>
<ul>
<li>计算简单，无需存储zero_point</li>
<li>零值精确表示（Q(0) = 0）</li>
<li>适合权重量化</li>
</ul>
<p><strong>非对称量化</strong>允许任意范围映射：</p>
<div class="codehilite"><pre><span></span><code>scale = (x_max - x_min) / (q_max - q_min)
zero_point = round(q_min - x_min / scale)
</code></pre></div>

<p>优点：</p>
<ul>
<li>更好利用量化范围</li>
<li>适合激活值（如ReLU后的非负分布）</li>
<li>更小的量化误差</li>
</ul>
<p><strong>CUDA实现对比：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 对称量化内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">symmetric_quantize_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mf">127.0f</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">);</span>
<span class="w">        </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="mf">-128.0f</span><span class="p">,</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="mf">127.0f</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">));</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2int_rn</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 非对称量化内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">asymmetric_quantize_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">uint8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">zero_point</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">zero_point</span><span class="p">;</span>
<span class="w">        </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="mf">255.0f</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">));</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2uint_rn</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2313">23.1.3 逐层与逐通道量化</h3>
<p><strong>逐层量化（Per-layer）</strong>：
整层共享一组量化参数，实现简单但精度损失较大。</p>
<p><strong>逐通道量化（Per-channel）</strong>：
每个输出通道独立量化，提高精度但增加存储开销。</p>
<p><strong>逐组量化（Per-group）</strong>：
将通道分组，组内共享参数，平衡精度和效率。</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 逐通道量化的高效实现</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">per_channel_quantize_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w">      </span><span class="c1">// [N, C, H, W]</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w">         </span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scales</span><span class="p">,</span><span class="w">     </span><span class="c1">// [C]</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">zero_points</span><span class="p">,</span><span class="w">  </span><span class="c1">// [C]</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">H</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">total</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">C</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">);</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">H</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">W</span><span class="p">))</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">C</span><span class="p">;</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scales</span><span class="p">[</span><span class="n">c</span><span class="p">];</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">zp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">zero_points</span><span class="p">[</span><span class="n">c</span><span class="p">];</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">zp</span><span class="p">;</span>
<span class="w">        </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="mf">-128.0f</span><span class="p">,</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="mf">127.0f</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">));</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2int_rn</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>分组量化优化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="w">     </span><span class="n">Original</span><span class="w"> </span><span class="n">Tensor</span>
<span class="w">    </span><span class="o">[</span><span class="n">C0</span><span class="o">][</span><span class="n">C1</span><span class="o">][</span><span class="n">C2</span><span class="o">][</span><span class="n">C3</span><span class="o">]</span><span class="p">...</span>
<span class="w">         </span><span class="o">|</span>
<span class="w">         </span><span class="n">v</span>
<span class="w">    </span><span class="k">Group</span><span class="w"> </span><span class="k">Size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">128</span>
<span class="w">    </span><span class="o">[</span><span class="n">G0: C0-C127</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">G1: C128-C255</span><span class="o">]</span><span class="p">...</span>
<span class="w">         </span><span class="o">|</span><span class="w">              </span><span class="o">|</span>
<span class="w">    </span><span class="n">scale0</span><span class="p">,</span><span class="w"> </span><span class="n">zp0</span><span class="w">    </span><span class="n">scale1</span><span class="p">,</span><span class="w"> </span><span class="n">zp1</span>
</code></pre></div>

<h3 id="2314-cudaint8int4">23.1.4 CUDA中的INT8/INT4运算</h3>
<p><strong>INT8 Tensor Core编程：</strong></p>
<p>Turing架构引入的INT8 Tensor Core提供极高的计算吞吐量：</p>
<div class="codehilite"><pre><span></span><code><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;mma.h&gt;</span>
<span class="n">using</span><span class="w"> </span><span class="n">namespace</span><span class="w"> </span><span class="n">nvcuda</span><span class="o">::</span><span class="n">wmma</span><span class="p">;</span>

<span class="c1">// INT8 WMMA示例</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">int8_wmma_gemm</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">int32_t</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">warpM</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="n">warpN</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w"> </span><span class="n">warpK</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 声明WMMA片段</span>
<span class="w">    </span><span class="n">fragment</span><span class="o">&lt;</span><span class="n">matrix_a</span><span class="p">,</span><span class="w"> </span><span class="n">warpM</span><span class="p">,</span><span class="w"> </span><span class="n">warpN</span><span class="p">,</span><span class="w"> </span><span class="n">warpK</span><span class="p">,</span><span class="w"> </span><span class="kt">int8_t</span><span class="p">,</span><span class="w"> </span><span class="n">row_major</span><span class="o">&gt;</span><span class="w"> </span><span class="n">a_frag</span><span class="p">;</span>
<span class="w">    </span><span class="n">fragment</span><span class="o">&lt;</span><span class="n">matrix_b</span><span class="p">,</span><span class="w"> </span><span class="n">warpM</span><span class="p">,</span><span class="w"> </span><span class="n">warpN</span><span class="p">,</span><span class="w"> </span><span class="n">warpK</span><span class="p">,</span><span class="w"> </span><span class="kt">int8_t</span><span class="p">,</span><span class="w"> </span><span class="n">col_major</span><span class="o">&gt;</span><span class="w"> </span><span class="n">b_frag</span><span class="p">;</span>
<span class="w">    </span><span class="n">fragment</span><span class="o">&lt;</span><span class="n">accumulator</span><span class="p">,</span><span class="w"> </span><span class="n">warpM</span><span class="p">,</span><span class="w"> </span><span class="n">warpN</span><span class="p">,</span><span class="w"> </span><span class="n">warpK</span><span class="p">,</span><span class="w"> </span><span class="kt">int32_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">c_frag</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 初始化累加器</span>
<span class="w">    </span><span class="n">fill_fragment</span><span class="p">(</span><span class="n">c_frag</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 计算warp的全局位置</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">warpId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">laneId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">warpK</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 加载矩阵片段</span>
<span class="w">        </span><span class="n">load_matrix_sync</span><span class="p">(</span><span class="n">a_frag</span><span class="p">,</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">K</span><span class="p">);</span>
<span class="w">        </span><span class="n">load_matrix_sync</span><span class="p">(</span><span class="n">b_frag</span><span class="p">,</span><span class="w"> </span><span class="n">B</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">K</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 执行矩阵乘法</span>
<span class="w">        </span><span class="n">mma_sync</span><span class="p">(</span><span class="n">c_frag</span><span class="p">,</span><span class="w"> </span><span class="n">a_frag</span><span class="p">,</span><span class="w"> </span><span class="n">b_frag</span><span class="p">,</span><span class="w"> </span><span class="n">c_frag</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 存储结果</span>
<span class="w">    </span><span class="n">store_matrix_sync</span><span class="p">(</span><span class="n">C</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...,</span><span class="w"> </span><span class="n">c_frag</span><span class="p">,</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="n">mem_row_major</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>INT4运算的位打包：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// INT4打包和解包</span>
<span class="kt">__device__</span><span class="w"> </span><span class="kr">__forceinline__</span><span class="w"> </span><span class="kt">int8_t</span><span class="w"> </span><span class="n">pack_int4</span><span class="p">(</span><span class="kt">int4</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int4</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">)</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="p">((</span><span class="n">b</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">__device__</span><span class="w"> </span><span class="kr">__forceinline__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">unpack_int4</span><span class="p">(</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="w"> </span><span class="n">packed</span><span class="p">,</span><span class="w"> </span><span class="kt">int4</span><span class="o">&amp;</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="kt">int4</span><span class="o">&amp;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">packed</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x08</span><span class="p">)</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">|=</span><span class="w"> </span><span class="mh">0xFFFFFFF0</span><span class="p">;</span><span class="w">  </span><span class="c1">// 符号扩展</span>
<span class="w">    </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">packed</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x08</span><span class="p">)</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">|=</span><span class="w"> </span><span class="mh">0xFFFFFFF0</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// INT4 GEMM内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">int4_gemm_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">A_packed</span><span class="p">,</span><span class="w">  </span><span class="c1">// 两个INT4打包成一个INT8</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">B_packed</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">C_packed</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="c1">// 使用向量化加载提高带宽利用</span>
<span class="w">    </span><span class="kt">int4</span><span class="w"> </span><span class="n">a_vec</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">int4</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">A_packed</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">...);</span>

<span class="w">    </span><span class="c1">// 解包并计算</span>
<span class="w">    </span><span class="cp">#pragma unroll</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int4</span><span class="w"> </span><span class="n">a_low</span><span class="p">,</span><span class="w"> </span><span class="n">a_high</span><span class="p">;</span>
<span class="w">        </span><span class="n">unpack_int4</span><span class="p">(</span><span class="n">a_vec</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">a_low</span><span class="p">,</span><span class="w"> </span><span class="n">a_high</span><span class="p">);</span>
<span class="w">        </span><span class="c1">// 执行INT4运算...</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>DP4A指令优化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用DP4A指令加速INT8点积</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">dp4a_gemm_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">A</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">B</span><span class="p">,</span><span class="w"> </span><span class="kt">int32_t</span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">row</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">M</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 加载4个INT8值并打包</span>
<span class="w">            </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">a_packed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">int32_t</span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">A</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">]);</span>
<span class="w">            </span><span class="kt">int32_t</span><span class="w"> </span><span class="n">b_packed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">int32_t</span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">B</span><span class="p">[</span><span class="n">col</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">]);</span>

<span class="w">            </span><span class="c1">// DP4A: sum += a[0]*b[0] + a[1]*b[1] + a[2]*b[2] + a[3]*b[3]</span>
<span class="w">            </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__dp4a</span><span class="p">(</span><span class="n">a_packed</span><span class="p">,</span><span class="w"> </span><span class="n">b_packed</span><span class="p">,</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="n">C</span><span class="p">[</span><span class="n">row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">col</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2315">23.1.5 量化误差分析</h3>
<p>量化引入的误差主要包括：</p>
<ol>
<li><strong>舍入误差</strong>：连续值映射到离散级别</li>
<li><strong>饱和误差</strong>：超出量化范围的值被裁剪</li>
<li><strong>累积误差</strong>：多层量化误差传播</li>
</ol>
<p><strong>误差度量：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">SQNR</span><span class="w"> </span><span class="p">(</span><span class="n">Signal</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">Quantization</span><span class="o">-</span><span class="n">Noise</span><span class="w"> </span><span class="n">Ratio</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">log10</span><span class="p">(</span><span class="n">P_signal</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">P_noise</span><span class="p">)</span>
<span class="err">其中</span><span class="w"> </span><span class="n">P_noise</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">E</span><span class="p">[(</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Q</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="err">²</span><span class="p">]</span>
</code></pre></div>

<p><strong>误差分析工具：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 量化误差统计内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">quantization_error_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">original</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">quantized</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">mse</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">max_error</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">shared_mse</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">shared_max</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>

<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">local_mse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabsf</span><span class="p">(</span><span class="n">original</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">quantized</span><span class="p">[</span><span class="n">idx</span><span class="p">]);</span>
<span class="w">        </span><span class="n">local_mse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">error</span><span class="p">;</span>
<span class="w">        </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">error</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">shared_mse</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_mse</span><span class="p">;</span>
<span class="w">    </span><span class="n">shared_max</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_max</span><span class="p">;</span>
<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 规约求和与最大值</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">shared_mse</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">shared_mse</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">];</span>
<span class="w">            </span><span class="n">shared_max</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">shared_max</span><span class="p">[</span><span class="n">tid</span><span class="p">],</span><span class="w"> </span><span class="n">shared_max</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">]);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">mse</span><span class="p">,</span><span class="w"> </span><span class="n">shared_mse</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">        </span><span class="n">atomicMax</span><span class="p">(</span><span class="n">max_error</span><span class="p">,</span><span class="w"> </span><span class="n">shared_max</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>敏感层识别：</strong>
某些层对量化更敏感，需要特殊处理：</p>
<ul>
<li>网络首尾层通常保持FP16/FP32</li>
<li>残差连接的加法操作易累积误差</li>
<li>小卷积核（1x1）的量化影响较大</li>
</ul>
<h2 id="232">23.2 量化感知训练</h2>
<p>量化感知训练（Quantization-Aware Training, QAT）在训练过程中模拟量化效应，使模型学习适应量化误差。相比训练后量化（Post-Training Quantization, PTQ），QAT能显著减少精度损失，特别是对于极低比特量化（INT4及以下）更是必不可少。</p>
<h3 id="2321">23.2.1 伪量化技术</h3>
<p>伪量化（Fake Quantization）在前向传播中模拟量化/反量化过程，但保持浮点运算以支持梯度计算。</p>
<p><strong>伪量化的数学表示：</strong></p>
<div class="codehilite"><pre><span></span><code>y = FakeQuant(x) = DQ(Q(x)) = round(x/s + z) <span class="gs">* s - z *</span> s
</code></pre></div>

<p><strong>直通估计器（Straight-Through Estimator, STE）：</strong></p>
<div class="codehilite"><pre><span></span><code>前向：y = FakeQuant(x)
反向：∂L/∂x = ∂L/∂y  (梯度直接传递)
</code></pre></div>

<p><strong>CUDA实现：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 伪量化前向内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">fake_quant_forward_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">zero_point</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">num_bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">zero_point</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 计算量化范围</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">qmin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">num_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">));</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">qmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">num_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 量化</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">        </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">        </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">qmin</span><span class="p">,</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="n">qmax</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">));</span>

<span class="w">        </span><span class="c1">// 反量化</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">z</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">s</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 伪量化反向内核（STE）</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">fake_quant_backward_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">grad_output</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">grad_input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">grad_scale</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">zero_point</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">num_bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">zero_point</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 计算量化范围</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">qmin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">num_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">));</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">qmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">num_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 检查是否在量化范围内</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">        </span><span class="kt">bool</span><span class="w"> </span><span class="n">in_range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">qmin</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">qmax</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// STE：范围内直接传递梯度，范围外截断</span>
<span class="w">        </span><span class="n">grad_input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in_range</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">grad_output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 累积scale的梯度</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">in_range</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">grad_s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad_output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">s</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">z</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">s</span><span class="p">);</span>
<span class="w">            </span><span class="n">atomicAdd</span><span class="p">(</span><span class="n">grad_scale</span><span class="p">,</span><span class="w"> </span><span class="n">grad_s</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>可学习量化参数：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// LSQ（Learned Step Size Quantization）实现</span>
<span class="n">class</span><span class="w"> </span><span class="n">LearnedStepSizeQuantizer</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_scale</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_grad_scale</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">init_scale</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_bits</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">compute_scale_gradient</span><span class="p">(</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">grad_out</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">Qn</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="p">(</span><span class="n">num_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">Qp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">Qn</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 量化值</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">);</span>
<span class="w">        </span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">Qp</span><span class="p">,</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="n">Qn</span><span class="p">,</span><span class="w"> </span><span class="n">q</span><span class="p">));</span>

<span class="w">        </span><span class="c1">// scale的梯度</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">grad_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">Qn</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="n">q</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">Qp</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 饱和区域</span>
<span class="w">            </span><span class="n">grad_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad_out</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">q</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 线性区域</span>
<span class="w">            </span><span class="n">grad_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">grad_out</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">q</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">grad_scale</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h3 id="2322">23.2.2 梯度的量化处理</h3>
<p>梯度量化和裁剪对QAT的稳定性至关重要。</p>
<p><strong>梯度缩放：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 自适应梯度缩放</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">adaptive_gradient_scaling_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">gradients</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">quantized_weights</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">full_precision_weights</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scaling_factors</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">shared_norm</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 计算量化误差</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fabsf</span><span class="p">(</span><span class="n">quantized_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">full_precision_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 规约求平均误差</span>
<span class="w">    </span><span class="n">shared_norm</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">error</span><span class="p">;</span>
<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">shared_norm</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">shared_norm</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 根据误差调整梯度</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">avg_error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shared_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0f</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">avg_error</span><span class="p">);</span>
<span class="w">        </span><span class="n">gradients</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>梯度裁剪与正则化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 感知量化的梯度裁剪</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">quantization_aware_gradient_clipping</span><span class="p">(</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">gradients</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">weights</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">clip_value</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_bits</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 根据量化比特数调整裁剪阈值</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">bit_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">powf</span><span class="p">(</span><span class="mf">2.0f</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">num_bits</span><span class="p">);</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">adjusted_clip</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clip_value</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">bit_scale</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 应用梯度裁剪</span>
<span class="w">        </span><span class="n">gradients</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="o">-</span><span class="n">adjusted_clip</span><span class="p">,</span><span class="w"> </span>
<span class="w">                              </span><span class="n">fminf</span><span class="p">(</span><span class="n">adjusted_clip</span><span class="p">,</span><span class="w"> </span><span class="n">gradients</span><span class="p">[</span><span class="n">idx</span><span class="p">]));</span>

<span class="w">        </span><span class="c1">// 添加量化正则化项</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">quant_reg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.01f</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]));</span>
<span class="w">        </span><span class="n">gradients</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">quant_reg</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2323">23.2.3 批归一化融合</h3>
<p>批归一化（BN）与量化的融合能减少推理时的计算量和内存访问。</p>
<p><strong>BN折叠公式：</strong></p>
<div class="codehilite"><pre><span></span><code>BN(x) = γ <span class="gs">* (x - μ) / √(σ² + ε) + β</span>
<span class="gs">折叠后：W&#39; = W *</span> γ / √(σ² + ε)
        b&#39; = β - μ * γ / √(σ² + ε)
</code></pre></div>

<p><strong>CUDA实现：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// BN参数折叠到卷积权重</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">fold_bn_to_conv_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">conv_weight</span><span class="p">,</span><span class="w">      </span><span class="c1">// [OC, IC, KH, KW]</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">conv_bias</span><span class="p">,</span><span class="w">        </span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">bn_scale</span><span class="p">,</span><span class="w">   </span><span class="c1">// γ</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">bn_bias</span><span class="p">,</span><span class="w">    </span><span class="c1">// β</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">bn_mean</span><span class="p">,</span><span class="w">    </span><span class="c1">// μ</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">bn_var</span><span class="p">,</span><span class="w">     </span><span class="c1">// σ²</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">epsilon</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">OC</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">IC</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">K</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">oc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">oc</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">OC</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bn_scale</span><span class="p">[</span><span class="n">oc</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sqrtf</span><span class="p">(</span><span class="n">bn_var</span><span class="p">[</span><span class="n">oc</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">epsilon</span><span class="p">);</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">bias</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bn_bias</span><span class="p">[</span><span class="n">oc</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">bn_mean</span><span class="p">[</span><span class="n">oc</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 更新卷积权重</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">IC</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">weight_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">oc</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">IC</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="n">conv_weight</span><span class="p">[</span><span class="n">weight_idx</span><span class="p">]</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 更新偏置</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">conv_bias</span><span class="p">[</span><span class="n">oc</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bias</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 量化感知的BN训练</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">quantization_aware_bn_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">running_mean</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">running_var</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">bias</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">momentum</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">N</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">HW</span><span class="p">,</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">training</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">c</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">C</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 计算当前批次的均值和方差</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="n">sum_sq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">HW</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">                </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">                </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
<span class="w">                </span><span class="n">sum_sq</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// Warp级规约</span>
<span class="w">        </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduceSum</span><span class="p">(</span><span class="n">sum</span><span class="p">);</span>
<span class="w">        </span><span class="n">sum_sq</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduceSum</span><span class="p">(</span><span class="n">sum_sq</span><span class="p">);</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="p">);</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">var</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum_sq</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">N</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">mean</span><span class="p">;</span>

<span class="w">            </span><span class="c1">// 更新running statistics</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">training</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">running_mean</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">momentum</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">running_mean</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">                                  </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">momentum</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">mean</span><span class="p">;</span>
<span class="w">                </span><span class="n">running_var</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">momentum</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">running_var</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">                                 </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">momentum</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">var</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>

<span class="w">            </span><span class="c1">// 应用BN变换（考虑量化）</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">inv_std</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rsqrtf</span><span class="p">(</span><span class="n">var</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1e-5f</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// 量化scale和bias</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">q_scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fake_quantize</span><span class="p">(</span><span class="n">scale</span><span class="p">[</span><span class="n">c</span><span class="p">],</span><span class="w"> </span><span class="mi">8</span><span class="p">);</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">q_bias</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fake_quantize</span><span class="p">(</span><span class="n">bias</span><span class="p">[</span><span class="n">c</span><span class="p">],</span><span class="w"> </span><span class="mi">8</span><span class="p">);</span>

<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="n">n</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">HW</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">C</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">HW</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">                    </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q_scale</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inv_std</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">q_bias</span><span class="p">;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2324">23.2.4 训练策略与技巧</h3>
<p><strong>渐进式量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 动态调整量化比特数</span>
<span class="n">class</span><span class="w"> </span><span class="n">ProgressiveQuantization</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">start_bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">target_bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">current_epoch</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">total_epochs</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">get_current_bits</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">progress</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">current_epoch</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total_epochs</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">start_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="p">)(</span><span class="n">progress</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="n">start_bits</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">target_bits</span><span class="p">));</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="n">target_bits</span><span class="p">,</span><span class="w"> </span><span class="n">bits</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">progressive_quantize_kernel</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">        </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_current_bits</span><span class="p">();</span>

<span class="w">            </span><span class="c1">// 根据当前比特数量化</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_scale</span><span class="p">(</span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="n">bits</span><span class="p">);</span>
<span class="w">            </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fake_quantize</span><span class="p">(</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span><span class="w"> </span><span class="n">bits</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>知识蒸馏辅助：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用教师模型指导量化训练</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">distillation_loss_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">student_logits</span><span class="p">,</span><span class="w">  </span><span class="c1">// 量化模型输出</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">teacher_logits</span><span class="p">,</span><span class="w">  </span><span class="c1">// 全精度模型输出</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">loss</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">temperature</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_classes</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">num_classes</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">total</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">num_classes</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">num_classes</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 计算软标签</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">student_soft</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expf</span><span class="p">(</span><span class="n">student_logits</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">temperature</span><span class="p">);</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">teacher_soft</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">expf</span><span class="p">(</span><span class="n">teacher_logits</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">temperature</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// KL散度损失</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">kl_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">teacher_soft</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">logf</span><span class="p">(</span><span class="n">teacher_soft</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">student_soft</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1e-8f</span><span class="p">);</span>

<span class="w">        </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">loss</span><span class="p">[</span><span class="n">b</span><span class="p">],</span><span class="w"> </span><span class="n">kl_loss</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">temperature</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">temperature</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2325">23.2.5 混合精度训练集成</h3>
<p>将QAT与自动混合精度（AMP）结合，加速训练过程。</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 混合精度量化感知训练</span>
<span class="n">template</span><span class="o">&lt;</span><span class="n">typename</span><span class="w"> </span><span class="n">T</span><span class="o">&gt;</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mixed_precision_qat_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w">           </span><span class="c1">// FP16输入</span>
<span class="w">    </span><span class="n">T</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w">               </span><span class="c1">// FP16输出</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">master_weights</span><span class="p">,</span><span class="w">   </span><span class="c1">// FP32主权重</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">quantized_weights</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scales</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">learning_rate</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// FP32计算</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">fp32_input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__half2float</span><span class="p">(</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]);</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">fp32_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">master_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>

<span class="w">        </span><span class="c1">// 伪量化</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scales</span><span class="p">[</span><span class="n">idx</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">128</span><span class="p">];</span><span class="w">  </span><span class="c1">// 分组量化</span>
<span class="w">        </span><span class="kt">int8_t</span><span class="w"> </span><span class="n">q_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2int_rn</span><span class="p">(</span><span class="n">fp32_weight</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">);</span>
<span class="w">        </span><span class="n">q_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">-128</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">127</span><span class="p">,</span><span class="w"> </span><span class="n">q_weight</span><span class="p">));</span>
<span class="w">        </span><span class="n">quantized_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q_weight</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 反量化用于前向传播</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">dq_weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">q_weight</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 计算输出（FP16）</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2half</span><span class="p">(</span><span class="n">fp32_input</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dq_weight</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 更新FP32主权重</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">gradient</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compute_gradient</span><span class="p">(...);</span>
<span class="w">        </span><span class="n">master_weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-=</span><span class="w"> </span><span class="n">learning_rate</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">gradient</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 动态损失缩放</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">dynamic_loss_scaling_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">loss</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale_factor</span><span class="p">,</span>
<span class="w">    </span><span class="kt">bool</span><span class="w"> </span><span class="n">overflow_detected</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">overflow_detected</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="o">*</span><span class="n">scale_factor</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mf">0.5f</span><span class="p">;</span><span class="w">  </span><span class="c1">// 减小scale</span>
<span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="o">*</span><span class="n">scale_factor</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span><span class="w">   </span><span class="c1">// 增大scale</span>
<span class="w">            </span><span class="o">*</span><span class="n">scale_factor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="o">*</span><span class="n">scale_factor</span><span class="p">,</span><span class="w"> </span><span class="mf">65536.0f</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="o">*</span><span class="n">loss</span><span class="w"> </span><span class="o">*=</span><span class="w"> </span><span class="o">*</span><span class="n">scale_factor</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="233">23.3 动态量化策略</h2>
<p>动态量化在推理时根据输入数据动态计算量化参数，特别适合激活值分布变化较大的场景。虽然增加了运行时开销，但能显著提高量化精度，是自动驾驶等安全关键应用的首选方案。</p>
<h3 id="2331">23.3.1 动态范围校准</h3>
<p><strong>统计信息收集：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 高效的min/max统计内核</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">collect_minmax_stats_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">min_vals</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">max_vals</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">num_blocks</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="k">extern</span><span class="w"> </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">shared_mem</span><span class="p">[];</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">s_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">shared_mem</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">s_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="n">shared_mem</span><span class="p">[</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 初始化局部最值</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">local_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">FLT_MAX</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">FLT_MAX</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 网格步进遍历</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="w">        </span><span class="n">local_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="n">local_min</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">        </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">local_max</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">s_min</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_min</span><span class="p">;</span>
<span class="w">    </span><span class="n">s_max</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_max</span><span class="p">;</span>
<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 块内规约</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">&gt;&gt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">s</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_min</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="n">s_min</span><span class="p">[</span><span class="n">tid</span><span class="p">],</span><span class="w"> </span><span class="n">s_min</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">]);</span>
<span class="w">            </span><span class="n">s_max</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">s_max</span><span class="p">[</span><span class="n">tid</span><span class="p">],</span><span class="w"> </span><span class="n">s_max</span><span class="p">[</span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">s</span><span class="p">]);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 写回全局内存</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">min_vals</span><span class="p">[</span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s_min</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">        </span><span class="n">max_vals</span><span class="p">[</span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s_max</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 百分位数计算（用于异常值处理）</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">percentile_calibration_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">sorted_input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">zero_point</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">percentile</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.999f</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">lower_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="p">)(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0f</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">percentile</span><span class="p">));</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">upper_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="p">)(</span><span class="n">n</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">percentile</span><span class="p">);</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">min_val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sorted_input</span><span class="p">[</span><span class="n">lower_idx</span><span class="p">];</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">max_val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sorted_input</span><span class="p">[</span><span class="n">upper_idx</span><span class="p">];</span>

<span class="w">        </span><span class="c1">// 计算量化参数</span>
<span class="w">        </span><span class="o">*</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">max_val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">min_val</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span>
<span class="w">        </span><span class="o">*</span><span class="n">zero_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="o">-</span><span class="n">min_val</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="o">*</span><span class="n">scale</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>KL散度校准：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// TensorRT风格的KL散度校准</span>
<span class="n">class</span><span class="w"> </span><span class="n">KLDivergenceCalibrator</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="k">static</span><span class="w"> </span><span class="n">constexpr</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">NUM_BINS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2048</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_histogram</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_reference_dist</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">build_histogram_kernel</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">        </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">histogram</span><span class="p">,</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">min_val</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">max_val</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">shared_hist</span><span class="p">[</span><span class="n">NUM_BINS</span><span class="p">];</span>

<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 初始化共享内存</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NUM_BINS</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">shared_hist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 构建直方图</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">bin_width</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">max_val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">min_val</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">NUM_BINS</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">bin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">((</span><span class="kt">int</span><span class="p">)((</span><span class="n">val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">min_val</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">bin_width</span><span class="p">),</span><span class="w"> </span><span class="n">NUM_BINS</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">            </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">shared_hist</span><span class="p">[</span><span class="n">bin</span><span class="p">],</span><span class="w"> </span><span class="mf">1.0f</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 写回全局内存</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">NUM_BINS</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">histogram</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">shared_hist</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">compute_kl_divergence</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">P</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">Q</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">kl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">kl</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">logf</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">kl</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h3 id="2332">23.3.2 激活值量化</h3>
<p><strong>在线激活量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 融合的激活量化内核</span>
<span class="n">template</span><span class="o">&lt;</span><span class="n">typename</span><span class="w"> </span><span class="n">ActivationType</span><span class="o">&gt;</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">fused_activation_quantize_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">running_min</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">running_max</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">momentum</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 计算激活值</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">activated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">constexpr</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">ActivationType</span><span class="p">,</span><span class="w"> </span><span class="n">ReLU</span><span class="o">&gt;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">activated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="mf">0.0f</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]);</span>
<span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">constexpr</span><span class="w"> </span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">is_same_v</span><span class="o">&lt;</span><span class="n">ActivationType</span><span class="p">,</span><span class="w"> </span><span class="n">SiLU</span><span class="o">&gt;</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">activated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">expf</span><span class="p">(</span><span class="o">-</span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">]));</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 更新统计信息（使用原子操作）</span>
<span class="w">    </span><span class="n">atomicMin</span><span class="p">(</span><span class="n">running_min</span><span class="p">,</span><span class="w"> </span><span class="n">activated</span><span class="p">);</span>
<span class="w">    </span><span class="n">atomicMax</span><span class="p">(</span><span class="n">running_max</span><span class="p">,</span><span class="w"> </span><span class="n">activated</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 动态量化</span>
<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span><span class="w">  </span><span class="c1">// 确保统计更新完成</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="n">running_max</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="o">*</span><span class="n">running_min</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">zero_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-*</span><span class="n">running_min</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>

<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">quantized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">activated</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">zero_point</span><span class="p">);</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">-128</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">127</span><span class="p">,</span><span class="w"> </span><span class="n">quantized</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>层级动态量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 逐层动态量化管理器</span>
<span class="n">class</span><span class="w"> </span><span class="n">LayerWiseDynamicQuantizer</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">LayerStats</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">min_val</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">max_val</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">zero_point</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">calibration_batches</span><span class="p">;</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">LayerStats</span><span class="o">*</span><span class="w"> </span><span class="n">d_layer_stats</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_layers</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">update_layer_stats_kernel</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">activation</span><span class="p">,</span>
<span class="w">        </span><span class="n">LayerStats</span><span class="o">*</span><span class="w"> </span><span class="n">stats</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">layer_id</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="c1">// 使用CUB进行高效规约</span>
<span class="w">        </span><span class="k">typedef</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">BlockReduce</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="o">&gt;</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">;</span>
<span class="w">        </span><span class="kt">__shared__</span><span class="w"> </span><span class="n">typename</span><span class="w"> </span><span class="n">BlockReduce</span><span class="o">::</span><span class="n">TempStorage</span><span class="w"> </span><span class="n">temp_storage</span><span class="p">;</span>

<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">activation</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">block_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Reduce</span><span class="p">(</span><span class="n">val</span><span class="p">,</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">Min</span><span class="p">());</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">block_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BlockReduce</span><span class="p">(</span><span class="n">temp_storage</span><span class="p">).</span><span class="n">Reduce</span><span class="p">(</span><span class="n">val</span><span class="p">,</span><span class="w"> </span><span class="n">cub</span><span class="o">::</span><span class="n">Max</span><span class="p">());</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 更新层统计信息</span>
<span class="w">            </span><span class="n">atomicMin</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">min_val</span><span class="p">,</span><span class="w"> </span><span class="n">block_min</span><span class="p">);</span>
<span class="w">            </span><span class="n">atomicMax</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">max_val</span><span class="p">,</span><span class="w"> </span><span class="n">block_max</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// 重新计算量化参数</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">max_val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">min_val</span><span class="p">;</span>
<span class="w">            </span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span>
<span class="w">            </span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">zero_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>
<span class="w">                </span><span class="n">roundf</span><span class="p">(</span><span class="o">-</span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">min_val</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stats</span><span class="p">[</span><span class="n">layer_id</span><span class="p">].</span><span class="n">scale</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h3 id="2333">23.3.3 自适应量化</h3>
<p><strong>输入感知量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 基于输入特征的自适应量化</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">input_aware_quantization_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scales</span><span class="p">,</span><span class="w">      </span><span class="c1">// 每个样本的scale</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">zero_points</span><span class="p">,</span><span class="w">   </span><span class="c1">// 每个样本的zero_point</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">batch_size</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">feature_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w">  </span><span class="c1">// batch index</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">bid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">batch_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 计算每个样本的统计信息</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">local_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">FLT_MAX</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">FLT_MAX</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">feature_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">feature_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="n">local_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fminf</span><span class="p">(</span><span class="n">local_min</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">            </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fmaxf</span><span class="p">(</span><span class="n">local_max</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// Warp级规约</span>
<span class="w">        </span><span class="n">local_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduceMin</span><span class="p">(</span><span class="n">local_min</span><span class="p">);</span>
<span class="w">        </span><span class="n">local_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warpReduceMax</span><span class="p">(</span><span class="n">local_max</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 计算自适应量化参数</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">range</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">local_max</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">local_min</span><span class="p">;</span>

<span class="w">            </span><span class="c1">// 根据范围选择量化策略</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">range</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.1f</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// 小范围：使用更高精度</span>
<span class="w">                </span><span class="n">scales</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">127.0f</span><span class="p">;</span>
<span class="w">                </span><span class="n">zero_points</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w">  </span><span class="c1">// 对称量化</span>
<span class="w">            </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// 大范围：标准量化</span>
<span class="w">                </span><span class="n">scales</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span>
<span class="w">                </span><span class="n">zero_points</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="o">-</span><span class="n">local_min</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scales</span><span class="p">[</span><span class="n">bid</span><span class="p">]);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 应用量化</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">feature_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">feature_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">quantized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scales</span><span class="p">[</span><span class="n">bid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">zero_points</span><span class="p">[</span><span class="n">bid</span><span class="p">]);</span>
<span class="w">            </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">-128</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">127</span><span class="p">,</span><span class="w"> </span><span class="n">quantized</span><span class="p">));</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="2334">23.3.4 运行时优化</h3>
<p><strong>量化参数缓存：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// LRU缓存管理量化参数</span>
<span class="n">template</span><span class="o">&lt;</span><span class="kt">int</span><span class="w"> </span><span class="n">CACHE_SIZE</span><span class="o">&gt;</span>
<span class="n">class</span><span class="w"> </span><span class="n">QuantizationCache</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">CacheEntry</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">hash</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">zero_point</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">timestamp</span><span class="p">;</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">CacheEntry</span><span class="w"> </span><span class="n">cache</span><span class="p">[</span><span class="n">CACHE_SIZE</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">current_time</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">lookup</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">hash</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">&amp;</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">&amp;</span><span class="w"> </span><span class="n">zero_point</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">CACHE_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">hash</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">hash</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">timestamp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current_time</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">                </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scale</span><span class="p">;</span>
<span class="w">                </span><span class="n">zero_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">zero_point</span><span class="p">;</span>
<span class="w">                </span><span class="k">return</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">insert</span><span class="p">(</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">hash</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">zero_point</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 找到最老的条目</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">lru_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">min_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">timestamp</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">CACHE_SIZE</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">timestamp</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min_time</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">min_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cache</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">timestamp</span><span class="p">;</span>
<span class="w">                </span><span class="n">lru_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 更新缓存</span>
<span class="w">        </span><span class="n">cache</span><span class="p">[</span><span class="n">lru_idx</span><span class="p">].</span><span class="n">hash</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">hash</span><span class="p">;</span>
<span class="w">        </span><span class="n">cache</span><span class="p">[</span><span class="n">lru_idx</span><span class="p">].</span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="n">cache</span><span class="p">[</span><span class="n">lru_idx</span><span class="p">].</span><span class="n">zero_point</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">zero_point</span><span class="p">;</span>
<span class="w">        </span><span class="n">cache</span><span class="p">[</span><span class="n">lru_idx</span><span class="p">].</span><span class="n">timestamp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">current_time</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<p><strong>流水线量化：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 异步量化流水线</span>
<span class="n">class</span><span class="w"> </span><span class="n">AsyncQuantizationPipeline</span><span class="w"> </span><span class="p">{</span>
<span class="n">private</span><span class="o">:</span>
<span class="w">    </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">compute_stream</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">quantize_stream</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaEvent_t</span><span class="o">*</span><span class="w"> </span><span class="n">events</span><span class="p">;</span>

<span class="n">public</span><span class="o">:</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="n">process_batch</span><span class="p">(</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">batch_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">batch_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// 在compute_stream中计算统计信息</span>
<span class="w">            </span><span class="n">collect_stats</span><span class="o">&lt;&lt;&lt;</span><span class="p">...,</span><span class="w"> </span><span class="n">compute_stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">                </span><span class="n">input</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">feature_size</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>

<span class="w">            </span><span class="c1">// 记录事件</span>
<span class="w">            </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">events</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">compute_stream</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// 在quantize_stream中执行量化</span>
<span class="w">            </span><span class="n">cudaStreamWaitEvent</span><span class="p">(</span><span class="n">quantize_stream</span><span class="p">,</span><span class="w"> </span><span class="n">events</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">            </span><span class="n">apply_quantization</span><span class="o">&lt;&lt;&lt;</span><span class="p">...,</span><span class="w"> </span><span class="n">quantize_stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">                </span><span class="n">input</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">feature_size</span><span class="p">,</span>
<span class="w">                </span><span class="n">output</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">feature_size</span><span class="p">,</span><span class="w"> </span><span class="p">...);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
</code></pre></div>

<h3 id="2335">23.3.5 性能与精度权衡</h3>
<p><strong>混合位宽策略：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 层级混合精度量化</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mixed_bitwidth_quantization_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span>
<span class="w">    </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w">  </span><span class="c1">// 可能是int4/int8/fp16</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">layer_bitwidths</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">layer_id</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">bits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer_bitwidths</span><span class="p">[</span><span class="n">layer_id</span><span class="p">];</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>

<span class="w">        </span><span class="k">switch</span><span class="p">(</span><span class="n">bits</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">case</span><span class="w"> </span><span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// INT4量化</span>
<span class="w">                </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">out4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int8_t</span><span class="o">*</span><span class="p">)</span><span class="n">output</span><span class="p">;</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">quantized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">roundf</span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">7.0f</span><span class="p">);</span><span class="w">  </span><span class="c1">// [-8, 7]</span>
<span class="w">                </span><span class="n">quantized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max</span><span class="p">(</span><span class="mi">-8</span><span class="p">,</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="n">quantized</span><span class="p">));</span>

<span class="w">                </span><span class="c1">// 打包两个INT4到一个INT8</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">out4</span><span class="p">[</span><span class="n">idx</span><span class="o">/</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">quantized</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">;</span>
<span class="w">                </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">out4</span><span class="p">[</span><span class="n">idx</span><span class="o">/</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">|=</span><span class="w"> </span><span class="p">(</span><span class="n">quantized</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x0F</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">                </span><span class="k">break</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="k">case</span><span class="w"> </span><span class="mi">8</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// INT8量化</span>
<span class="w">                </span><span class="kt">int8_t</span><span class="o">*</span><span class="w"> </span><span class="n">out8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">int8_t</span><span class="o">*</span><span class="p">)</span><span class="n">output</span><span class="p">;</span>
<span class="w">                </span><span class="n">out8</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2int_rn</span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">127.0f</span><span class="p">);</span>
<span class="w">                </span><span class="k">break</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="k">case</span><span class="w"> </span><span class="mi">16</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="c1">// FP16</span>
<span class="w">                </span><span class="n">half</span><span class="o">*</span><span class="w"> </span><span class="n">out16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">half</span><span class="o">*</span><span class="p">)</span><span class="n">output</span><span class="p">;</span>
<span class="w">                </span><span class="n">out16</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__float2half</span><span class="p">(</span><span class="n">val</span><span class="p">);</span>
<span class="w">                </span><span class="k">break</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 敏感度分析</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">sensitivity_analysis_kernel</span><span class="p">(</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">original_output</span><span class="p">,</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">quantized_output</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">sensitivity_scores</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">num_layers</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">layer_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">layer</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">num_layers</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">error_sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0f</span><span class="p">;</span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">layer_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">layer_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">original_output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">quantized_output</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="n">error_sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">diff</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 规约计算MSE</span>
<span class="w">        </span><span class="n">error_sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockReduceSum</span><span class="p">(</span><span class="n">error_sum</span><span class="p">);</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">sensitivity_scores</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrtf</span><span class="p">(</span><span class="n">error_sum</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">layer_size</span><span class="p">);</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="234">23.4 自定义量化算子</h2>
<h3 id="2341-gemm">23.4.1 量化GEMM实现</h3>
<h3 id="2342">23.4.2 量化卷积优化</h3>
<h3 id="2343">23.4.3 特殊激活函数处理</h3>
<h3 id="2344">23.4.4 融合算子设计</h3>
<h3 id="2345-tensorrt">23.4.5 TensorRT集成</h3>
<h2 id="235">23.5 案例：超低比特推理</h2>
<h3 id="2351">23.5.1 场景需求分析</h3>
<h3 id="2352">23.5.2 模型量化流程</h3>
<h3 id="2353-cuda">23.5.3 CUDA内核实现</h3>
<h3 id="2354">23.5.4 性能优化</h3>
<h3 id="2355">23.5.5 精度恢复技术</h3>
<h2 id="_1">本章小结</h2>
<h2 id="_2">练习题</h2>
<h2 id="gotchas">常见陷阱与错误 (Gotchas)</h2>
<h2 id="_3">最佳实践检查清单</h2>
            </article>
            
            <nav class="page-nav"><a href="chapter22.html" class="nav-link prev">← 第22章：稀疏计算与动态稀疏</a><a href="chapter24.html" class="nav-link next">第24章：新一代GPU特性展望 →</a></nav>
        </main>
    </div>
</body>
</html>