<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第3章：全局内存优化策略</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">CUDA 高性能编程实战教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第1章：CUDA硬件架构深度剖析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第2章：CUDA编程模型与执行模型</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第3章：全局内存优化策略</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第4章：共享内存与Bank Conflict</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第5章：寄存器优化与常量内存</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第6章：Warp级编程与协作组</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第7章：原子操作与同步原语</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第8章：PTX内联与底层优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第9章：张量核心与混合精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第10章：CUTLASS深度解析</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第11章：激光雷达点云处理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第12章：多传感器融合的并行化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第13章：实时语义分割与实例分割</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第14章：路径规划与轨迹优化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第15章：视觉SLAM的GPU加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第16章：机械臂运动规划</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第17章：强化学习推理加速</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第18章：大规模点云重建与网格化</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第19章：多GPU编程与扩展</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第20章：CUDA Graph与内核融合</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第21章：嵌入式GPU开发（Jetson）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第22章：稀疏计算与动态稀疏</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第23章：量化与低精度计算</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第24章：新一代GPU特性展望</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第25章：性能分析与调优方法论</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第26章：CUDA调试技术与错误处理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter27.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第27章：开发环境与工具链配置</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="3">第3章：全局内存优化策略</h1>
<p>全局内存是CUDA编程中最基础也是最关键的内存类型。作为GPU上容量最大的内存空间，全局内存承载着绝大部分的数据存储和传输任务。然而，它也是延迟最高的内存层级，一次未优化的全局内存访问可能需要数百个时钟周期。在自动驾驶的激光雷达点云处理或具身智能的高分辨率视觉SLAM中，每秒需要处理GB级别的数据，内存带宽往往成为制约系统性能的主要瓶颈。本章将深入探讨全局内存的访问机制，掌握合并访问、缓存优化、向量化等关键技术，最终实现接近硬件理论峰值的内存带宽利用率。</p>
<h2 id="31">3.1 内存合并访问模式</h2>
<h3 id="311">3.1.1 合并访问的硬件机制</h3>
<p>当一个warp（32个线程）执行内存访问指令时，硬件会尝试将这些访问合并成尽可能少的内存事务。现代GPU支持32字节、64字节和128字节三种事务大小，选择哪种取决于访问的地址分布和数据量。</p>
<div class="codehilite"><pre><span></span><code><span class="nx">内存事务生成规则</span><span class="err">：</span>
<span class="err">┌─────────────────────────────────────────────┐</span>
<span class="err">│</span><span class="w">  </span><span class="nx">Warp内32个线程的内存请求</span><span class="w">                    </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="nx">Thread</span><span class="w"> </span><span class="mi">0</span><span class="p">:</span><span class="w"> </span><span class="nx">addr_0</span><span class="w">                           </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="nx">Thread</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="nx">addr_1</span><span class="w">                           </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="o">...</span><span class="w">                                        </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="nx">Thread</span><span class="w"> </span><span class="mi">31</span><span class="p">:</span><span class="w"> </span><span class="nx">addr_31</span><span class="w">                         </span><span class="err">│</span>
<span class="err">└─────────────┬───────────────────────────────┘</span>
<span class="w">              </span><span class="err">↓</span>
<span class="err">┌─────────────────────────────────────────────┐</span>
<span class="err">│</span><span class="w">  </span><span class="nx">硬件合并逻辑</span><span class="w">                               </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="nx">计算最小和最大地址</span><span class="w">                       </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="nx">确定覆盖的128字节对齐段数量</span><span class="w">              </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="mi">3</span><span class="p">.</span><span class="w"> </span><span class="nx">生成1</span><span class="o">-</span><span class="mi">32</span><span class="nx">个内存事务</span><span class="w">                       </span><span class="err">│</span>
<span class="err">└─────────────┬───────────────────────────────┘</span>
<span class="w">              </span><span class="err">↓</span>
<span class="err">┌─────────────────────────────────────────────┐</span>
<span class="err">│</span><span class="w">  </span><span class="nx">内存事务</span><span class="err">（</span><span class="mi">32</span><span class="nx">B</span><span class="o">/</span><span class="mi">64</span><span class="nx">B</span><span class="o">/</span><span class="mi">128</span><span class="nx">B</span><span class="err">）</span><span class="w">                   </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="nx">事务1</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="nx">base_addr</span><span class="p">,</span><span class="w"> </span><span class="nx">base_addr</span><span class="o">+</span><span class="nx">size</span><span class="p">)</span><span class="w">         </span><span class="err">│</span>
<span class="err">│</span><span class="w">  </span><span class="nx">事务2</span><span class="p">:</span><span class="w"> </span><span class="o">...</span><span class="w">                                 </span><span class="err">│</span>
<span class="err">└─────────────────────────────────────────────┘</span>
</code></pre></div>

<p>理想情况下，如果warp内所有线程访问连续的内存地址，且起始地址128字节对齐，那么只需要一个128字节的事务即可完成全部访问。最坏情况下，如果每个线程访问的地址都分散在不同的128字节段中，则需要32个事务。</p>
<h3 id="312">3.1.2 合并访问模式分析</h3>
<p><strong>连续访问模式（Coalesced Access）</strong></p>
<p>最理想的访问模式，线程ID与内存地址呈线性关系：</p>
<div class="codehilite"><pre><span></span><code><span class="nc">float</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">N</span><span class="o">]</span><span class="p">;</span>
<span class="nc">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="nc">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">tid</span><span class="o">]</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">完美合并</span>

<span class="n">内存布局</span><span class="err">：</span>
<span class="nl">Thread</span><span class="p">:</span><span class="w">  </span><span class="mi">0</span><span class="w">   </span><span class="mi">1</span><span class="w">   </span><span class="mi">2</span><span class="w">   </span><span class="mi">3</span><span class="w">   </span><span class="mi">4</span><span class="w">   </span><span class="mi">5</span><span class="w">   </span><span class="mi">6</span><span class="w">   </span><span class="mi">7</span><span class="w">  </span><span class="p">...</span><span class="w">  </span><span class="mi">31</span>
<span class="nl">Address</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w">   </span><span class="mi">4</span><span class="w">   </span><span class="mi">8</span><span class="w">   </span><span class="mi">12</span><span class="w">  </span><span class="mi">16</span><span class="w">  </span><span class="mi">20</span><span class="w">  </span><span class="mi">24</span><span class="w">  </span><span class="mi">28</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="mi">124</span>
<span class="w">         </span><span class="err">└─────────────</span><span class="w"> </span><span class="mi">128</span><span class="n">字节</span><span class="w"> </span><span class="err">─────────────┘</span>
<span class="w">         </span><span class="n">生成1个128B事务</span>
</code></pre></div>

<p><strong>跨步访问模式（Strided Access）</strong></p>
<p>线程以固定步长访问内存，合并效率取决于步长大小：</p>
<div class="codehilite"><pre><span></span><code><span class="nc">float</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">N</span><span class="o">]</span><span class="p">;</span>
<span class="nc">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="nc">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">tid * stride</span><span class="o">]</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">跨步访问</span>

<span class="n">步长</span><span class="o">=</span><span class="mi">2</span><span class="n">时的内存布局</span><span class="err">：</span>
<span class="nl">Thread</span><span class="p">:</span><span class="w">  </span><span class="mi">0</span><span class="w">   </span><span class="mi">1</span><span class="w">   </span><span class="mi">2</span><span class="w">   </span><span class="mi">3</span><span class="w">   </span><span class="mi">4</span><span class="w">   </span><span class="mi">5</span><span class="w">   </span><span class="mi">6</span><span class="w">   </span><span class="mi">7</span><span class="w">  </span><span class="p">...</span><span class="w">  </span><span class="mi">31</span>
<span class="nl">Address</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w">   </span><span class="mi">8</span><span class="w">   </span><span class="mi">16</span><span class="w">  </span><span class="mi">24</span><span class="w">  </span><span class="mi">32</span><span class="w">  </span><span class="mi">40</span><span class="w">  </span><span class="mi">48</span><span class="w">  </span><span class="mi">56</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="mi">248</span>
<span class="w">         </span><span class="err">└────</span><span class="w"> </span><span class="mi">128</span><span class="n">B</span><span class="w"> </span><span class="err">────┘└────</span><span class="w"> </span><span class="mi">128</span><span class="n">B</span><span class="w"> </span><span class="err">────┘</span>
<span class="w">         </span><span class="n">生成2个128B事务</span><span class="err">，</span><span class="n">带宽利用率50</span><span class="o">%</span>

<span class="n">步长</span><span class="o">=</span><span class="mi">32</span><span class="n">时</span><span class="err">：</span>
<span class="n">每个线程访问不同的128B段</span><span class="err">，</span><span class="n">生成32个事务</span>
<span class="n">带宽利用率仅3</span><span class="mf">.125</span><span class="o">%</span><span class="err">（</span><span class="mi">4</span><span class="n">B</span><span class="o">/</span><span class="mi">128</span><span class="n">B</span><span class="err">）</span>
</code></pre></div>

<p><strong>随机访问模式（Random Access）</strong></p>
<p>最差的访问模式，通常出现在哈希表、稀疏数据结构中：</p>
<div class="codehilite"><pre><span></span><code><span class="nc">int</span><span class="w"> </span><span class="n">indices</span><span class="o">[</span><span class="n">N</span><span class="o">]</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">随机索引</span>
<span class="nc">float</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">M</span><span class="o">]</span><span class="p">;</span>
<span class="nc">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="nc">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">data</span><span class="o">[</span><span class="n">indices[tid</span><span class="o">]</span><span class="err">]</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">随机访问</span>

<span class="n">可能生成1</span><span class="o">-</span><span class="mi">32</span><span class="n">个事务</span><span class="err">，</span><span class="n">平均性能极差</span>
</code></pre></div>

<h3 id="313">3.1.3 优化策略</h3>
<p><strong>数据布局转换：AoS到SoA</strong></p>
<p>在自动驾驶场景中，点云数据常用结构体数组（AoS）表示：</p>
<div class="codehilite"><pre><span></span><code><span class="o">//</span><span class="w"> </span><span class="n">AoS布局</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">访问效率低</span>
<span class="n">struct</span><span class="w"> </span><span class="n">Point</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="n">intensity</span><span class="p">;</span>
<span class="w">    </span><span class="n">uint16_t</span><span class="w"> </span><span class="n">ring</span><span class="p">;</span>
<span class="w">    </span><span class="n">uint16_t</span><span class="w"> </span><span class="n">padding</span><span class="p">;</span>
<span class="err">}</span><span class="p">;</span>
<span class="n">Point</span><span class="w"> </span><span class="n">points</span><span class="o">[</span><span class="n">N</span><span class="o">]</span><span class="p">;</span>

<span class="o">//</span><span class="w"> </span><span class="n">访问x坐标时</span><span class="err">，</span><span class="n">实际读取了整个结构体</span>
<span class="nc">float</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">points</span><span class="o">[</span><span class="n">tid</span><span class="o">]</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">读取16字节</span><span class="err">，</span><span class="n">只用4字节</span>
<span class="o">//</span><span class="w"> </span><span class="n">带宽利用率</span><span class="err">：</span><span class="mi">4</span><span class="o">/</span><span class="mi">16</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">25</span><span class="o">%</span>

<span class="o">//</span><span class="w"> </span><span class="n">SoA布局</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">访问效率高</span>
<span class="n">struct</span><span class="w"> </span><span class="n">PointCloud</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>
<span class="w">    </span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">z</span><span class="p">;</span>
<span class="w">    </span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">intensity</span><span class="p">;</span>
<span class="w">    </span><span class="n">uint16_t</span><span class="o">*</span><span class="w"> </span><span class="n">ring</span><span class="p">;</span>
<span class="err">}</span><span class="p">;</span>

<span class="o">//</span><span class="w"> </span><span class="n">访问x坐标</span><span class="err">，</span><span class="n">完美合并</span>
<span class="nc">float</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">point_cloud</span><span class="p">.</span><span class="n">x</span><span class="o">[</span><span class="n">tid</span><span class="o">]</span><span class="p">;</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">带宽利用率100</span><span class="o">%</span>
</code></pre></div>

<p><strong>访问模式重组</strong></p>
<p>通过改变计算顺序或使用共享内存缓冲，将随机访问转换为合并访问：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 原始：随机访问</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">scatter_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">out</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">tid</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span><span class="w">  </span><span class="c1">// 随机写</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 优化：使用原子操作+排序</span>
<span class="c1">// 1. 先对indices排序</span>
<span class="c1">// 2. 使用分段的合并写入</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">scatter_optimized</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                  </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">sorted_indices</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">segment_starts</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                  </span><span class="kt">int</span><span class="w"> </span><span class="n">n_segments</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 每个block处理一个segment，保证合并写入</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">seg_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment_starts</span><span class="p">[</span><span class="n">seg_id</span><span class="p">];</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">end</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">segment_starts</span><span class="p">[</span><span class="n">seg_id</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">];</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">start</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">end</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">out</span><span class="p">[</span><span class="n">sorted_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w">  </span><span class="c1">// segment内合并写</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="32">3.2 缓存行为与配置</h2>
<h3 id="321-l1l2">3.2.1 L1/L2缓存架构</h3>
<p>现代GPU的缓存层次结构在不同架构间有显著差异：</p>
<div class="codehilite"><pre><span></span><code>Volta/Turing架构（V100/RTX 2080）：
┌──────────────────────────────────┐
│         SM (流多处理器)           │
│  ┌────────────────────────────┐  │
│  │  L1 Data Cache (128KB)     │  │  ← 与共享内存统一
│  │  + Shared Memory            │  │     可配置分割
│  └────────────┬───────────────┘  │
│               ↓                   │
└───────────────┼───────────────────┘
                ↓
┌──────────────────────────────────┐
│      L2 Cache (6MB)              │  ← 全局共享
└──────────────┬───────────────────┘
                ↓
┌──────────────────────────────────┐
│    Global Memory (HBM2)          │
└──────────────────────────────────┘

Ampere架构（A100/RTX 3090）：

- L1: 192KB每SM（可配置）
- L2: 40MB（A100）或 6MB（RTX 3090）
- 新增异步拷贝指令，支持绕过L1

Hopper架构（H100）：

- L1: 256KB每SM
- L2: 50MB
- 新增TMA（Tensor Memory Accelerator）单元
</code></pre></div>

<p>缓存行为的关键参数：</p>
<ul>
<li><strong>缓存行大小</strong>：128字节（所有架构统一）</li>
<li><strong>L1缓存策略</strong>：写穿（write-through），读时缓存</li>
<li><strong>L2缓存策略</strong>：写回（write-back），支持原子操作缓存</li>
</ul>
<h3 id="322">3.2.2 缓存配置与控制</h3>
<p><strong>配置L1缓存大小</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 配置kernel的L1缓存偏好</span>
<span class="n">cudaFuncSetCacheConfig</span><span class="p">(</span><span class="n">my_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">cudaFuncCachePreferL1</span><span class="p">);</span><span class="w">    </span><span class="c1">// 偏好L1</span>
<span class="n">cudaFuncSetCacheConfig</span><span class="p">(</span><span class="n">my_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">cudaFuncCachePreferShared</span><span class="p">);</span><span class="w"> </span><span class="c1">// 偏好共享内存</span>
<span class="n">cudaFuncSetCacheConfig</span><span class="p">(</span><span class="n">my_kernel</span><span class="p">,</span><span class="w"> </span><span class="n">cudaFuncCachePreferEqual</span><span class="p">);</span><span class="w">  </span><span class="c1">// 均衡分配</span>

<span class="c1">// Volta+架构的动态配置</span>
<span class="n">cudaFuncSetAttribute</span><span class="p">(</span><span class="n">my_kernel</span><span class="p">,</span>
<span class="w">    </span><span class="n">cudaFuncAttributePreferredSharedMemoryCarveout</span><span class="p">,</span>
<span class="w">    </span><span class="n">cudaSharedmemCarveoutMaxL1</span><span class="p">);</span><span class="w">  </span><span class="c1">// 最大化L1缓存</span>
</code></pre></div>

<p><strong>使用只读缓存路径</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// __ldg内在函数：通过只读缓存路径加载</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="kt">__restrict__</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 普通加载：通过L1/L2</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">val1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 只读缓存加载：通过纹理缓存路径</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">val2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__ldg</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">]);</span>

<span class="w">    </span><span class="c1">// const __restrict__也会启用只读缓存</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="kt">__restrict__</span><span class="w"> </span><span class="n">ro_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">val3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ro_data</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>缓存绕过策略</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用向量化加载绕过L1（Ampere+）</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">streaming_kernel</span><span class="p">(</span><span class="kt">float4</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 流式访问，不污染L1缓存</span>
<span class="w">    </span><span class="kt">float4</span><span class="w"> </span><span class="n">val</span><span class="p">;</span>
<span class="w">    </span><span class="k">asm</span><span class="w"> </span><span class="k">volatile</span><span class="p">(</span><span class="s">&quot;ld.global.cs.v4.f32 {%0,%1,%2,%3}, [%4];&quot;</span>
<span class="w">                 </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;=f&quot;</span><span class="p">(</span><span class="n">val</span><span class="p">.</span><span class="n">x</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;=f&quot;</span><span class="p">(</span><span class="n">val</span><span class="p">.</span><span class="n">y</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;=f&quot;</span><span class="p">(</span><span class="n">val</span><span class="p">.</span><span class="n">z</span><span class="p">),</span><span class="w"> </span><span class="s">&quot;=f&quot;</span><span class="p">(</span><span class="n">val</span><span class="p">.</span><span class="n">w</span><span class="p">)</span>
<span class="w">                 </span><span class="o">:</span><span class="w"> </span><span class="s">&quot;l&quot;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">]));</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="323">3.2.3 缓存友好的访问模式</h3>
<p><strong>时间局部性优化</strong></p>
<p>在具身智能的传感器融合中，多次访问同一数据：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 差的时间局部性</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">sensor_fusion_bad</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">lidar</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">camera</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">imu</span><span class="p">,</span>
<span class="w">                                  </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 每个数据只访问一次，缓存无法发挥作用</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lidar</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">camera</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">imu</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.5f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.3f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.2f</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 好的时间局部性</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">sensor_fusion_good</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">lidar</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">camera</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">imu</span><span class="p">,</span>
<span class="w">                                   </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">window</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 使用滑动窗口，重复访问缓存中的数据</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">window</span><span class="p">;</span><span class="w"> </span><span class="n">w</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">l</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lidar</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">camera</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">imu</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>

<span class="w">            </span><span class="c1">// 时间序列滤波，多次访问相邻数据</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">filtered</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-2</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">nidx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">k</span><span class="p">;</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">nidx</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">nidx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="n">filtered</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">lidar</span><span class="p">[</span><span class="n">nidx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.2f</span><span class="p">;</span><span class="w">  </span><span class="c1">// 从缓存读取</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="n">output</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filtered</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.3f</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">0.2f</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>空间局部性优化</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 2D卷积的空间局部性优化</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">conv2d_optimized</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span>
<span class="w">                                 </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">kernel</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 使用2D thread block匹配2D数据布局</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 访问3x3邻域，利用空间局部性</span>
<span class="w">        </span><span class="cp">#pragma unroll</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">ky</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span><span class="w"> </span><span class="n">ky</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">ky</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="cp">#pragma unroll</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">kx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span><span class="w"> </span><span class="n">kx</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">kx</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">kx</span><span class="p">;</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">ky</span><span class="p">;</span>
<span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">nx</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">nx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">ny</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="c1">// 相邻线程访问相邻内存，提高缓存命中率</span>
<span class="w">                    </span><span class="n">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">ny</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nx</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">kernel</span><span class="p">[(</span><span class="n">ky</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">kx</span><span class="o">+</span><span class="mi">1</span><span class="p">)];</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="33-loadstore">3.3 向量化load/store操作</h2>
<h3 id="331">3.3.1 向量化访存原理</h3>
<p>GPU的内存控制器针对向量化访问进行了优化。使用float2、float4等向量类型可以：</p>
<ul>
<li>减少指令数量</li>
<li>提高内存吞吐量</li>
<li>改善指令级并行性</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="n">标量访问</span><span class="w"> </span><span class="n">vs</span><span class="w"> </span><span class="n">向量访问的指令生成</span><span class="err">：</span>

<span class="n">标量访问</span><span class="err">（</span><span class="mi">4</span><span class="n">条指令</span><span class="err">）：</span>
<span class="n">LD</span><span class="p">.</span><span class="n">E</span><span class="w"> </span><span class="n">R0</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">address+0</span><span class="o">]</span>
<span class="n">LD</span><span class="p">.</span><span class="n">E</span><span class="w"> </span><span class="n">R1</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">address+4</span><span class="o">]</span>
<span class="n">LD</span><span class="p">.</span><span class="n">E</span><span class="w"> </span><span class="n">R2</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">address+8</span><span class="o">]</span>
<span class="n">LD</span><span class="p">.</span><span class="n">E</span><span class="w"> </span><span class="n">R3</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">address+12</span><span class="o">]</span>

<span class="n">向量访问</span><span class="err">（</span><span class="mi">1</span><span class="n">条指令</span><span class="err">）：</span>
<span class="n">LD</span><span class="p">.</span><span class="n">E</span><span class="mf">.128</span><span class="w"> </span><span class="nl">R0</span><span class="p">:</span><span class="n">R3</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">address</span><span class="o">]</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">一次加载128位</span>
</code></pre></div>

<h3 id="332">3.3.2 实现技术</h3>
<p><strong>使用内建向量类型</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 向量化的矩阵拷贝</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">matrix_copy_vectorized</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vec_tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w">  </span><span class="c1">// 每个线程处理4个float</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">vec_tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 将指针转换为float4*</span>
<span class="w">        </span><span class="kt">float4</span><span class="o">*</span><span class="w"> </span><span class="n">dst4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float4</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="kt">float4</span><span class="o">*</span><span class="w"> </span><span class="n">src4</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float4</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 一次读写16字节</span>
<span class="w">        </span><span class="n">dst4</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src4</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// 更激进的向量化：使用CUDA的大向量类型</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">alignas</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="n">float8</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float4</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>
<span class="p">};</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">matrix_copy_float8</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">vec_tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">vec_tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">float8</span><span class="o">*</span><span class="w"> </span><span class="n">dst8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="n">float8</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">dst</span><span class="p">);</span>
<span class="w">        </span><span class="k">const</span><span class="w"> </span><span class="n">float8</span><span class="o">*</span><span class="w"> </span><span class="n">src8</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="n">float8</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">src</span><span class="p">);</span>
<span class="w">        </span><span class="n">dst8</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src8</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span><span class="w">  </span><span class="c1">// 一次32字节</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>联合体优化技巧</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用联合体进行类型双关</span>
<span class="k">union</span><span class="w"> </span><span class="nc">Vec4</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float4</span><span class="w"> </span><span class="n">vec</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">arr</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
<span class="w">    </span><span class="kt">uint4</span><span class="w"> </span><span class="n">u</span><span class="p">;</span>
<span class="p">};</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">process_rgbadata</span><span class="p">(</span><span class="kt">uint8_t</span><span class="o">*</span><span class="w"> </span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 读取4个RGBA像素（16字节）</span>
<span class="w">        </span><span class="kt">uint4</span><span class="w"> </span><span class="n">pixels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint4</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">image</span><span class="p">)[</span><span class="n">tid</span><span class="p">];</span>

<span class="w">        </span><span class="n">Vec4</span><span class="w"> </span><span class="n">result</span><span class="p">;</span>
<span class="w">        </span><span class="c1">// 提取并归一化每个通道</span>
<span class="w">        </span><span class="n">result</span><span class="p">.</span><span class="n">arr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">pixels</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0xFF</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span><span class="w">         </span><span class="c1">// R</span>
<span class="w">        </span><span class="n">result</span><span class="p">.</span><span class="n">arr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixels</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0xFF</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span><span class="w">  </span><span class="c1">// G</span>
<span class="w">        </span><span class="n">result</span><span class="p">.</span><span class="n">arr</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixels</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0xFF</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span><span class="w"> </span><span class="c1">// B</span>
<span class="w">        </span><span class="n">result</span><span class="p">.</span><span class="n">arr</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixels</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">24</span><span class="p">)</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0xFF</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span><span class="w"> </span><span class="c1">// A</span>

<span class="w">        </span><span class="c1">// 向量化写入</span>
<span class="w">        </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float4</span><span class="o">*&gt;</span><span class="p">(</span><span class="n">output</span><span class="p">)[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">result</span><span class="p">.</span><span class="n">vec</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="333">3.3.3 应用场景：多通道传感器数据处理</h3>
<p>在自动驾驶中，处理多通道激光雷达数据：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// Velodyne 64线激光雷达数据处理</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">VelodynePoint</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">;</span><span class="w">        </span><span class="c1">// 3D坐标</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">intensity</span><span class="p">;</span><span class="w">      </span><span class="c1">// 反射强度</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">azimuth</span><span class="p">;</span><span class="w">       </span><span class="c1">// 方位角</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">distance</span><span class="p">;</span><span class="w">      </span><span class="c1">// 距离</span>
<span class="w">    </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">ring</span><span class="p">;</span><span class="w">       </span><span class="c1">// 激光线号</span>
<span class="w">    </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">time</span><span class="p">;</span><span class="w">       </span><span class="c1">// 时间戳</span>
<span class="p">};</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">process_velodyne_vectorized</span><span class="p">(</span>
<span class="w">    </span><span class="n">VelodynePoint</span><span class="o">*</span><span class="w"> </span><span class="n">points</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float4</span><span class="o">*</span><span class="w"> </span><span class="n">cartesian_out</span><span class="p">,</span><span class="w">  </span><span class="c1">// x,y,z,intensity</span>
<span class="w">    </span><span class="kt">float2</span><span class="o">*</span><span class="w"> </span><span class="n">polar_out</span><span class="p">,</span><span class="w">      </span><span class="c1">// azimuth,distance</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n_points</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_points</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 向量化读取点云数据（32字节对齐）</span>
<span class="w">        </span><span class="n">VelodynePoint</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">points</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>

<span class="w">        </span><span class="c1">// 坐标变换（自车坐标系）</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">cos_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__cosf</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">azimuth</span><span class="p">);</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">sin_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">__sinf</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">azimuth</span><span class="p">);</span>

<span class="w">        </span><span class="kt">float4</span><span class="w"> </span><span class="n">cartesian</span><span class="p">;</span>
<span class="w">        </span><span class="n">cartesian</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">distance</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">cos_a</span><span class="p">;</span>
<span class="w">        </span><span class="n">cartesian</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">distance</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sin_a</span><span class="p">;</span>
<span class="w">        </span><span class="n">cartesian</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
<span class="w">        </span><span class="n">cartesian</span><span class="p">.</span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">intensity</span><span class="p">;</span>

<span class="w">        </span><span class="kt">float2</span><span class="w"> </span><span class="n">polar</span><span class="p">;</span>
<span class="w">        </span><span class="n">polar</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">azimuth</span><span class="p">;</span>
<span class="w">        </span><span class="n">polar</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">p</span><span class="p">.</span><span class="n">distance</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 向量化写入</span>
<span class="w">        </span><span class="n">cartesian_out</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cartesian</span><span class="p">;</span>
<span class="w">        </span><span class="n">polar_out</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">polar</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="cp">## 3.4 内存带宽优化</span>

<span class="cp">### 3.4.1 带宽分析与测量</span>

<span class="n">理解和测量内存带宽是优化的第一步</span><span class="err">。</span><span class="n">GPU的内存带宽受多个因素影响</span><span class="err">：</span>

<span class="o">**</span><span class="n">理论带宽计算</span><span class="o">**</span>
</code></pre></div>

<p>理论带宽 = 内存频率 × 总线宽度 × 2 (DDR)</p>
<p>示例（V100）：</p>
<ul>
<li>HBM2内存频率：877 MHz</li>
<li>总线宽度：4096 bits = 512 bytes</li>
<li>理论带宽 = 877 MHz × 512 bytes × 2 = 900 GB/s</li>
</ul>
<p>示例（A100）：</p>
<ul>
<li>HBM2e内存频率：1215 MHz  </li>
<li>总线宽度：5120 bits = 640 bytes</li>
<li>理论带宽 = 1215 MHz × 640 bytes × 2 = 1555 GB/s</li>
</ul>
<p>示例（H100）：</p>
<ul>
<li>HBM3内存频率：1593 MHz</li>
<li>总线宽度：6144 bits = 768 bytes  </li>
<li>理论带宽 = 1593 MHz × 768 bytes × 2 = 2448 GB/s</li>
</ul>
<div class="codehilite"><pre><span></span><code><span class="o">**</span><span class="n">有效带宽测量</span><span class="o">**</span>

<span class="err">```</span><span class="n">cuda</span>
<span class="o">//</span><span class="w"> </span><span class="n">带宽测试kernel</span>
<span class="n">__global__</span><span class="w"> </span><span class="n">void</span><span class="w"> </span><span class="n">bandwidth_test</span><span class="p">(</span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">dst</span><span class="p">,</span><span class="w"> </span><span class="n">const</span><span class="w"> </span><span class="nc">float</span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">,</span><span class="w"> </span><span class="nc">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nc">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="nc">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nc">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">dst</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">src</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">    </span><span class="err">}</span>
<span class="err">}</span>

<span class="o">//</span><span class="w"> </span><span class="n">测量函数</span>
<span class="nc">float</span><span class="w"> </span><span class="n">measure_bandwidth</span><span class="p">(</span><span class="nc">int</span><span class="w"> </span><span class="n">n_elements</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_src</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">d_dst</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_src</span><span class="p">,</span><span class="w"> </span><span class="n">n_elements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sizeof</span><span class="p">(</span><span class="nc">float</span><span class="p">));</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_dst</span><span class="p">,</span><span class="w"> </span><span class="n">n_elements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sizeof</span><span class="p">(</span><span class="nc">float</span><span class="p">));</span>

<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">预热</span>
<span class="w">    </span><span class="n">bandwidth_test</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_dst</span><span class="p">,</span><span class="w"> </span><span class="n">d_src</span><span class="p">,</span><span class="w"> </span><span class="n">n_elements</span><span class="p">);</span>

<span class="w">    </span><span class="n">cudaEvent_t</span><span class="w"> </span><span class="k">start</span><span class="p">,</span><span class="w"> </span><span class="n">stop</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="k">start</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaEventCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stop</span><span class="p">);</span>

<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">测量</span>
<span class="w">    </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="k">start</span><span class="p">);</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nc">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">bandwidth_test</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_dst</span><span class="p">,</span><span class="w"> </span><span class="n">d_src</span><span class="p">,</span><span class="w"> </span><span class="n">n_elements</span><span class="p">);</span>
<span class="w">    </span><span class="err">}</span>
<span class="w">    </span><span class="n">cudaEventRecord</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>
<span class="w">    </span><span class="n">cudaEventSynchronize</span><span class="p">(</span><span class="n">stop</span><span class="p">);</span>

<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="n">milliseconds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">cudaEventElapsedTime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">milliseconds</span><span class="p">,</span><span class="w"> </span><span class="k">start</span><span class="p">,</span><span class="w"> </span><span class="n">stop</span><span class="p">);</span>

<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">计算带宽</span><span class="err">（</span><span class="n">读</span><span class="o">+</span><span class="n">写</span><span class="err">）</span>
<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="n">bytes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">2.0</span><span class="n">f</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">n_elements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sizeof</span><span class="p">(</span><span class="nc">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">;</span>
<span class="w">    </span><span class="nc">float</span><span class="w"> </span><span class="n">bandwidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bytes</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">milliseconds</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1e6</span><span class="p">);</span><span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">GB</span><span class="o">/</span><span class="n">s</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">bandwidth</span><span class="p">;</span>
<span class="err">}</span>
</code></pre></div>

<p><strong>Roofline模型分析</strong></p>
<div class="codehilite"><pre><span></span><code>Roofline模型：性能受计算强度限制

性能(GFLOPS)
    ↑
    │     计算受限区域
    │    ╱─────────── 峰值计算性能
    │   ╱ 
    │  ╱  内存受限区域
    │ ╱   
    │╱    性能 = 带宽 × 计算强度
    └────────────────────→ 计算强度(FLOPS/Byte)
         Ridge Point

计算强度 = 浮点运算数 / 内存访问字节数

示例分析：

<span class="k">-</span> SAXPY (y = a*x + y): 2 FLOPS / 12 Bytes = 0.167
<span class="k">-</span> GEMM (C = A*B + C): 2*n³ FLOPS / 4*n² Bytes = n/2
<span class="k">-</span> 卷积: 取决于kernel大小和复用程度
</code></pre></div>

<h3 id="342">3.4.2 带宽优化技术</h3>
<p><strong>数据压缩与解压</strong></p>
<p>在具身智能场景中，深度图像的压缩传输：</p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 16位深度图压缩为8位+缩放因子</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">compress_depth</span><span class="p">(</span><span class="kt">uint8_t</span><span class="o">*</span><span class="w"> </span><span class="n">compressed</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">scale_factors</span><span class="p">,</span>
<span class="w">                               </span><span class="k">const</span><span class="w"> </span><span class="kt">uint16_t</span><span class="o">*</span><span class="w"> </span><span class="n">depth</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 计算16x16块的最大最小值（使用共享内存）</span>
<span class="w">        </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">s_min</span><span class="p">,</span><span class="w"> </span><span class="n">s_max</span><span class="p">;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_min</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">65535</span><span class="p">;</span>
<span class="w">            </span><span class="n">s_max</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="kt">uint16_t</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">depth</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>

<span class="w">        </span><span class="c1">// 原子更新最值</span>
<span class="w">        </span><span class="n">atomicMin</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s_min</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">        </span><span class="n">atomicMax</span><span class="p">(</span><span class="o">&amp;</span><span class="n">s_max</span><span class="p">,</span><span class="w"> </span><span class="n">val</span><span class="p">);</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 量化到8位</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">s_max</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">s_min</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">255.0f</span><span class="p">;</span>
<span class="w">        </span><span class="kt">uint8_t</span><span class="w"> </span><span class="n">compressed_val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">val</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">s_min</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>

<span class="w">        </span><span class="n">compressed</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">compressed_val</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 块的第一个线程保存缩放因子</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">block_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">            </span><span class="n">scale_factors</span><span class="p">[</span><span class="n">block_id</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s_min</span><span class="p">;</span>
<span class="w">            </span><span class="n">scale_factors</span><span class="p">[</span><span class="n">block_id</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scale</span><span class="p">;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>异步内存传输与计算重叠</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用CUDA流实现传输与计算重叠</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">process_with_overlap</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">h_data</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_data</span><span class="p">,</span><span class="w"> </span>
<span class="w">                         </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">d_result</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n_chunks</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">n_chunks</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 创建流</span>
<span class="w">    </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 双缓冲</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="o">*</span><span class="n">d_buffer</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_buffer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>
<span class="w">    </span><span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_buffer</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">));</span>

<span class="w">    </span><span class="c1">// 流水线处理</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_chunks</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">stream_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 异步拷贝到GPU</span>
<span class="w">        </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">d_buffer</span><span class="p">[</span><span class="n">stream_id</span><span class="p">],</span><span class="w"> </span>
<span class="w">                       </span><span class="n">h_data</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">,</span>
<span class="w">                       </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">                       </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">,</span>
<span class="w">                       </span><span class="n">streams</span><span class="p">[</span><span class="n">stream_id</span><span class="p">]);</span>

<span class="w">        </span><span class="c1">// 在该流上启动kernel</span>
<span class="w">        </span><span class="n">process_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">streams</span><span class="p">[</span><span class="n">stream_id</span><span class="p">]</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span>
<span class="w">            </span><span class="n">d_result</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">,</span>
<span class="w">            </span><span class="n">d_buffer</span><span class="p">[</span><span class="n">stream_id</span><span class="p">],</span>
<span class="w">            </span><span class="n">chunk_size</span><span class="p">);</span>

<span class="w">        </span><span class="c1">// 异步拷贝回CPU（如需要）</span>
<span class="w">        </span><span class="n">cudaMemcpyAsync</span><span class="p">(</span><span class="n">h_result</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">,</span>
<span class="w">                       </span><span class="n">d_result</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">,</span>
<span class="w">                       </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span>
<span class="w">                       </span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">,</span>
<span class="w">                       </span><span class="n">streams</span><span class="p">[</span><span class="n">stream_id</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 同步所有流</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cudaStreamSynchronize</span><span class="p">(</span><span class="n">streams</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>预取策略（Unified Memory）</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 统一内存的预取优化</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">slam_with_prefetch</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">unified_map</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">map_size</span><span class="p">,</span>
<span class="w">                        </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">new_scan</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">scan_size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 预取地图数据到GPU</span>
<span class="w">    </span><span class="n">cudaMemPrefetchAsync</span><span class="p">(</span><span class="n">unified_map</span><span class="p">,</span><span class="w"> </span><span class="n">map_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 预取新扫描数据到GPU</span>
<span class="w">    </span><span class="n">cudaMemPrefetchAsync</span><span class="p">(</span><span class="n">new_scan</span><span class="p">,</span><span class="w"> </span><span class="n">scan_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 启动SLAM kernel</span>
<span class="w">    </span><span class="n">slam_update_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span><span class="w"> </span><span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">unified_map</span><span class="p">,</span><span class="w"> </span><span class="n">new_scan</span><span class="p">,</span><span class="w"> </span><span class="n">map_size</span><span class="p">,</span><span class="w"> </span><span class="n">scan_size</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 预取更新后的地图回CPU（用于可视化）</span>
<span class="w">    </span><span class="n">cudaMemPrefetchAsync</span><span class="p">(</span><span class="n">unified_map</span><span class="p">,</span><span class="w"> </span><span class="n">map_size</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span><span class="w"> </span><span class="n">cudaCpuDeviceId</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div>

<h3 id="343">3.4.3 带宽受限算法优化</h3>
<p><strong>Kernel融合减少内存访问</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 未融合版本：3次全局内存访问</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">add_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
<span class="p">}</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">mul_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">scalar</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scalar</span><span class="p">;</span>
<span class="p">}</span>

<span class="c1">// 融合版本：2次全局内存访问</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">fused_add_mul</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span>
<span class="w">                              </span><span class="kt">float</span><span class="w"> </span><span class="n">scalar</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">[</span><span class="n">tid</span><span class="p">])</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scalar</span><span class="p">;</span><span class="w">  </span><span class="c1">// 寄存器中完成所有计算</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>计算与访存重叠（延迟隐藏）</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用指令级并行隐藏内存延迟</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">compute_intensive_kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">output</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 展开循环，增加并行度</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">acc0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">acc1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">acc2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">acc3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tid</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 发起多个独立的内存请求</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">stride</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">stride</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="kt">float</span><span class="w"> </span><span class="n">val3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="o">*</span><span class="n">stride</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="o">*</span><span class="n">stride</span><span class="p">]</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 在等待内存时进行计算</span>
<span class="w">        </span><span class="n">acc0</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__sinf</span><span class="p">(</span><span class="n">val0</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">__cosf</span><span class="p">(</span><span class="n">val0</span><span class="p">);</span>
<span class="w">        </span><span class="n">acc1</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__sinf</span><span class="p">(</span><span class="n">val1</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">__cosf</span><span class="p">(</span><span class="n">val1</span><span class="p">);</span>
<span class="w">        </span><span class="n">acc2</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__sinf</span><span class="p">(</span><span class="n">val2</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">__cosf</span><span class="p">(</span><span class="n">val2</span><span class="p">);</span>
<span class="w">        </span><span class="n">acc3</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">__sinf</span><span class="p">(</span><span class="n">val3</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">__cosf</span><span class="p">(</span><span class="n">val3</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 归约结果</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">output</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">acc0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">acc1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">acc2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">acc3</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>具身智能案例：实时SLAM的带宽优化</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1">// ICP（迭代最近点）算法的带宽优化</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">PointNormal</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">float3</span><span class="w"> </span><span class="n">point</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float3</span><span class="w"> </span><span class="n">normal</span><span class="p">;</span>
<span class="p">};</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">icp_correspondence_optimized</span><span class="p">(</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">correspondences</span><span class="p">,</span><span class="w">        </span><span class="c1">// 输出：对应关系</span>
<span class="w">    </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">distances</span><span class="p">,</span><span class="w">            </span><span class="c1">// 输出：距离</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">PointNormal</span><span class="o">*</span><span class="w"> </span><span class="n">source</span><span class="p">,</span><span class="w">   </span><span class="c1">// 源点云</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="n">PointNormal</span><span class="o">*</span><span class="w"> </span><span class="n">target</span><span class="p">,</span><span class="w">   </span><span class="c1">// 目标点云</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">transform</span><span class="p">,</span><span class="w">      </span><span class="c1">// 4x4变换矩阵</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n_source</span><span class="p">,</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">n_target</span><span class="p">,</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">max_dist</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">    </span><span class="c1">// 每个block处理一个源点，使用共享内存缓存目标点</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="n">PointNormal</span><span class="w"> </span><span class="n">s_target</span><span class="p">[</span><span class="mi">256</span><span class="p">];</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">source_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">source_idx</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">n_source</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 加载并变换源点</span>
<span class="w">    </span><span class="n">PointNormal</span><span class="w"> </span><span class="n">src</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">source</span><span class="p">[</span><span class="n">source_idx</span><span class="p">];</span>
<span class="w">    </span><span class="kt">float3</span><span class="w"> </span><span class="n">transformed_point</span><span class="p">;</span>
<span class="w">    </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">                         </span><span class="n">transform</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">    </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">                         </span><span class="n">transform</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">7</span><span class="p">];</span>
<span class="w">    </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">9</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span>
<span class="w">                         </span><span class="n">transform</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">src</span><span class="p">.</span><span class="n">point</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">transform</span><span class="p">[</span><span class="mi">11</span><span class="p">];</span>

<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">min_dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">max_dist</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">best_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 分块处理目标点云</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">chunk_start</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">chunk_start</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_target</span><span class="p">;</span><span class="w"> </span><span class="n">chunk_start</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="c1">// 协作加载目标点到共享内存</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">target_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chunk_start</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">target_idx</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">n_target</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">s_target</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">target</span><span class="p">[</span><span class="n">target_idx</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 计算距离</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">chunk_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">min</span><span class="p">(</span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">n_target</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">chunk_start</span><span class="p">);</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">chunk_size</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">float3</span><span class="w"> </span><span class="n">diff</span><span class="p">;</span>
<span class="w">            </span><span class="n">diff</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">s_target</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">point</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">            </span><span class="n">diff</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">s_target</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">point</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="w">            </span><span class="n">diff</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">transformed_point</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">s_target</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">point</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>

<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">diff</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>

<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">dist</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">min_dist</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">min_dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dist</span><span class="p">;</span>
<span class="w">                </span><span class="n">best_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">chunk_start</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="c1">// 使用warp级归约找到最小距离</span>
<span class="w">    </span><span class="n">min_dist</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warp_reduce_min</span><span class="p">(</span><span class="n">min_dist</span><span class="p">);</span>
<span class="w">    </span><span class="n">best_idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">warp_broadcast</span><span class="p">(</span><span class="n">best_idx</span><span class="p">,</span><span class="w"> </span><span class="n">min_dist</span><span class="p">);</span>

<span class="w">    </span><span class="c1">// 第一个线程写入结果</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">correspondences</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">best_idx</span><span class="p">;</span>
<span class="w">        </span><span class="n">distances</span><span class="p">[</span><span class="n">source_idx</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrtf</span><span class="p">(</span><span class="n">min_dist</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<h2 id="35">3.5 案例：高带宽矩阵转置</h2>
<p>矩阵转置是展示内存优化技术的经典案例。看似简单的操作，实则充分暴露了内存访问模式对性能的决定性影响。</p>
<h3 id="351">3.5.1 朴素实现与性能分析</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 朴素实现：严重的内存访问问题</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_naive</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">out</span><span class="p">[</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">y</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">];</span><span class="w">  </span>
<span class="w">        </span><span class="c1">// 问题：读取合并，但写入跨步！</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">性能分析</span><span class="err">：</span>

<span class="o">-</span><span class="w"> </span><span class="n">读取</span><span class="err">：</span><span class="n">连续线程读取连续地址</span><span class="err">，</span><span class="n">完美合并</span>
<span class="o">-</span><span class="w"> </span><span class="n">写入</span><span class="err">：</span><span class="n">连续线程写入间隔height的地址</span><span class="err">，</span><span class="n">严重不合并</span>
<span class="o">-</span><span class="w"> </span><span class="n">带宽利用率</span><span class="err">：</span><span class="n">约10</span><span class="mi">-15</span><span class="o">%</span><span class="err">（</span><span class="n">取决于矩阵大小</span><span class="err">）</span>
</code></pre></div>

<h3 id="352">3.5.2 合并访问优化</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用共享内存实现合并读写</span>
<span class="cp">#define TILE_DIM 32</span>
<span class="cp">#define BLOCK_ROWS 8</span>

<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_coalesced</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span><span class="w">  </span><span class="c1">// +1避免bank conflict</span>

<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 合并读取到共享内存（每个线程读4个元素）</span>
<span class="w">    </span><span class="cp">#pragma unroll</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">BLOCK_ROWS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[(</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 交换线程的x和y来实现转置后的合并写入</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="cp">#pragma unroll</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">BLOCK_ROWS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">out</span><span class="p">[(</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">性能提升</span><span class="err">：</span>

<span class="o">-</span><span class="w"> </span><span class="n">读写都实现合并访问</span>
<span class="o">-</span><span class="w"> </span><span class="n">带宽利用率</span><span class="err">：</span><span class="n">约60</span><span class="mi">-70</span><span class="o">%</span>
</code></pre></div>

<h3 id="353">3.5.3 向量化优化</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 使用float4向量化进一步优化</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_vectorized</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 每个线程处理4个float</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 向量化读取</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float4</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="k">const</span><span class="w"> </span><span class="kt">float4</span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">in</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">])[</span><span class="mi">0</span><span class="p">];</span>
<span class="w">        </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
<span class="w">        </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
<span class="w">        </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">.</span><span class="n">w</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 转置后向量化写入</span>
<span class="w">    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">float4</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">        </span><span class="n">data</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="w">        </span><span class="n">data</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="w">        </span><span class="n">data</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">2</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="w">        </span><span class="n">data</span><span class="p">.</span><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">];</span>
<span class="w">        </span><span class="n">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">float4</span><span class="o">*&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">out</span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">x</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">性能提升</span><span class="err">：</span>

<span class="o">-</span><span class="w"> </span><span class="n">减少内存事务数量</span>
<span class="o">-</span><span class="w"> </span><span class="n">带宽利用率</span><span class="err">：</span><span class="n">约75</span><span class="mi">-80</span><span class="o">%</span>
</code></pre></div>

<h3 id="354">3.5.4 共享内存协同优化</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 终极优化：双缓冲+异步拷贝（Ampere+）</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">transpose_ultimate</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">width</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">height</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 双缓冲共享内存</span>
<span class="w">    </span><span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">tile</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="p">][</span><span class="n">TILE_DIM</span><span class="o">+</span><span class="mi">1</span><span class="p">];</span>

<span class="w">    </span><span class="c1">// 异步拷贝管道</span>
<span class="w">    </span><span class="n">cuda</span><span class="o">::</span><span class="n">pipeline</span><span class="o">&lt;</span><span class="n">cuda</span><span class="o">::</span><span class="n">thread_scope_thread</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pipe</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cuda</span><span class="o">::</span><span class="n">make_pipeline</span><span class="p">();</span>

<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span>
<span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">tile_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 第一个tile的异步加载</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">cuda</span><span class="o">::</span><span class="n">memcpy_async</span><span class="p">(</span>
<span class="w">            </span><span class="o">&amp;</span><span class="n">tile</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="w">            </span><span class="o">&amp;</span><span class="n">in</span><span class="p">[(</span><span class="n">tile_y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tile_x</span><span class="p">],</span>
<span class="w">            </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">,</span>
<span class="w">            </span><span class="n">pipe</span>
<span class="w">        </span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">pipe</span><span class="p">.</span><span class="n">producer_commit</span><span class="p">();</span>

<span class="w">    </span><span class="c1">// 主循环：重叠传输和计算</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span><span class="w"> </span><span class="n">k</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">buffer_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">next_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">buffer_id</span><span class="p">;</span>

<span class="w">        </span><span class="c1">// 等待当前tile就绪</span>
<span class="w">        </span><span class="n">pipe</span><span class="p">.</span><span class="n">consumer_wait</span><span class="p">();</span>
<span class="w">        </span><span class="nf">__syncthreads</span><span class="p">();</span>

<span class="w">        </span><span class="c1">// 预取下一个tile（如果不是最后一个）</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">k</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="kt">int</span><span class="w"> </span><span class="n">next_tile_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="nb">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span>
<span class="w">                </span><span class="n">cuda</span><span class="o">::</span><span class="n">memcpy_async</span><span class="p">(</span>
<span class="w">                    </span><span class="o">&amp;</span><span class="n">tile</span><span class="p">[</span><span class="n">next_buffer</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
<span class="w">                    </span><span class="o">&amp;</span><span class="n">in</span><span class="p">[(</span><span class="n">tile_y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">next_tile_x</span><span class="p">],</span>
<span class="w">                    </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">,</span>
<span class="w">                    </span><span class="n">pipe</span>
<span class="w">                </span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">            </span><span class="n">pipe</span><span class="p">.</span><span class="n">producer_commit</span><span class="p">();</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="c1">// 处理当前tile的转置写入</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">out_x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tile_y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">out_y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">out_x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">out_y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">width</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="cp">#pragma unroll</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">TILE_DIM</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">BLOCK_ROWS</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="n">out</span><span class="p">[(</span><span class="n">out_y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">height</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">out_x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>
<span class="w">                    </span><span class="n">tile</span><span class="p">[</span><span class="n">buffer_id</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">];</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>

<span class="w">        </span><span class="n">pipe</span><span class="p">.</span><span class="n">consumer_release</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>

<span class="n">性能达到</span><span class="err">：</span>

<span class="o">-</span><span class="w"> </span><span class="n">带宽利用率</span><span class="err">：</span><span class="n">约85</span><span class="mi">-90</span><span class="o">%</span>
<span class="o">-</span><span class="w"> </span><span class="n">接近硬件理论极限</span>
</code></pre></div>

<h3 id="355">3.5.5 性能对比与分析</h3>
<div class="codehilite"><pre><span></span><code>性能测试结果（8192x8192矩阵，V100）：

实现版本            带宽(GB/s)   利用率    相对性能
─────────────────────────────────────────────
朴素实现            95          10.6%     1.0x
合并访问            570         63.3%     6.0x  
向量化              684         76.0%     7.2x
双缓冲+异步         810         90.0%     8.5x
理论峰值            900         100%      -

关键优化点：

1. 合并访问：6倍性能提升（最关键）
2. 向量化：额外20%提升
3. 异步传输：额外18%提升
4. Bank conflict避免：约5%提升
</code></pre></div>

<h2 id="36">3.6 本章小结</h2>
<p>全局内存优化是CUDA性能调优的基础和关键。本章深入探讨了内存访问模式、缓存行为、向量化技术和带宽优化策略。</p>
<p><strong>核心要点</strong>：</p>
<ol>
<li>
<p><strong>合并访问是第一要务</strong>：未合并的内存访问会导致10倍甚至更多的性能损失。通过数据布局转换（AoS→SoA）和访问模式重组可以实现合并。</p>
</li>
<li>
<p><strong>缓存配置因场景而异</strong>：L1缓存对具有时空局部性的算法有利，但流式访问应考虑绕过L1。使用<code>__ldg</code>和<code>const __restrict__</code>可以利用只读缓存路径。</p>
</li>
<li>
<p><strong>向量化减少指令开销</strong>：float2/float4等向量类型可以减少内存事务数量，提高带宽利用率。在处理多通道数据时尤其有效。</p>
</li>
<li>
<p><strong>带宽优化需要系统思维</strong>：
   - 测量和分析：使用Roofline模型识别瓶颈
   - 数据压缩：在带宽受限时权衡计算与传输
   - 异步传输：重叠计算与数据移动
   - Kernel融合：减少内存往返次数</p>
</li>
<li>
<p><strong>实战案例的启示</strong>：矩阵转置案例展示了从10%到90%带宽利用率的优化过程，核心在于合并访问+共享内存+向量化+异步传输的组合使用。</p>
</li>
</ol>
<p><strong>关键公式</strong>：</p>
<ul>
<li>有效带宽 = 数据传输量 / 执行时间</li>
<li>带宽利用率 = 有效带宽 / 理论带宽</li>
<li>计算强度 = FLOPS / 内存访问字节数</li>
<li>内存事务效率 = 请求字节数 / 传输字节数</li>
</ul>
<p>记住：在自动驾驶和具身智能的实时系统中，每GB/s的带宽提升都可能意味着更高的帧率、更低的延迟，甚至决定系统能否实时运行。掌握这些优化技术，是构建高性能AI系统的必备技能。</p>
<h2 id="37">3.7 练习题</h2>
<h3 id="_1">基础题（理解概念）</h3>
<p><strong>练习3.1</strong>：给定一个warp的32个线程，分别访问地址[0, 128, 256, ..., 3968]（步长128字节），计算需要多少个128字节的内存事务？带宽利用率是多少？</p>
<details>
<summary>提示</summary>
<p>考虑128字节对齐的内存段，每个线程访问不同的段。</p>
</details>
<details>
<summary>答案</summary>
<p>需要32个128字节事务。每个线程访问4字节，共需128字节，但实际传输32×128=4096字节。带宽利用率=128/4096=3.125%。</p>
</details>
<p><strong>练习3.2</strong>：解释为什么在共享内存tile声明中使用<code>[TILE_DIM][TILE_DIM+1]</code>而不是<code>[TILE_DIM][TILE_DIM]</code>？</p>
<details>
<summary>提示</summary>
<p>考虑共享内存的bank组织，32个bank，每个bank 4字节宽。</p>
</details>
<details>
<summary>答案</summary>
<p>添加padding避免bank conflict。当TILE_DIM=32时，同一列的连续元素会映射到同一个bank，导致32路bank conflict。+1使得列元素分散到不同bank。</p>
</details>
<p><strong>练习3.3</strong>：在Volta架构上，L1缓存和共享内存共享128KB空间。如果kernel使用64KB共享内存，L1缓存有多大？这对性能有何影响？</p>
<details>
<summary>提示</summary>
<p>考虑缓存大小对命中率的影响，以及不同访问模式的需求。</p>
</details>
<details>
<summary>答案</summary>
<p>L1缓存为64KB。影响：1)缓存容量减少可能降低时间局部性好的算法性能；2)对流式访问影响小；3)需要权衡共享内存带来的数据复用收益与L1缓存减少的损失。</p>
</details>
<h3 id="_2">进阶题（应用技术）</h3>
<p><strong>练习3.4</strong>：设计一个kernel，高效地将RGB图像（3通道，uint8_t）转换为灰度图像，灰度值计算公式为：<code>gray = 0.299*R + 0.587*G + 0.114*B</code>。要求达到&gt;80%的带宽利用率。</p>
<details>
<summary>提示</summary>
<ol>
<li>使用向量化加载RGB数据</li>
<li>考虑数据对齐</li>
<li>使用整数运算避免浮点转换</li>
</ol>
</details>
<details>
<summary>答案</summary>
<p>关键点：1)使用uchar4向量化读取4个像素（12字节）；2)使用定点数运算(×1000)避免浮点；3)确保输入输出都是合并访问；4)每个线程处理多个像素增加ILP。</p>
</details>
<p><strong>练习3.5</strong>：优化稀疏矩阵向量乘法（SpMV）的内存访问。给定CSR格式的稀疏矩阵，如何减少随机访问带来的性能损失？</p>
<details>
<summary>提示</summary>
<ol>
<li>考虑向量x的访问模式</li>
<li>使用纹理内存或只读缓存</li>
<li>分块处理提高局部性</li>
</ol>
</details>
<details>
<summary>答案</summary>
<p>策略：1)向量x通过纹理缓存/__ldg访问；2)使用SELL-C-σ格式改善合并；3)行分块使多个线程协作处理长行；4)使用共享内存缓存频繁访问的x元素。</p>
</details>
<h3 id="_3">挑战题（综合优化）</h3>
<p><strong>练习3.6</strong>：实现一个高性能的2D卷积kernel（5×5卷积核），处理4K分辨率图像，要求达到&gt;1TFLOPS的计算吞吐量。分析内存访问模式并给出优化策略。</p>
<details>
<summary>提示</summary>
<ol>
<li>计算重用率：每个输出需要25次乘加</li>
<li>使用共享内存缓存输入tile</li>
<li>考虑halo区域的处理</li>
<li>向量化和循环展开</li>
</ol>
</details>
<details>
<summary>答案</summary>
<p>优化要点：1)输入tile加载到共享内存(如18×18 for 14×14输出)；2)使用float4向量化；3)寄存器缓存卷积核；4)每个线程计算2×2或4×4输出块；5)texture内存处理边界；6)考虑使用Tensor Core（如可用）。</p>
</details>
<p><strong>练习3.7</strong>：在自动驾驶场景中，需要实时处理64线激光雷达数据（每帧约13万点）。设计一个数据结构和访问模式，支持：1)快速范围查询；2)体素化（voxelization）；3)KNN搜索。要求总处理时间&lt;10ms。</p>
<details>
<summary>提示</summary>
<ol>
<li>考虑空间数据结构（网格、八叉树）</li>
<li>平衡构建时间和查询效率</li>
<li>利用点云的时序特性</li>
</ol>
</details>
<details>
<summary>答案</summary>
<p>方案：1)使用规则网格+哈希表，O(1)体素查询；2)Morton编码实现空间局部性；3)分层网格支持多尺度；4)使用滑动窗口复用上帧结构；5)共享内存缓存邻域体素；6)原子操作处理点计数。</p>
</details>
<p><strong>练习3.8</strong>：设计一个统一内存(Unified Memory)的使用策略，用于具身智能机器人的SLAM系统。系统需要维护一个大规模地图（&gt;1GB），同时CPU需要进行路径规划，GPU进行地图更新。如何优化数据移动？</p>
<details>
<summary>提示</summary>
<ol>
<li>使用cudaMemAdvise提示访问模式</li>
<li>预取策略</li>
<li>分区管理</li>
<li>考虑页面迁移开销</li>
</ol>
</details>
<details>
<summary>答案</summary>
<p>策略：1)地图分块，活跃块预取到GPU；2)使用cudaMemAdviseSetReadMostly标记静态区域；3)CPU路径规划时预取相关块；4)使用流并发更新不同块；5)定期整理减少碎片；6)关键路径避免页错误。</p>
</details>
<h2 id="38">3.8 常见陷阱与错误</h2>
<h3 id="1">陷阱1：误判内存合并</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 看似合并，实际不合并</span>
<span class="k">struct</span><span class="w"> </span><span class="nc">Vec3</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">z</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">process</span><span class="p">(</span><span class="n">Vec3</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="n">tid</span><span class="p">].</span><span class="n">x</span><span class="p">;</span><span class="w">  </span><span class="c1">// 线程访问步长12字节，不完全合并！</span>
<span class="p">}</span>
<span class="c1">// 解决：使用SoA布局或float3向量类型</span>
</code></pre></div>

<h3 id="2">陷阱2：缓存污染</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 大量流式数据污染L1缓存</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">stream_process</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">in</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="n">out</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">in</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">2.0f</span><span class="p">;</span><span class="w">  </span><span class="c1">// 无重用，却占用缓存</span>
<span class="p">}</span>
<span class="c1">// 解决：使用 -Xptxas -dlcm=cg 编译选项绕过L1</span>
</code></pre></div>

<h3 id="3_1">陷阱3：向量化的错误假设</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 错误：假设地址总是对齐的</span>
<span class="kt">float4</span><span class="o">*</span><span class="w"> </span><span class="n">ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="kt">float4</span><span class="o">*</span><span class="p">)(</span><span class="o">&amp;</span><span class="n">array</span><span class="p">[</span><span class="n">offset</span><span class="p">]);</span><span class="w">  </span><span class="c1">// offset不是4的倍数时未对齐！</span>
<span class="kt">float4</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">*</span><span class="n">ptr</span><span class="p">;</span><span class="w">  </span><span class="c1">// 可能导致性能下降或错误</span>
<span class="c1">// 解决：检查对齐或使用非对齐加载</span>
</code></pre></div>

<h3 id="4">陷阱4：统一内存的隐藏开销</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 页面迁移的隐藏成本</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">kernel</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">unified_data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// 首次访问触发页错误，可能有ms级延迟！</span>
<span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">unified_data</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span><span class="w">  </span>
<span class="p">}</span>
<span class="c1">// 解决：使用cudaMemPrefetchAsync预取</span>
</code></pre></div>

<h3 id="5">陷阱5：原子操作的带宽影响</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 原子操作严重降低带宽</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">histogram</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">bins</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">val</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">data</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="w">    </span><span class="n">atomicAdd</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bins</span><span class="p">[</span><span class="n">val</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span><span class="w">  </span><span class="c1">// 多个线程竞争同一地址</span>
<span class="p">}</span>
<span class="c1">// 解决：使用共享内存局部直方图+归约</span>
</code></pre></div>

<h3 id="6bank-conflict">陷阱6：Bank Conflict的隐蔽性</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 隐蔽的bank conflict</span>
<span class="kt">__shared__</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="n">matrix</span><span class="p">[</span><span class="mi">16</span><span class="p">][</span><span class="mi">16</span><span class="p">];</span><span class="w">  </span><span class="c1">// 16 &lt; 32，看似安全</span>
<span class="n">matrix</span><span class="p">[</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">value</span><span class="p">;</span><span class="w">  </span><span class="c1">// 但列访问时仍有conflict！</span>
<span class="c1">// 解决：使用[16][17]或重新安排访问模式</span>
</code></pre></div>

<h3 id="7">陷阱7：错误的带宽计算</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 错误：只计算有用数据</span>
<span class="n">bandwidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">useful_bytes</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">time</span><span class="p">;</span><span class="w">  </span><span class="c1">// 忽略了浪费的传输！</span>
<span class="c1">// 正确：计算实际传输</span>
<span class="n">bandwidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">actual_transferred_bytes</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">time</span><span class="p">;</span>
</code></pre></div>

<h3 id="8">陷阱8：过度优化的陷阱</h3>
<div class="codehilite"><pre><span></span><code><span class="c1">// 过度复杂的优化反而降低性能</span>
<span class="c1">// 16个不同的内存访问模式，寄存器压力过大</span>
<span class="c1">// 解决：平衡优化复杂度与收益</span>
</code></pre></div>

<h2 id="39">3.9 最佳实践检查清单</h2>
<h3 id="_4">设计阶段</h3>
<ul>
<li>[ ] <strong>数据结构选择</strong>：AoS vs SoA，考虑访问模式</li>
<li>[ ] <strong>内存分配</strong>：确保基地址对齐（使用cudaMallocPitch）</li>
<li>[ ] <strong>算法选择</strong>：评估计算强度，判断是否内存受限</li>
<li>[ ] <strong>容量规划</strong>：估算内存带宽需求vs硬件能力</li>
<li>[ ] <strong>访问模式分析</strong>：画出内存访问图，识别热点</li>
</ul>
<h3 id="_5">实现阶段</h3>
<ul>
<li>[ ] <strong>合并访问</strong>：连续线程访问连续地址</li>
<li>[ ] <strong>向量化</strong>：使用float2/float4减少事务</li>
<li>[ ] <strong>缓存配置</strong>：根据访问模式选择L1/Shared比例</li>
<li>[ ] <strong>只读路径</strong>：标记const __restrict__或使用__ldg</li>
<li>[ ] <strong>避免bank conflict</strong>：共享内存padding</li>
<li>[ ] <strong>数据预取</strong>：统一内存使用cudaMemPrefetchAsync</li>
<li>[ ] <strong>循环展开</strong>：增加指令级并行，隐藏延迟</li>
</ul>
<h3 id="_6">优化阶段</h3>
<ul>
<li>[ ] <strong>性能分析</strong>：使用Nsight Compute检查内存效率</li>
<li>[ ] <strong>带宽测量</strong>：对比实测vs理论带宽</li>
<li>[ ] <strong>瓶颈识别</strong>：Load/Store单元利用率</li>
<li>[ ] <strong>事务分析</strong>：检查L2缓存事务大小分布</li>
<li>[ ] <strong>占用率分析</strong>：确保足够的活跃warp隐藏延迟</li>
<li>[ ] <strong>迭代优化</strong>：根据profiler数据调整</li>
</ul>
<h3 id="_7">验证阶段</h3>
<ul>
<li>[ ] <strong>正确性</strong>：cuda-memcheck检查越界访问</li>
<li>[ ] <strong>扩展性</strong>：测试不同问题规模</li>
<li>[ ] <strong>稳定性</strong>：长时间运行测试</li>
<li>[ ] <strong>移植性</strong>：不同GPU架构的性能</li>
<li>[ ] <strong>边界情况</strong>：非对齐、非2的幂次大小</li>
<li>[ ] <strong>错误处理</strong>：内存分配失败等异常情况</li>
</ul>
<h3 id="_8">部署阶段</h3>
<ul>
<li>[ ] <strong>性能监控</strong>：运行时带宽监控</li>
<li>[ ] <strong>自适应调优</strong>：根据硬件动态调整参数</li>
<li>[ ] <strong>版本兼容</strong>：不同CUDA版本的兼容性</li>
<li>[ ] <strong>文档完善</strong>：记录优化决策和权衡</li>
<li>[ ] <strong>持续优化</strong>：新硬件的适配计划</li>
</ul>
<p>记住：优秀的CUDA程序员总是从内存访问模式开始思考问题。在动手编码前，先在纸上画出数据布局和访问模式！每一个字节的传输都应该是有意义的，每一次内存访问都应该经过精心设计。</p>
            </article>
            
            <nav class="page-nav"><a href="chapter2.html" class="nav-link prev">← 第2章：CUDA编程模型与执行模型</a><a href="chapter4.html" class="nav-link next">第4章：共享内存与Bank Conflict →</a></nav>
        </main>
    </div>
</body>
</html>