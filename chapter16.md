# 第16章：机械臂运动规划

机械臂运动规划是具身智能的核心挑战之一，涉及高维度配置空间搜索、实时碰撞检测和复杂约束优化。本章探讨如何利用CUDA大规模并行计算能力，将传统的串行运动规划算法加速100倍以上，实现毫秒级的实时规划。我们将深入剖析正逆运动学的批量求解、基于空间哈希的碰撞检测、RRT-Connect的并行化策略、轨迹优化算法的GPU实现，以及多机械臂系统的协调控制。通过本章学习，你将掌握构建高性能机械臂控制系统的关键技术。

## 16.1 正逆运动学并行求解

### 16.1.1 运动学基础与并行化机会

机械臂运动学是连接关节空间与笛卡尔空间的桥梁。对于n自由度机械臂，正运动学（FK）计算关节角度q到末端执行器位姿T的映射，逆运动学（IK）则求解相反方向。在实际应用中，我们需要：

1. **批量FK计算**：评估数千条候选轨迹的末端位置
2. **多解IK求解**：寻找所有可达的关节配置
3. **实时更新**：毫秒级响应动态环境变化

传统的串行DH参数法在GPU上的并行化面临以下挑战：
- 矩阵链乘的数据依赖
- 数值稳定性与精度要求
- 奇异点附近的特殊处理

### 16.1.2 正运动学的并行实现

正运动学的核心是齐次变换矩阵的连乘：

```
T = A₁(q₁) × A₂(q₂) × ... × Aₙ(qₙ)
```

我们采用分段并行策略：

```
配置空间采样批量化：
┌─────────────────────────────┐
│   B个批次 × N个关节        │
│ ┌───┬───┬───┬───┬───┐     │
│ │q₁₁│q₁₂│q₁₃│...│q₁ₙ│ B₁  │
│ ├───┼───┼───┼───┼───┤     │
│ │q₂₁│q₂₂│q₂₃│...│q₂ₙ│ B₂  │
│ ├───┼───┼───┼───┼───┤     │
│ │...│...│...│...│...│ ... │
│ └───┴───┴───┴───┴───┘     │
└─────────────────────────────┘
         ↓ 并行计算
┌─────────────────────────────┐
│  每个线程块处理一个批次    │
│  warp内协作计算矩阵乘法    │
└─────────────────────────────┘
```

**优化策略**：

1. **矩阵乘法融合**：将4×4矩阵乘法展开为标量操作，利用寄存器重用
2. **三角函数优化**：使用快速近似函数`__sinf`和`__cosf`
3. **共享内存缓存**：预计算的DH参数存储在共享内存
4. **向量化加载**：使用`float4`一次加载整行矩阵

### 16.1.3 逆运动学的数值方法

逆运动学通常无解析解，我们实现并行化的雅可比迭代法：

```
Δq = J⁺(q) × Δx
```

其中J⁺是雅可比矩阵的伪逆。GPU实现的关键点：

1. **雅可比矩阵计算**：
   - 数值微分：并行计算各关节的偏导数
   - 解析方法：利用向量叉积的并行性

2. **伪逆求解**：
   - SVD分解：使用cuSOLVER库
   - 阻尼最小二乘：`(JᵀJ + λI)⁻¹Jᵀ`的批量求解

3. **多起点优化**：
   - 并行启动多个初始猜测
   - 使用不同的零空间投影策略
   - 共享内存中维护最优解

### 16.1.4 奇异点处理与鲁棒性

机械臂在奇异配置附近，雅可比矩阵接近奇异，需要特殊处理：

```
奇异值分解流程：
┌──────────────┐
│ 计算 J = UΣVᵀ │
└──────┬───────┘
       ↓
┌──────────────┐
│ 检测小奇异值 │
│ if σᵢ < ε    │
└──────┬───────┘
       ↓
┌──────────────┐
│ 阻尼处理     │
│ σᵢ' = σᵢ/(σᵢ²+λ²) │
└──────────────┘
```

**并行化策略**：
- 每个线程块处理一个雅可比矩阵
- warp级别的奇异值筛选
- 原子操作更新全局最优解

### 16.1.5 性能优化技巧

1. **寄存器优化**：
   - 手动展开小矩阵运算
   - 使用`#pragma unroll`指导循环展开

2. **内存访问模式**：
   - 结构体数组（SoA）布局
   - 对齐的内存分配确保合并访问

3. **数值精度控制**：
   - 混合精度：位置用fp32，旋转用fp64
   - Kahan求和算法减少累积误差

4. **分支消除**：
   - 使用条件赋值替代if-else
   - 预计算查找表处理特殊情况

## 16.2 碰撞检测的空间哈希

### 16.2.1 碰撞检测在运动规划中的角色

碰撞检测是运动规划的性能瓶颈，占据总计算时间的70-90%。对于机械臂系统，我们需要检测：

1. **自碰撞**：机械臂各连杆之间的碰撞
2. **环境碰撞**：与静态/动态障碍物的碰撞  
3. **多臂碰撞**：多个机械臂之间的相互碰撞

传统的包围盒层次结构（BVH）在GPU上效率低下，因为：
- 树遍历的不规则内存访问
- 线程分支导致的warp发散
- 动态场景的频繁重建开销

### 16.2.2 空间哈希的基本原理

空间哈希将3D空间划分为均匀网格，每个物体映射到其占据的网格单元：

```
空间哈希结构：
┌────────────────────────────┐
│  3D空间 → 网格索引         │
│  hash(x,y,z) = (⌊x/s⌋,⌊y/s⌋,⌊z/s⌋) │
└────────────────────────────┘
            ↓
┌────────────────────────────┐
│  哈希表（固定大小）        │
│ ┌────┬────┬────┬────┐    │
│ │桶0 │桶1 │桶2 │... │    │
│ └────┴────┴────┴────┘    │
│    ↓    ↓    ↓           │
│  对象列表（动态）          │
└────────────────────────────┘
```

**GPU友好的设计**：
1. 固定大小哈希表避免动态内存分配
2. 原子操作处理并发插入
3. 紧凑的对象表示减少内存带宽

### 16.2.3 并行化的空间哈希构建

构建流程分为三个并行阶段：

**阶段1：计算包围盒并统计**
```cuda
每个线程处理一个物体：
1. 计算AABB包围盒
2. 确定占据的网格单元
3. 原子增加计数器
```

**阶段2：分配内存并构建索引**
```cuda
前缀和计算偏移量：
┌───┬───┬───┬───┐
│ 3 │ 0 │ 5 │ 2 │ 每个桶的对象数
└───┴───┴───┴───┘
    ↓ scan
┌───┬───┬───┬───┐
│ 0 │ 3 │ 3 │ 8 │ 起始偏移量
└───┴───┴───┴───┘
```

**阶段3：插入对象引用**
```cuda
并发插入策略：
- 使用atomicAdd获取插入位置
- 写入对象ID和几何信息
- 内存栅栏确保可见性
```

### 16.2.4 宽相位与窄相位检测

**宽相位：网格级别筛选**

```
并行遍历模式：
┌─────────────────────────┐
│ 每个线程块 → 一个网格  │
│ 每个线程 → 一对对象    │
└─────────────────────────┘
         ↓
┌─────────────────────────┐
│ AABB快速排斥测试       │
│ 使用shuffle共享结果    │
└─────────────────────────┘
```

优化技巧：
1. **空间局部性**：相邻网格分配给同一线程块
2. **负载均衡**：动态任务队列处理稠密区域
3. **早期剔除**：利用时间相干性跳过静态对

**窄相位：精确几何检测**

对于机械臂的胶囊体/球体原语：

```cuda
胶囊体-胶囊体距离计算：
1. 计算线段最近点（并行）
2. 点到线段距离（向量化）
3. 考虑半径的穿透深度
```

GJK算法的GPU实现：
- 每个线程对处理一个碰撞对
- 共享内存维护单纯形
- warp投票加速收敛判断

### 16.2.5 连续碰撞检测（CCD）

对于高速运动，离散检测可能遗漏碰撞。我们实现扫掠体积的CCD：

```
运动轨迹离散化：
t=0 ────┬────┬────┬──── t=1
        │    │    │
      检测点（自适应细分）
```

**并行化策略**：
1. **保守推进**：二分搜索第一次碰撞时间
2. **区间算术**：使用区间包围盒加速排斥
3. **自适应细分**：根据相对速度调整采样密度

### 16.2.6 动态场景更新

增量更新策略减少重建开销：

```
更新流程：
┌──────────────┐
│ 标记脏对象  │ 移动的物体
└──────┬───────┘
       ↓
┌──────────────┐
│ 局部清除    │ 仅清除相关网格
└──────┬───────┘
       ↓
┌──────────────┐
│ 重新插入    │ 新位置的网格
└──────────────┘
```

**优化技术**：
1. **双缓冲**：读写分离避免竞争
2. **时间戳**：跟踪对象版本避免重复检测
3. **层次化网格**：多分辨率适应不同尺度物体

## 16.3 RRT-Connect的GPU实现

### 16.3.1 RRT-Connect算法概述

RRT-Connect是双向快速扩展随机树算法，通过从起点和终点同时生长搜索树来加速路径发现。其核心优势是：
- 概率完备性保证
- 高维空间的有效探索
- 自然处理复杂约束

算法的计算瓶颈在于：
1. 大量的最近邻搜索（80%时间）
2. 密集的碰撞检测
3. 树结构的动态更新

### 16.3.2 并行化架构设计

我们采用批量并行的RRT-Connect架构：

```
并行RRT-Connect结构：
┌─────────────────────────────┐
│  GPU全局内存               │
│ ┌─────────┬─────────┐      │
│ │ Tree_A  │ Tree_B  │      │
│ └─────────┴─────────┘      │
│      ↓         ↓           │
│ ┌─────────────────┐        │
│ │ 批量采样生成器 │        │
│ └─────────────────┘        │
│      ↓                     │
│ ┌─────────────────┐        │
│ │ 并行扩展内核   │        │
│ └─────────────────┘        │
└─────────────────────────────┘
```

**关键设计决策**：
1. **批量采样**：一次生成K个随机样本，摊销随机数生成开销
2. **并行扩展**：多个线程同时尝试不同方向的扩展
3. **延迟更新**：批量收集成功的节点，减少树更新的同步开销

### 16.3.3 高效的最近邻搜索

传统的KD-Tree在GPU上性能差，我们实现基于网格的近似最近邻：

**空间分区策略**：
```
配置空间网格化：
┌───┬───┬───┬───┐
│   │   │ * │   │  * = 树节点
├───┼───┼───┼───┤  
│ * │   │   │ * │  网格大小自适应
├───┼───┼───┼───┤
│   │ * │ * │   │
└───┴───┴───┴───┘
```

**并行搜索算法**：
```cuda
1. 计算查询点的网格坐标
2. 并行搜索邻域网格：
   - 每个warp处理一个环
   - shuffle交换最小距离
3. 精确计算k个最近邻
```

**优化技巧**：
1. **Morton编码**：将多维坐标映射到1D，改善缓存局部性
2. **分层网格**：粗细两级网格平衡精度与效率
3. **增量维护**：新节点插入时仅更新局部网格

### 16.3.4 并行树扩展策略

**Extend操作的并行化**：

```cuda
批量扩展内核：
parallel_for(each sample in batch) {
    1. 找到最近节点 q_near
    2. 计算新节点 q_new = steer(q_near, q_sample)
    3. 碰撞检测 collision_free(q_near, q_new)
    4. 如果无碰撞，原子添加到候选列表
}
```

**Connect操作的优化**：

贪心连接使用迭代深化：
```
深度限制的连接：
┌──────────┐
│ depth=1  │ 快速尝试
└────┬─────┘
     ↓ 失败
┌──────────┐
│ depth=2  │ 更多步数
└────┬─────┘
     ↓ 失败
┌──────────┐
│ depth=4  │ 指数增长
└──────────┘
```

### 16.3.5 树结构的内存管理

**紧凑的节点表示**：
```cuda
struct RRTNode {
    float3 position;      // 12字节
    int parent_idx;       // 4字节
    float cost;           // 4字节
    int children_start;   // 4字节
    short children_count; // 2字节
    short flags;          // 2字节
    // 总计：28字节 → 对齐到32字节
};
```

**内存池管理**：
1. **预分配策略**：避免动态分配的开销
2. **紧凑存储**：删除节点后的空间回收
3. **分块分配**：每个线程块管理独立的内存块

### 16.3.6 收敛检测与路径提取

**并行收敛检测**：
```cuda
两树连接检测：
1. 批量计算树间距离矩阵
2. warp级别的最小值归约
3. 原子更新全局最优连接
```

**路径平滑优化**：
```
短切（Shortcut）优化：
原始路径： A──B──C──D──E
           ↓ 并行测试所有对
优化路径： A────────D──E
```

并行实现：
- 每个线程测试一对非相邻节点
- 使用投票机制选择最佳短切
- 迭代直到收敛

### 16.3.7 多查询优化

利用经验加速后续查询：

**路径库维护**：
```
经验重用策略：
┌─────────────────┐
│ 历史路径数据库 │
└────────┬────────┘
         ↓
┌─────────────────┐
│ 相似性匹配     │ 并行计算
└────────┬────────┘
         ↓
┌─────────────────┐
│ 路径修复/适应  │
└─────────────────┘
```

**增量式RRT**：
- 保留有效的树结构部分
- 并行修剪无效分支
- 热启动新的查询

## 16.4 轨迹优化（CHOMP/TrajOpt）

### 16.4.1 从路径到轨迹的优化

RRT生成的路径通常不平滑且次优，轨迹优化将其转换为满足动力学约束的平滑轨迹。两种主流方法：

1. **CHOMP（Covariant Hamiltonian Optimization）**：基于梯度的函数优化
2. **TrajOpt（Trajectory Optimization）**：序列凸优化（SCP）

优化目标的一般形式：
```
min J = λ₁·J_smooth + λ₂·J_collision + λ₃·J_dynamics
```

### 16.4.2 CHOMP的GPU并行化

CHOMP将轨迹表示为时间参数化的路径点序列，通过梯度下降最小化代价函数。

**代价函数组成**：

1. **平滑项**（加速度最小化）：
```
J_smooth = ∑ᵢ ||qᵢ₊₁ - 2qᵢ + qᵢ₋₁||²
```

2. **障碍物项**（距离场梯度）：
```
J_obs = ∑ᵢ ∑ⱼ c(d(xⱼⁱ))
```

**并行梯度计算**：
```cuda
梯度计算内核：
parallel_for(each waypoint i) {
    // 平滑项梯度
    grad_smooth[i] = K * (2q[i] - q[i-1] - q[i+1])
    
    // 障碍物梯度（每个身体点）
    parallel_for(each body_point j) {
        x_j = FK(q[i], j)  // 正运动学
        grad_obs += J^T * ∇c(d(x_j))
    }
    
    // 合并梯度
    grad_total[i] = λ₁*grad_smooth + λ₂*grad_obs
}
```

**距离场的GPU构建**：

使用3D Euclidean Distance Transform（EDT）：
```
EDT并行算法：
┌─────────────┐
│ 二值化网格  │ 障碍物=1，自由=0
└──────┬──────┘
       ↓
┌─────────────┐
│ X轴扫描    │ 1D距离变换
└──────┬──────┘
       ↓
┌─────────────┐
│ Y轴扫描    │ 沿列并行
└──────┬──────┘
       ↓
┌─────────────┐
│ Z轴扫描    │ 最终距离场
└─────────────┘
```

### 16.4.3 TrajOpt的序列凸优化

TrajOpt将非凸问题分解为一系列凸子问题：

**线性化策略**：
```
原始非凸约束：
    h(x) ≤ 0
    
线性化近似：
    h(x̄) + ∇h(x̄)ᵀ(x-x̄) ≤ 0
    
信赖域约束：
    ||x - x̄|| ≤ δ
```

**GPU上的QP求解器**：

每次迭代求解二次规划（QP）：
```
min  ½xᵀHx + fᵀx
s.t. Ax ≤ b
     Cx = d
```

并行内点法实现：
1. **KKT系统构建**：并行组装海森矩阵
2. **线性求解**：PCG（预条件共轭梯度）
3. **步长搜索**：并行回溯线搜索

### 16.4.4 碰撞约束的高效处理

**连续碰撞约束**：

对于移动障碍物，需要时空碰撞检测：
```
签名距离函数（SDF）查询：
┌────────────────────┐
│ 4D查询(x,y,z,t)   │
└─────────┬──────────┘
          ↓
┌────────────────────┐
│ 时间插值的3D SDF  │
│ d(x,t) = (1-α)d₀ + αd₁ │
└────────────────────┘
```

**稀疏碰撞检查**：
```cuda
自适应采样策略：
1. 粗采样检测潜在碰撞段
2. 二分细化确定碰撞区间
3. 密集采样生成约束
```

### 16.4.5 动力学约束集成

**关节限制**：
```
位置限制： q_min ≤ q ≤ q_max
速度限制： |q̇| ≤ v_max
加速度限制： |q̈| ≤ a_max
扭矩限制： |τ| ≤ τ_max
```

**并行投影算法**：
```cuda
约束投影内核：
parallel_for(each waypoint) {
    // 位置投影
    q = clamp(q, q_min, q_max)
    
    // 速度投影（考虑时间间隔）
    Δq = q[i] - q[i-1]
    if(||Δq|| > v_max * dt) {
        q[i] = q[i-1] + normalize(Δq) * v_max * dt
    }
    
    // 加速度类似处理
}
```

### 16.4.6 多分辨率优化策略

**时间分辨率自适应**：
```
粗到细优化：
Level 0: ●───────●───────● (3点)
         ↓ 优化并细化
Level 1: ●───●───●───●───● (5点)
         ↓ 优化并细化
Level 2: ●─●─●─●─●─●─●─●─● (9点)
```

**GPU实现要点**：
1. **插值内核**：并行三次样条插值
2. **重采样**：自适应密度控制
3. **层次传播**：粗层解作为细层初值

### 16.4.7 实时性能优化

**计算复用策略**：

1. **梯度缓存**：
```cuda
struct GradientCache {
    float4* body_positions;  // FK结果
    float3* sdf_gradients;   // 距离场梯度
    bool* validity_flags;    // 有效性标记
};
```

2. **增量更新**：
```
仅更新变化的路径段：
━━━●───●───●━━━━
   ↑       ↑
   修改区间
```

3. **早停策略**：
- 梯度范数阈值
- 代价改善率监控
- 最大迭代次数限制

**批量轨迹优化**：

同时优化多条候选轨迹：
```cuda
批量优化架构：
┌─────────────────────┐
│ N条初始轨迹        │
└──────────┬──────────┘
           ↓
┌─────────────────────┐
│ 并行优化（共享SDF） │
└──────────┬──────────┘
           ↓
┌─────────────────────┐
│ 选择最优轨迹       │
└─────────────────────┘
```

## 16.5 多机械臂协调控制

### 16.5.1 多臂系统的挑战

多机械臂协调带来指数级的复杂度增长：

1. **组合爆炸**：n个m自由度机械臂产生n×m维配置空间
2. **耦合约束**：臂间避碰、协同操作、时序同步
3. **通信开销**：分布式系统的同步成本
4. **死锁风险**：资源竞争导致的相互等待

GPU并行化的优势在于能同时处理所有机械臂的运动规划和碰撞检测。

### 16.5.2 集中式协调架构

**统一配置空间方法**：

将所有机械臂视为一个高维系统：
```
联合配置空间：
Q = Q₁ × Q₂ × ... × Qₙ
dim(Q) = ∑ᵢ DOF(i)
```

**GPU任务分配**：
```
并行任务映射：
┌─────────────────────────┐
│ SM0: Robot1 FK/IK      │
│ SM1: Robot2 FK/IK      │
│ SM2: Inter-robot检测   │
│ SM3: 环境碰撞检测      │
└─────────────────────────┘
```

### 16.5.3 优先级规划策略

**分层协调框架**：
```
优先级分配：
Level 1: 主臂（操作关键路径）
Level 2: 辅助臂（支撑/协助）
Level 3: 空闲臂（避让）
```

**GPU实现**：
```cuda
优先级规划内核：
1. 高优先级臂规划
   parallel_plan(primary_arms)
   
2. 约束传播
   update_forbidden_zones(primary_paths)
   
3. 低优先级臂规划
   parallel_plan_with_constraints(secondary_arms)
```

### 16.5.4 时空协调机制

**时间同步图（STG）**：
```
时空轨迹表示：
     t₀   t₁   t₂   t₃
R1: [q₁⁰][q₁¹][q₁²][q₁³]
R2: [q₂⁰][q₂¹][q₂²][q₂³]
R3: [q₃⁰][q₃¹][q₃²][q₃³]
     ↓交叉检测↓
```

**并行冲突检测**：
```cuda
时空冲突检测：
parallel_for(each time_step t) {
    parallel_for(each robot_pair (i,j)) {
        // 计算t时刻的碰撞
        collision[t][i][j] = check_collision(q[i][t], q[j][t])
    }
}
```

**速度调整策略**：
```cuda
时间重参数化：
if(collision_detected) {
    // 减速避让
    s_new = s_old * scale_factor
    resample_trajectory(s_new)
}
```

### 16.5.5 分布式协调控制

**去中心化架构**：

每个机械臂维护局部规划器，通过消息传递协调：
```
消息传递协议：
┌────────┐  intent  ┌────────┐
│ Arm 1  │<-------->│ Arm 2  │
└────────┘          └────────┘
    ↓                    ↓
┌────────────────────────────┐
│   GPU共享内存通信总线      │
└────────────────────────────┘
```

**GPU上的消息队列**：
```cuda
struct Message {
    int sender_id;
    int receiver_id;
    float4 target_pose;
    float timestamp;
    int priority;
};

__device__ MessageQueue msg_queue[MAX_ROBOTS];
```

### 16.5.6 协同操作优化

**双臂协同抓取**：

约束关系：
```
闭链约束：
T₁(q₁) · T_grasp₁ = T_object = T₂(q₂) · T_grasp₂
```

**并行雅可比求解**：
```cuda
协同操作雅可比：
J_combined = [J₁, -J₂]
Δq = J_combined⁺ · Δx_object
```

**负载分配优化**：
```
力/扭矩分配：
min ||W₁τ₁||² + ||W₂τ₂||²
s.t. J₁ᵀτ₁ + J₂ᵀτ₂ = F_external
```

### 16.5.7 死锁预防与恢复

**资源图构建**：
```
等待图分析：
R1 → Zone_A → R2
↑              ↓
└─── Zone_B ←─┘
    (死锁环)
```

**GPU死锁检测**：
```cuda
并行环检测算法：
1. 构建等待矩阵 W[i][j]
2. 计算传递闭包 W*（并行Floyd-Warshall）
3. 检测对角线元素（自等待=死锁）
```

**恢复策略**：
1. **回退**：低优先级臂退让
2. **重规划**：打破循环依赖
3. **虚拟障碍物**：临时扩大安全区域

### 16.5.8 性能扩展性分析

**强扩展性测试**：
```
机械臂数量 vs 规划时间：
2臂: 5ms
4臂: 8ms
8臂: 15ms
16臂: 35ms
```

**优化策略**：
1. **空间分区**：减少不必要的碰撞检测
2. **时间窗口**：仅检测近期时间步
3. **稀疏通信**：事件驱动的消息传递
4. **动态负载均衡**：根据复杂度调整SM分配

## 本章小结

本章深入探讨了机械臂运动规划在GPU上的并行化实现，涵盖了从底层运动学计算到高层多臂协调的完整技术栈：

### 核心技术要点

1. **正逆运动学并行化**：
   - 批量FK计算的矩阵链乘优化
   - 雅可比迭代法的并行IK求解
   - 奇异点的鲁棒处理策略

2. **空间哈希碰撞检测**：
   - GPU友好的固定大小哈希表
   - 宽相位与窄相位的两级检测
   - 连续碰撞检测（CCD）的实现

3. **RRT-Connect GPU加速**：
   - 批量采样与并行扩展
   - 基于网格的近似最近邻搜索
   - 多查询优化与经验重用

4. **轨迹优化算法**：
   - CHOMP的并行梯度计算
   - TrajOpt的序列凸优化
   - 多分辨率优化策略

5. **多臂协调控制**：
   - 集中式与分布式架构
   - 时空协调与死锁预防
   - 协同操作的约束处理

### 关键性能指标

- **运动学求解**：批量1000个配置的FK计算 < 0.1ms
- **碰撞检测**：10万个原语对的检测 < 1ms
- **路径规划**：7自由度机械臂RRT规划 < 50ms
- **轨迹优化**：100个路径点的CHOMP优化 < 10ms
- **多臂协调**：4臂系统实时协调控制 < 10ms

### 核心优化原则

1. **数据并行**：批量处理多个查询
2. **内存优化**：SoA布局与合并访问
3. **计算复用**：缓存中间结果
4. **负载均衡**：动态任务分配
5. **通信最小化**：减少同步点

## 练习题

### 基础题

**练习16.1**：实现6自由度机械臂的批量正运动学计算，输入1024个关节配置，输出末端位姿。

<details>
<summary>提示</summary>
使用每个线程处理一个配置，共享内存存储DH参数，注意矩阵乘法的寄存器优化。
</details>

<details>
<summary>答案</summary>
关键点：1) 将4×4矩阵乘法展开为标量运算；2) 使用__sincosf同时计算正弦余弦；3) 利用纹理内存缓存DH参数；4) 确保内存访问模式合并。预期性能：1024个配置的FK计算应在0.1ms内完成。
</details>

**练习16.2**：设计一个空间哈希结构，支持动态插入和删除胶囊体形状的碰撞原语。

<details>
<summary>提示</summary>
使用双缓冲技术处理并发更新，原子操作管理桶内对象列表。
</details>

<details>
<summary>答案</summary>
实现要点：1) 固定大小哈希表+动态对象池；2) 使用版本号避免ABA问题；3) 延迟删除策略减少内存碎片；4) 网格大小选择为最大对象尺寸的2-3倍。
</details>

**练习16.3**：实现RRT中的批量最近邻搜索，使用Morton编码优化空间局部性。

<details>
<summary>提示</summary>
将3D坐标映射到Morton码，利用Z-order曲线的空间聚类特性。
</details>

<details>
<summary>答案</summary>
Morton编码通过交错x,y,z的二进制位实现空间映射。排序后的Morton码保证空间相近的点在内存中连续，提高缓存命中率。使用位操作并行计算Morton码。
</details>

**练习16.4**：优化CHOMP的距离场查询，实现三线性插值的向量化版本。

<details>
<summary>提示</summary>
使用float4一次加载2×2×2的网格数据，利用fma指令加速插值计算。
</details>

<details>
<summary>答案</summary>
关键优化：1) 预计算插值权重；2) 使用纹理内存的硬件插值；3) 批量查询时重用网格单元数据；4) 边界处理使用钳位而非分支。
</details>

### 挑战题

**练习16.5**：设计并实现一个GPU加速的双臂协同装配系统，要求两个7自由度机械臂协同完成插孔装配任务。

<details>
<summary>提示</summary>
考虑闭链约束、力/位混合控制、柔顺性要求，使用增广拉格朗日方法处理约束。
</details>

<details>
<summary>答案</summary>
系统架构：1) 主从控制模式，主臂引导位置，从臂提供支撑力；2) 使用投影梯度法处理闭链约束；3) 实现虚拟弹簧-阻尼模型提供柔顺性；4) 并行计算两臂的零空间，优化关节配置；5) 使用力传感器反馈修正轨迹。关键挑战是保证数值稳定性和实时性能。
</details>

**练习16.6**：实现一个自适应分辨率的RRT*算法，根据障碍物密度动态调整采样策略。

<details>
<summary>提示</summary>
使用八叉树维护空间占用信息，高障碍物密度区域增加采样密度。
</details>

<details>
<summary>答案</summary>
实现策略：1) 并行构建八叉树统计障碍物分布；2) 基于信息熵计算采样概率图；3) 使用重要性采样生成偏向狭窄通道的样本；4) 动态调整连接半径适应局部复杂度；5) 实现批量重连优化降低路径代价。预期效果：狭窄通道场景下成功率提升3-5倍。
</details>

**练习16.7**：开发一个多机械臂仓库分拣系统，支持16个机械臂的实时协调控制。

<details>
<summary>提示</summary>
使用分层规划架构，结合拍卖算法进行任务分配，实现去中心化协调。
</details>

<details>
<summary>答案</summary>
系统设计：1) 任务层：并行拍卖算法分配抓取任务；2) 路径层：时空A*避免碰撞；3) 控制层：分布式MPC跟踪轨迹；4) 使用预测窗口检测潜在冲突；5) 实现优先级反转处理死锁；6) 空间分区减少通信开销。关键指标：16臂系统应保持<50ms的重规划延迟。
</details>

**练习16.8**：探索使用神经网络加速运动规划，设计一个学习型的轨迹优化器。

<details>
<summary>提示</summary>
训练网络预测CHOMP的梯度方向，使用CUDA Graph优化推理性能。
</details>

<details>
<summary>答案</summary>
混合方法：1) 离线训练CNN预测距离场梯度；2) 使用GNN编码机械臂拓扑结构；3) 推理时网络输出作为优化初值；4) 传统优化器精修保证安全性；5) 使用TensorRT部署，融合算子减少内核启动；6) 实现在线学习不断改进预测。预期加速：相比纯优化方法快5-10倍收敛。
</details>

## 常见陷阱与错误（Gotchas）

### 内存管理陷阱

1. **动态内存分配**：避免在内核中使用malloc，预分配所有需要的内存
2. **内存泄漏**：RRT节点的生命周期管理，使用内存池避免碎片
3. **bank conflict**：共享内存中矩阵存储注意padding避免冲突

### 数值稳定性问题

1. **奇异配置**：雅可比矩阵接近奇异时使用阻尼最小二乘
2. **累积误差**：长链式矩阵乘法使用Kahan求和或双精度
3. **归一化**：四元数表示旋转时频繁归一化避免漂移

### 同步错误

1. **竞态条件**：多臂系统的共享资源访问需要原子操作
2. **死锁**：避免嵌套锁，使用超时机制
3. **内存一致性**：使用内存栅栏确保更新可见性

### 性能瓶颈

1. **warp发散**：碰撞检测的早期退出造成线程空闲
2. **内存带宽**：大量随机访问距离场造成缓存未命中
3. **负载不均**：某些机械臂的规划复杂度远高于其他

### 算法收敛问题

1. **局部最小值**：CHOMP容易陷入局部最优，需要多起点策略
2. **振荡**：步长过大导致优化振荡，使用自适应步长
3. **约束违反**：硬约束处理不当导致不可行解

## 最佳实践检查清单

### 设计审查

- [ ] 是否选择了合适的并行粒度（任务级/数据级/指令级）？
- [ ] 内存访问模式是否优化（合并访问、避免bank conflict）？
- [ ] 是否充分利用了GPU内存层次（纹理、常量、共享内存）？
- [ ] 算法是否适合GPU架构（高算术强度、规则控制流）？

### 实现检查

- [ ] 是否避免了动态内存分配和递归调用？
- [ ] 原子操作是否必要且使用正确？
- [ ] 是否处理了所有边界条件和异常情况？
- [ ] 数值计算是否考虑了精度和稳定性？

### 优化验证

- [ ] 是否使用Nsight Compute分析了性能瓶颈？
- [ ] 占用率是否达到目标（通常>50%）？
- [ ] 内存带宽利用率是否合理？
- [ ] 是否存在明显的负载不均衡？

### 系统集成

- [ ] 与CPU代码的接口是否高效（最小化数据传输）？
- [ ] 多GPU扩展是否考虑（数据分区、通信优化）？
- [ ] 错误处理和恢复机制是否完善？
- [ ] 是否提供了性能监控和调试接口？

### 测试覆盖

- [ ] 单元测试是否覆盖所有核心算法？
- [ ] 压力测试是否验证了极限场景？
- [ ] 正确性验证是否与CPU参考实现对比？
- [ ] 性能基准是否在目标硬件上测试？